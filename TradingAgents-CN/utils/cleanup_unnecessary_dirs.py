#!/usr/bin/env python3
"""
æ¸…ç†ä¸å¿…è¦çš„ç›®å½•å’Œæ–‡ä»¶
ç§»é™¤è‡ªåŠ¨ç”Ÿæˆçš„æ–‡ä»¶å’Œä¸´æ—¶è¾“å‡º
"""

import os
import shutil
from pathlib import Path

# å¯¼å…¥æ—¥å¿—æ¨¡å—
from tradingagents.utils.logging_manager import get_logger
logger = get_logger('default')


def cleanup_directories():
    """æ¸…ç†ä¸å¿…è¦çš„ç›®å½•"""
    logger.info(f"ğŸ§¹ æ¸…ç†ä¸å¿…è¦çš„ç›®å½•å’Œæ–‡ä»¶")
    logger.info(f"=")
    
    # é¡¹ç›®æ ¹ç›®å½•
    project_root = Path(".")
    
    # éœ€è¦æ¸…ç†çš„ç›®å½•
    cleanup_dirs = [
        "tradingagents.egg-info",
        "enhanced_analysis_reports",
        "__pycache__",
        ".pytest_cache",
    ]
    
    # éœ€è¦æ¸…ç†çš„æ–‡ä»¶æ¨¡å¼
    cleanup_patterns = [
        "*.pyc",
        "*.pyo", 
        "*.pyd",
        ".DS_Store",
        "Thumbs.db"
    ]
    
    cleaned_count = 0
    
    # æ¸…ç†ç›®å½•
    for dir_name in cleanup_dirs:
        dir_path = project_root / dir_name
        if dir_path.exists():
            try:
                shutil.rmtree(dir_path)
                logger.info(f"âœ… åˆ é™¤ç›®å½•: {dir_name}")
                cleaned_count += 1
            except Exception as e:
                logger.error(f"âŒ åˆ é™¤å¤±è´¥ {dir_name}: {e}")
    
    # é€’å½’æ¸…ç†æ–‡ä»¶
    for pattern in cleanup_patterns:
        for file_path in project_root.rglob(pattern):
            try:
                file_path.unlink()
                logger.info(f"âœ… åˆ é™¤æ–‡ä»¶: {file_path}")
                cleaned_count += 1
            except Exception as e:
                logger.error(f"âŒ åˆ é™¤å¤±è´¥ {file_path}: {e}")
    
    return cleaned_count

def update_gitignore():
    """æ›´æ–°.gitignoreæ–‡ä»¶"""
    logger.info(f"\nğŸ“ æ›´æ–°.gitignoreæ–‡ä»¶")
    logger.info(f"=")
    
    gitignore_path = Path(".gitignore")
    
    # éœ€è¦æ·»åŠ çš„å¿½ç•¥è§„åˆ™
    ignore_rules = [
        "# PythonåŒ…å…ƒæ•°æ®",
        "*.egg-info/",
        "tradingagents.egg-info/",
        "",
        "# ä¸´æ—¶è¾“å‡ºæ–‡ä»¶", 
        "enhanced_analysis_reports/",
        "analysis_reports/",
        "",
        "# Pythonç¼“å­˜",
        "__pycache__/",
        "*.py[cod]",
        "*$py.class",
        ".pytest_cache/",
        "",
        "# ç³»ç»Ÿæ–‡ä»¶",
        ".DS_Store",
        "Thumbs.db",
        "",
        "# IDEæ–‡ä»¶",
        ".vscode/settings.json",
        ".idea/",
        "",
        "# æ—¥å¿—æ–‡ä»¶",
        "*.log",
        "logs/",
    ]
    
    try:
        # è¯»å–ç°æœ‰å†…å®¹
        existing_content = ""
        if gitignore_path.exists():
            with open(gitignore_path, 'r', encoding='utf-8') as f:
                existing_content = f.read()
        
        # æ£€æŸ¥å“ªäº›è§„åˆ™éœ€è¦æ·»åŠ 
        new_rules = []
        for rule in ignore_rules:
            if rule.strip() and rule not in existing_content:
                new_rules.append(rule)
        
        if new_rules:
            # æ·»åŠ æ–°è§„åˆ™
            with open(gitignore_path, 'a', encoding='utf-8') as f:
                f.write("\n# è‡ªåŠ¨æ¸…ç†è„šæœ¬æ·»åŠ çš„è§„åˆ™\n")
                for rule in new_rules:
                    f.write(f"{rule}\n")
            
            logger.info(f"âœ… æ·»åŠ äº† {len(new_rules)} æ¡æ–°çš„å¿½ç•¥è§„åˆ™")
        else:
            logger.info(f"âœ… .gitignoreå·²ç»æ˜¯æœ€æ–°çš„")
            
    except Exception as e:
        logger.error(f"âŒ æ›´æ–°.gitignoreå¤±è´¥: {e}")

def analyze_upstream_contribution():
    """åˆ†æupstream_contributionç›®å½•"""
    logger.debug(f"\nğŸ” åˆ†æupstream_contributionç›®å½•")
    logger.info(f"=")
    
    upstream_dir = Path("upstream_contribution")
    
    if not upstream_dir.exists():
        logger.info(f"âœ… upstream_contributionç›®å½•ä¸å­˜åœ¨")
        return
    
    # ç»Ÿè®¡å†…å®¹
    batch_dirs = list(upstream_dir.glob("batch*"))
    json_files = list(upstream_dir.glob("*.json"))
    
    logger.info(f"ğŸ“Š å‘ç°å†…å®¹:")
    logger.info(f"   - Batchç›®å½•: {len(batch_dirs)}ä¸ª")
    logger.info(f"   - JSONæ–‡ä»¶: {len(json_files)}ä¸ª")
    
    for batch_dir in batch_dirs:
        logger.info(f"   - {batch_dir.name}: {len(list(batch_dir.rglob('*')))}ä¸ªæ–‡ä»¶")
    
    # è¯¢é—®æ˜¯å¦åˆ é™¤
    logger.info(f"\nğŸ’¡ upstream_contributionç›®å½•ç”¨é€”:")
    logger.info(f"   - å‡†å¤‡å‘ä¸Šæ¸¸é¡¹ç›®(TauricResearch/TradingAgents)è´¡çŒ®ä»£ç ")
    logger.info(f"   - åŒ…å«ç§»é™¤ä¸­æ–‡å†…å®¹çš„ç‰ˆæœ¬")
    logger.info(f"   - å¦‚æœä¸è®¡åˆ’å‘ä¸Šæ¸¸è´¡çŒ®ï¼Œå¯ä»¥åˆ é™¤")
    
    return len(batch_dirs) + len(json_files)

def main():
    """ä¸»å‡½æ•°"""
    logger.info(f"ğŸ§¹ TradingAgents ç›®å½•æ¸…ç†å·¥å…·")
    logger.info(f"=")
    logger.info(f"ğŸ’¡ ç›®æ ‡: æ¸…ç†è‡ªåŠ¨ç”Ÿæˆçš„æ–‡ä»¶å’Œä¸å¿…è¦çš„ç›®å½•")
    logger.info(f"=")
    
    # æ¸…ç†ç›®å½•å’Œæ–‡ä»¶
    cleaned_count = cleanup_directories()
    
    # æ›´æ–°gitignore
    update_gitignore()
    
    # åˆ†æupstream_contribution
    upstream_count = analyze_upstream_contribution()
    
    # æ€»ç»“
    logger.info(f"\nğŸ“Š æ¸…ç†æ€»ç»“")
    logger.info(f"=")
    logger.info(f"âœ… æ¸…ç†äº† {cleaned_count} ä¸ªæ–‡ä»¶/ç›®å½•")
    logger.info(f"ğŸ“ æ›´æ–°äº† .gitignore æ–‡ä»¶")
    
    if upstream_count > 0:
        logger.warning(f"âš ï¸ upstream_contributionç›®å½•åŒ…å« {upstream_count} ä¸ªé¡¹ç›®")
        logger.info(f"   å¦‚æœä¸éœ€è¦å‘ä¸Šæ¸¸è´¡çŒ®ï¼Œå¯ä»¥æ‰‹åŠ¨åˆ é™¤:")
        logger.info(f"   rm -rf upstream_contribution/")
    
    logger.info(f"\nğŸ‰ æ¸…ç†å®Œæˆï¼é¡¹ç›®ç›®å½•æ›´åŠ æ•´æ´")
    logger.info(f"\nğŸ’¡ å»ºè®®:")
    logger.info(f"   1. æ£€æŸ¥gitçŠ¶æ€: git status")
    logger.info(f"   2. æäº¤æ¸…ç†æ›´æ”¹: git add . && git commit -m 'æ¸…ç†ä¸å¿…è¦çš„ç›®å½•å’Œæ–‡ä»¶'")
    logger.info(f"   3. å¦‚æœä¸éœ€è¦upstream_contributionï¼Œå¯ä»¥æ‰‹åŠ¨åˆ é™¤")

if __name__ == "__main__":
    main()
