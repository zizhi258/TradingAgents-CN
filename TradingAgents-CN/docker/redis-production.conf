# =============================================================================
# Production Redis Configuration for TradingAgents-CN Data Pipeline
# Optimized for high-performance caching and message queuing
# =============================================================================

# Network and Connection Settings
bind 0.0.0.0
port 6379
tcp-backlog 511
tcp-keepalive 300
timeout 0

# Memory Management
maxmemory 2gb
maxmemory-policy allkeys-lru
maxmemory-samples 5

# Persistence Configuration
save 900 1      # Save snapshot if at least 1 key changed in 900 seconds
save 300 10     # Save snapshot if at least 10 keys changed in 300 seconds  
save 60 10000   # Save snapshot if at least 10000 keys changed in 60 seconds

stop-writes-on-bgsave-error yes
rdbcompression yes
rdbchecksum yes
dbfilename dump.rdb
dir /data

# Append Only File (AOF) Configuration
appendonly yes
appendfilename "appendonly.aof"
appendfsync everysec
no-appendfsync-on-rewrite no
auto-aof-rewrite-percentage 100
auto-aof-rewrite-min-size 64mb
aof-load-truncated yes
aof-use-rdb-preamble yes

# Logging
loglevel notice
logfile /var/log/redis/redis-server.log
syslog-enabled no

# Performance Tuning
databases 16
hash-max-ziplist-entries 512
hash-max-ziplist-value 64
list-max-ziplist-size -2
list-compress-depth 0
set-max-intset-entries 512
zset-max-ziplist-entries 128
zset-max-ziplist-value 64
hll-sparse-max-bytes 3000
stream-node-max-bytes 4096
stream-node-max-entries 100

# Client Settings
client-output-buffer-limit normal 0 0 0
client-output-buffer-limit replica 256mb 64mb 60
client-output-buffer-limit pubsub 32mb 8mb 60
client-query-buffer-limit 1gb
proto-max-bulk-len 512mb

# Security (password will be set via command line)
protected-mode yes
# requirepass will be set via Docker command

# Replication Settings (for replica instances)
replica-serve-stale-data yes
replica-read-only yes
repl-diskless-sync no
repl-diskless-sync-delay 5
repl-ping-replica-period 10
repl-timeout 60
repl-disable-tcp-nodelay no
replica-priority 100

# Slow Log Configuration
slowlog-log-slower-than 10000
slowlog-max-len 128

# Latency Monitor
latency-monitor-threshold 100

# Key Expiration
hz 10

# Memory Usage Optimization for Data Pipeline
# Optimize for streaming data patterns
stream-node-max-entries 1000
stream-node-max-bytes 8192

# Large hash tables for market data
hash-max-ziplist-entries 1024
hash-max-ziplist-value 128

# Sorted sets for time-series data
zset-max-ziplist-entries 256
zset-max-ziplist-value 128

# List optimization for queues
list-max-ziplist-size 8
list-compress-depth 2

# Advanced Features
dynamic-hz yes
lua-time-limit 5000

# Module Loading (if needed for extensions)
# loadmodule /path/to/redis-module.so

# =============================================================================
# Data Pipeline Specific Configurations
# =============================================================================

# Configure multiple databases for different purposes:
# DB 0: Market data cache
# DB 1: Celery/Airflow message broker
# DB 2: Session data
# DB 3: ML features cache
# DB 4: Analysis results cache
# DB 5: Configuration cache
# DB 6: Streaming pipeline buffers
# DB 7: Data quality metrics
# DB 8-15: Reserved for future use

databases 16

# Notifications for keyspace events (useful for monitoring)
notify-keyspace-events Ex

# =============================================================================
# Monitoring and Statistics
# =============================================================================

# Enable INFO command sections
# info all

# =============================================================================
# Comments for Operational Teams
# =============================================================================

# This Redis instance is configured for TradingAgents-CN data pipeline with:
# 1. High-performance caching for market data
# 2. Message queuing for Airflow/Celery
# 3. Session storage for web applications
# 4. Real-time data streaming buffers
# 5. ML feature caching for model inference
# 6. Analysis result caching
#
# Memory usage is optimized for:
# - Frequent reads and writes of small to medium-sized objects
# - Time-series data with automatic expiration
# - Message queuing with persistence
# - High concurrent connections from multiple services
#
# Monitoring recommendations:
# - Monitor memory usage and hit rates
# - Check slow log for performance issues
# - Monitor keyspace events for data pipeline health
# - Set up alerts for replication lag (if using replicas)
#
# Backup strategy:
# - RDB snapshots are saved automatically based on save directives
# - AOF provides durability for message queue operations
# - Consider external backup solution for critical data