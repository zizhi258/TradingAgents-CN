#!/usr/bin/env python3
"""
è°ƒåº¦å™¨è¿è¡ŒæŠ¥å‘Šå·¥å…·
ç”¨äºç”Ÿæˆç»“æ„åŒ–çš„è°ƒåº¦å™¨æ‰§è¡ŒæŠ¥å‘Šå’Œæ€§èƒ½æŒ‡æ ‡
"""

import json
import os
from datetime import datetime
from pathlib import Path
from typing import Dict, List, Optional, Any
from dataclasses import dataclass, asdict

@dataclass
class DigestRunReport:
    """æ‘˜è¦è¿è¡ŒæŠ¥å‘Šæ•°æ®ç»“æ„"""
    run_id: str
    trigger_type: str
    start_time: str
    end_time: Optional[str] = None
    duration_seconds: Optional[float] = None
    status: str = "running"  # running, completed, failed, cancelled
    subscriptions_processed: int = 0
    symbols_analyzed: int = 0
    emails_sent: int = 0
    emails_failed: int = 0
    total_cost: float = 0.0
    attachments_generated: List[str] = None
    errors: List[str] = None
    performance_metrics: Dict[str, Any] = None
    
    def __post_init__(self):
        if self.attachments_generated is None:
            self.attachments_generated = []
        if self.errors is None:
            self.errors = []
        if self.performance_metrics is None:
            self.performance_metrics = {}

class RunReportManager:
    """è¿è¡ŒæŠ¥å‘Šç®¡ç†å™¨"""
    
    def __init__(self, reports_dir: str = None):
        if reports_dir is None:
            reports_dir = Path(__file__).parent.parent.parent / "data" / "scheduler_runs"
        
        self.reports_dir = Path(reports_dir)
        self.reports_dir.mkdir(parents=True, exist_ok=True)
    
    def create_run_report(self, trigger_type: str, trigger_data: Dict = None) -> str:
        """åˆ›å»ºæ–°çš„è¿è¡ŒæŠ¥å‘Š"""
        run_id = f"{trigger_type}_{datetime.now().strftime('%Y%m%d_%H%M%S_%f')[:-3]}"
        
        report = DigestRunReport(
            run_id=run_id,
            trigger_type=trigger_type,
            start_time=datetime.now().isoformat(),
            status="running"
        )
        
        # æ·»åŠ è§¦å‘å™¨æ•°æ®åˆ°æ€§èƒ½æŒ‡æ ‡
        if trigger_data:
            report.performance_metrics['trigger_data'] = trigger_data
        
        self._save_report(report)
        return run_id
    
    def update_run_report(self, run_id: str, **updates) -> bool:
        """æ›´æ–°è¿è¡ŒæŠ¥å‘Š"""
        try:
            report = self._load_report(run_id)
            if not report:
                return False
            
            # æ›´æ–°å­—æ®µ
            for key, value in updates.items():
                if hasattr(report, key):
                    setattr(report, key, value)
            
            # è‡ªåŠ¨è®¡ç®—æŒç»­æ—¶é—´
            if report.end_time and report.start_time:
                start_dt = datetime.fromisoformat(report.start_time)
                end_dt = datetime.fromisoformat(report.end_time)
                report.duration_seconds = (end_dt - start_dt).total_seconds()
            
            self._save_report(report)
            return True
            
        except Exception as e:
            print(f"æ›´æ–°è¿è¡ŒæŠ¥å‘Šå¤±è´¥: {e}")
            return False
    
    def complete_run_report(self, run_id: str, status: str = "completed", 
                          subscriptions: int = 0, symbols: int = 0,
                          emails_sent: int = 0, emails_failed: int = 0,
                          total_cost: float = 0.0, attachments: List[str] = None,
                          errors: List[str] = None) -> bool:
        """å®Œæˆè¿è¡ŒæŠ¥å‘Š"""
        updates = {
            'end_time': datetime.now().isoformat(),
            'status': status,
            'subscriptions_processed': subscriptions,
            'symbols_analyzed': symbols,
            'emails_sent': emails_sent,
            'emails_failed': emails_failed,
            'total_cost': total_cost
        }
        
        if attachments:
            updates['attachments_generated'] = attachments
        if errors:
            updates['errors'] = errors
        
        return self.update_run_report(run_id, **updates)
    
    def add_error(self, run_id: str, error: str) -> bool:
        """å‘è¿è¡ŒæŠ¥å‘Šæ·»åŠ é”™è¯¯"""
        try:
            report = self._load_report(run_id)
            if report:
                report.errors.append(f"{datetime.now().isoformat()}: {error}")
                self._save_report(report)
                return True
            return False
        except Exception:
            return False
    
    def add_performance_metric(self, run_id: str, metric_name: str, value: Any) -> bool:
        """æ·»åŠ æ€§èƒ½æŒ‡æ ‡"""
        try:
            report = self._load_report(run_id)
            if report:
                report.performance_metrics[metric_name] = value
                self._save_report(report)
                return True
            return False
        except Exception:
            return False
    
    def get_recent_reports(self, limit: int = 10) -> List[Dict]:
        """è·å–æœ€è¿‘çš„è¿è¡ŒæŠ¥å‘Š"""
        try:
            report_files = sorted(
                self.reports_dir.glob("*.json"), 
                key=lambda x: x.stat().st_mtime,
                reverse=True
            )[:limit]
            
            reports = []
            for file_path in report_files:
                try:
                    with open(file_path, 'r', encoding='utf-8') as f:
                        reports.append(json.load(f))
                except Exception as e:
                    print(f"è¯»å–æŠ¥å‘Šæ–‡ä»¶å¤±è´¥ {file_path}: {e}")
            
            return reports
            
        except Exception as e:
            print(f"è·å–æœ€è¿‘æŠ¥å‘Šå¤±è´¥: {e}")
            return []
    
    def get_statistics_summary(self, days: int = 7) -> Dict:
        """è·å–ç»Ÿè®¡æ‘˜è¦"""
        try:
            from datetime import timedelta
            cutoff_date = datetime.now() - timedelta(days=days)
            
            recent_reports = []
            for file_path in self.reports_dir.glob("*.json"):
                if file_path.stat().st_mtime >= cutoff_date.timestamp():
                    try:
                        with open(file_path, 'r', encoding='utf-8') as f:
                            recent_reports.append(json.load(f))
                    except Exception:
                        continue
            
            if not recent_reports:
                return {'total_runs': 0, 'period_days': days}
            
            # è®¡ç®—ç»Ÿè®¡ä¿¡æ¯
            stats = {
                'period_days': days,
                'total_runs': len(recent_reports),
                'successful_runs': len([r for r in recent_reports if r.get('status') == 'completed']),
                'failed_runs': len([r for r in recent_reports if r.get('status') == 'failed']),
                'total_emails_sent': sum(r.get('emails_sent', 0) for r in recent_reports),
                'total_emails_failed': sum(r.get('emails_failed', 0) for r in recent_reports),
                'total_subscriptions_processed': sum(r.get('subscriptions_processed', 0) for r in recent_reports),
                'total_symbols_analyzed': sum(r.get('symbols_analyzed', 0) for r in recent_reports),
                'total_cost': sum(r.get('total_cost', 0) for r in recent_reports),
                'average_duration': 0,
                'success_rate': 0
            }
            
            # è®¡ç®—å¹³å‡æŒç»­æ—¶é—´
            durations = [r.get('duration_seconds', 0) for r in recent_reports if r.get('duration_seconds')]
            if durations:
                stats['average_duration'] = sum(durations) / len(durations)
            
            # è®¡ç®—æˆåŠŸç‡
            if stats['total_runs'] > 0:
                stats['success_rate'] = stats['successful_runs'] / stats['total_runs']
            
            return stats
            
        except Exception as e:
            print(f"è·å–ç»Ÿè®¡æ‘˜è¦å¤±è´¥: {e}")
            return {'error': str(e)}
    
    def cleanup_old_reports(self, days: int = 30) -> int:
        """æ¸…ç†æ—§çš„æŠ¥å‘Šæ–‡ä»¶"""
        try:
            from datetime import timedelta
            cutoff_date = datetime.now() - timedelta(days=days)
            
            cleaned_count = 0
            for file_path in self.reports_dir.glob("*.json"):
                if file_path.stat().st_mtime < cutoff_date.timestamp():
                    try:
                        file_path.unlink()
                        cleaned_count += 1
                    except Exception as e:
                        print(f"åˆ é™¤æŠ¥å‘Šæ–‡ä»¶å¤±è´¥ {file_path}: {e}")
            
            return cleaned_count
            
        except Exception as e:
            print(f"æ¸…ç†æ—§æŠ¥å‘Šå¤±è´¥: {e}")
            return 0
    
    def _load_report(self, run_id: str) -> Optional[DigestRunReport]:
        """åŠ è½½è¿è¡ŒæŠ¥å‘Š"""
        try:
            report_file = self.reports_dir / f"{run_id}.json"
            if not report_file.exists():
                return None
            
            with open(report_file, 'r', encoding='utf-8') as f:
                data = json.load(f)
            
            return DigestRunReport(**data)
            
        except Exception as e:
            print(f"åŠ è½½è¿è¡ŒæŠ¥å‘Šå¤±è´¥: {e}")
            return None
    
    def _save_report(self, report: DigestRunReport) -> bool:
        """ä¿å­˜è¿è¡ŒæŠ¥å‘Š"""
        try:
            report_file = self.reports_dir / f"{report.run_id}.json"
            
            with open(report_file, 'w', encoding='utf-8') as f:
                json.dump(asdict(report), f, ensure_ascii=False, indent=2)
            
            return True
            
        except Exception as e:
            print(f"ä¿å­˜è¿è¡ŒæŠ¥å‘Šå¤±è´¥: {e}")
            return False

# å…¨å±€å®ä¾‹
_run_report_manager = None

def get_run_report_manager() -> RunReportManager:
    """è·å–å…¨å±€è¿è¡ŒæŠ¥å‘Šç®¡ç†å™¨å®ä¾‹"""
    global _run_report_manager
    if _run_report_manager is None:
        _run_report_manager = RunReportManager()
    return _run_report_manager

def create_digest_run_report(trigger_type: str, trigger_data: Dict = None) -> str:
    """ä¾¿æ·å‡½æ•°ï¼šåˆ›å»ºæ‘˜è¦è¿è¡ŒæŠ¥å‘Š"""
    manager = get_run_report_manager()
    return manager.create_run_report(trigger_type, trigger_data)

def complete_digest_run_report(run_id: str, **kwargs) -> bool:
    """ä¾¿æ·å‡½æ•°ï¼šå®Œæˆæ‘˜è¦è¿è¡ŒæŠ¥å‘Š"""
    manager = get_run_report_manager()
    return manager.complete_run_report(run_id, **kwargs)

def add_run_error(run_id: str, error: str) -> bool:
    """ä¾¿æ·å‡½æ•°ï¼šæ·»åŠ è¿è¡Œé”™è¯¯"""
    manager = get_run_report_manager()
    return manager.add_error(run_id, error)

if __name__ == "__main__":
    # æµ‹è¯•ä»£ç 
    print("ğŸ§ª æµ‹è¯•è¿è¡ŒæŠ¥å‘Šç®¡ç†å™¨")
    
    manager = RunReportManager()
    
    # åˆ›å»ºæµ‹è¯•æŠ¥å‘Š
    run_id = manager.create_run_report("daily", {"test": True})
    print(f"åˆ›å»ºæŠ¥å‘Š: {run_id}")
    
    # æ›´æ–°æŠ¥å‘Š
    manager.add_performance_metric(run_id, "test_metric", 42)
    manager.add_error(run_id, "æµ‹è¯•é”™è¯¯")
    
    # å®ŒæˆæŠ¥å‘Š
    manager.complete_run_report(
        run_id, "completed",
        subscriptions=5, symbols=10, emails_sent=3,
        total_cost=1.25, attachments=["test.pdf", "test.html"]
    )
    
    # è·å–ç»Ÿè®¡ä¿¡æ¯
    stats = manager.get_statistics_summary()
    print(f"ç»Ÿè®¡ä¿¡æ¯: {stats}")
    
    # è·å–æœ€è¿‘æŠ¥å‘Š
    recent = manager.get_recent_reports(5)
    print(f"æœ€è¿‘æŠ¥å‘Šæ•°é‡: {len(recent)}")
    
    print("âœ… æµ‹è¯•å®Œæˆ")