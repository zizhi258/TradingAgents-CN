"""
æ–°é—»è¿‡æ»¤é›†æˆæ¨¡å—
å°†æ–°é—»è¿‡æ»¤å™¨é›†æˆåˆ°ç°æœ‰çš„æ–°é—»è·å–æµç¨‹ä¸­
"""

import pandas as pd
import logging
from typing import Optional, Dict, Any
from datetime import datetime

logger = logging.getLogger(__name__)

def integrate_news_filtering(original_get_stock_news_em):
    """
    è£…é¥°å™¨ï¼šä¸ºget_stock_news_emå‡½æ•°æ·»åŠ æ–°é—»è¿‡æ»¤åŠŸèƒ½
    
    Args:
        original_get_stock_news_em: åŸå§‹çš„get_stock_news_emå‡½æ•°
        
    Returns:
        åŒ…è£…åçš„å‡½æ•°ï¼Œå…·æœ‰æ–°é—»è¿‡æ»¤åŠŸèƒ½
    """
    def filtered_get_stock_news_em(symbol: str, enable_filter: bool = True, min_score: float = 30, 
                                  use_semantic: bool = False, use_local_model: bool = False) -> pd.DataFrame:
        """
        å¢å¼ºç‰ˆget_stock_news_emï¼Œé›†æˆæ–°é—»è¿‡æ»¤åŠŸèƒ½
        
        Args:
            symbol: è‚¡ç¥¨ä»£ç 
            enable_filter: æ˜¯å¦å¯ç”¨æ–°é—»è¿‡æ»¤
            min_score: æœ€ä½ç›¸å…³æ€§è¯„åˆ†é˜ˆå€¼
            use_semantic: æ˜¯å¦ä½¿ç”¨è¯­ä¹‰ç›¸ä¼¼åº¦è¿‡æ»¤
            use_local_model: æ˜¯å¦ä½¿ç”¨æœ¬åœ°åˆ†ç±»æ¨¡å‹
            
        Returns:
            pd.DataFrame: è¿‡æ»¤åçš„æ–°é—»æ•°æ®
        """
        logger.info(f"[æ–°é—»è¿‡æ»¤é›†æˆ] å¼€å§‹è·å– {symbol} çš„æ–°é—»ï¼Œè¿‡æ»¤å¼€å…³: {enable_filter}")
        
        # è°ƒç”¨åŸå§‹å‡½æ•°è·å–æ–°é—»
        start_time = datetime.now()
        try:
            news_df = original_get_stock_news_em(symbol)
            fetch_time = (datetime.now() - start_time).total_seconds()
            
            if news_df.empty:
                logger.warning(f"[æ–°é—»è¿‡æ»¤é›†æˆ] åŸå§‹å‡½æ•°æœªè·å–åˆ° {symbol} çš„æ–°é—»æ•°æ®")
                return news_df
            
            logger.info(f"[æ–°é—»è¿‡æ»¤é›†æˆ] åŸå§‹æ–°é—»è·å–æˆåŠŸ: {len(news_df)}æ¡ï¼Œè€—æ—¶: {fetch_time:.2f}ç§’")
            
            # å¦‚æœä¸å¯ç”¨è¿‡æ»¤ï¼Œç›´æ¥è¿”å›åŸå§‹æ•°æ®
            if not enable_filter:
                logger.info(f"[æ–°é—»è¿‡æ»¤é›†æˆ] è¿‡æ»¤åŠŸèƒ½å·²ç¦ç”¨ï¼Œè¿”å›åŸå§‹æ–°é—»æ•°æ®")
                return news_df
            
            # å¯ç”¨æ–°é—»è¿‡æ»¤
            filter_start_time = datetime.now()
            
            try:
                # å¯¼å…¥è¿‡æ»¤å™¨
                from tradingagents.utils.enhanced_news_filter import create_enhanced_news_filter
                
                # åˆ›å»ºè¿‡æ»¤å™¨
                news_filter = create_enhanced_news_filter(
                    symbol, 
                    use_semantic=use_semantic, 
                    use_local_model=use_local_model
                )
                
                # æ‰§è¡Œè¿‡æ»¤
                filtered_df = news_filter.filter_news_enhanced(news_df, min_score=min_score)
                
                filter_time = (datetime.now() - filter_start_time).total_seconds()
                
                # è®°å½•è¿‡æ»¤ç»Ÿè®¡
                original_count = len(news_df)
                filtered_count = len(filtered_df)
                filter_rate = (original_count - filtered_count) / original_count * 100 if original_count > 0 else 0
                
                logger.info(f"[æ–°é—»è¿‡æ»¤é›†æˆ] æ–°é—»è¿‡æ»¤å®Œæˆ:")
                logger.info(f"  - åŸå§‹æ–°é—»: {original_count}æ¡")
                logger.info(f"  - è¿‡æ»¤åæ–°é—»: {filtered_count}æ¡")
                logger.info(f"  - è¿‡æ»¤ç‡: {filter_rate:.1f}%")
                logger.info(f"  - è¿‡æ»¤è€—æ—¶: {filter_time:.2f}ç§’")
                
                if not filtered_df.empty:
                    avg_score = filtered_df['final_score'].mean()
                    max_score = filtered_df['final_score'].max()
                    logger.info(f"  - å¹³å‡è¯„åˆ†: {avg_score:.1f}")
                    logger.info(f"  - æœ€é«˜è¯„åˆ†: {max_score:.1f}")
                
                return filtered_df
                
            except Exception as filter_error:
                logger.error(f"[æ–°é—»è¿‡æ»¤é›†æˆ] æ–°é—»è¿‡æ»¤å¤±è´¥: {filter_error}")
                logger.error(f"[æ–°é—»è¿‡æ»¤é›†æˆ] è¿”å›åŸå§‹æ–°é—»æ•°æ®ä½œä¸ºå¤‡ç”¨")
                return news_df
                
        except Exception as fetch_error:
            logger.error(f"[æ–°é—»è¿‡æ»¤é›†æˆ] åŸå§‹æ–°é—»è·å–å¤±è´¥: {fetch_error}")
            return pd.DataFrame()  # è¿”å›ç©ºDataFrame
    
    return filtered_get_stock_news_em


def patch_akshare_utils():
    """
    ä¸ºakshare_utilsæ¨¡å—çš„get_stock_news_emå‡½æ•°æ·»åŠ è¿‡æ»¤åŠŸèƒ½
    """
    try:
        from tradingagents.dataflows import akshare_utils
        
        # ä¿å­˜åŸå§‹å‡½æ•°
        if not hasattr(akshare_utils, '_original_get_stock_news_em'):
            akshare_utils._original_get_stock_news_em = akshare_utils.get_stock_news_em
            
            # åº”ç”¨è¿‡æ»¤è£…é¥°å™¨
            akshare_utils.get_stock_news_em = integrate_news_filtering(
                akshare_utils._original_get_stock_news_em
            )
            
            logger.info("[æ–°é—»è¿‡æ»¤é›†æˆ] âœ… æˆåŠŸä¸ºakshare_utils.get_stock_news_emæ·»åŠ è¿‡æ»¤åŠŸèƒ½")
        else:
            logger.info("[æ–°é—»è¿‡æ»¤é›†æˆ] akshare_utils.get_stock_news_emå·²ç»è¢«å¢å¼º")
            
    except Exception as e:
        logger.error(f"[æ–°é—»è¿‡æ»¤é›†æˆ] æ— æ³•å¢å¼ºakshare_utils.get_stock_news_em: {e}")


def create_filtered_realtime_news_function():
    """
    åˆ›å»ºå¢å¼ºç‰ˆçš„å®æ—¶æ–°é—»è·å–å‡½æ•°
    """
    def get_filtered_realtime_stock_news(ticker: str, curr_date: str, hours_back: int = 6, 
                                       enable_filter: bool = True, min_score: float = 30) -> str:
        """
        å¢å¼ºç‰ˆå®æ—¶æ–°é—»è·å–å‡½æ•°ï¼Œé›†æˆæ–°é—»è¿‡æ»¤
        
        Args:
            ticker: è‚¡ç¥¨ä»£ç 
            curr_date: å½“å‰æ—¥æœŸ
            hours_back: å›æº¯å°æ—¶æ•°
            enable_filter: æ˜¯å¦å¯ç”¨æ–°é—»è¿‡æ»¤
            min_score: æœ€ä½ç›¸å…³æ€§è¯„åˆ†é˜ˆå€¼
            
        Returns:
            str: æ ¼å¼åŒ–çš„æ–°é—»æŠ¥å‘Š
        """
        logger.info(f"[å¢å¼ºå®æ—¶æ–°é—»] å¼€å§‹è·å– {ticker} çš„è¿‡æ»¤æ–°é—»")
        
        try:
            # å¯¼å…¥åŸå§‹å‡½æ•°
            from tradingagents.dataflows.realtime_news_utils import get_realtime_stock_news
            
            # è°ƒç”¨åŸå§‹å‡½æ•°è·å–æ–°é—»
            original_report = get_realtime_stock_news(ticker, curr_date, hours_back)
            
            if not enable_filter:
                logger.info(f"[å¢å¼ºå®æ—¶æ–°é—»] è¿‡æ»¤åŠŸèƒ½å·²ç¦ç”¨ï¼Œè¿”å›åŸå§‹æŠ¥å‘Š")
                return original_report
            
            # å¦‚æœå¯ç”¨è¿‡æ»¤ä¸”æ˜¯Aè‚¡ï¼Œå°è¯•é‡æ–°è·å–å¹¶è¿‡æ»¤
            if any(suffix in ticker for suffix in ['.SH', '.SZ', '.SS', '.XSHE', '.XSHG']) or \
               (not '.' in ticker and ticker.isdigit()):
                
                logger.info(f"[å¢å¼ºå®æ—¶æ–°é—»] æ£€æµ‹åˆ°Aè‚¡ä»£ç ï¼Œå°è¯•ä½¿ç”¨è¿‡æ»¤ç‰ˆä¸œæ–¹è´¢å¯Œæ–°é—»")
                
                try:
                    from tradingagents.dataflows.akshare_utils import get_stock_news_em
                    
                    # æ¸…ç†è‚¡ç¥¨ä»£ç 
                    clean_ticker = ticker.replace('.SH', '').replace('.SZ', '').replace('.SS', '')\
                                    .replace('.XSHE', '').replace('.XSHG', '')
                    
                    # å…ˆè·å–åŸå§‹æ–°é—»
                    original_news_df = get_stock_news_em(clean_ticker)
                     
                    if enable_filter and not original_news_df.empty:
                         # åº”ç”¨æ–°é—»è¿‡æ»¤
                         from tradingagents.utils.news_filter import create_news_filter
                         news_filter = create_news_filter(clean_ticker)
                         filtered_news_df = news_filter.filter_news(original_news_df, min_score=min_score)
                         
                         # è®°å½•è¿‡æ»¤ç»Ÿè®¡
                         filter_stats = news_filter.get_filter_statistics(original_news_df, filtered_news_df)
                         logger.info(f"[æ–°é—»è¿‡æ»¤é›†æˆ] æ–°é—»è¿‡æ»¤å®Œæˆ:")
                         logger.info(f"  - åŸå§‹æ–°é—»: {len(original_news_df)}æ¡")
                         logger.info(f"  - è¿‡æ»¤åæ–°é—»: {len(filtered_news_df)}æ¡")
                         logger.info(f"  - è¿‡æ»¤ç‡: {filter_stats['filter_rate']:.1f}%")
                    else:
                         filtered_news_df = original_news_df
                    
                    if not filtered_news_df.empty:
                        # æ„å»ºè¿‡æ»¤åçš„æŠ¥å‘Š
                        news_count = len(filtered_news_df)
                        
                        report = f"# {ticker} è¿‡æ»¤æ–°é—»æŠ¥å‘Š\n\n"
                        report += f"ğŸ“… ç”Ÿæˆæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n"
                        report += f"ğŸ“Š è¿‡æ»¤åæ–°é—»æ€»æ•°: {news_count}æ¡\n"
                        report += f"ğŸ” è¿‡æ»¤é˜ˆå€¼: {min_score}åˆ†\n\n"
                        
                        # æ·»åŠ è¿‡æ»¤ç»Ÿè®¡ä¿¡æ¯
                        if 'final_score' in filtered_news_df.columns:
                            avg_score = filtered_news_df['final_score'].mean()
                            max_score = filtered_news_df['final_score'].max()
                            report += f"ğŸ“ˆ å¹³å‡ç›¸å…³æ€§è¯„åˆ†: {avg_score:.1f}åˆ†\n"
                            report += f"ğŸ† æœ€é«˜ç›¸å…³æ€§è¯„åˆ†: {max_score:.1f}åˆ†\n\n"
                        
                        # æ·»åŠ æ–°é—»å†…å®¹
                        for idx, (_, row) in enumerate(filtered_news_df.iterrows()):
                            report += f"### {row.get('æ–°é—»æ ‡é¢˜', 'æ— æ ‡é¢˜')}\n"
                            report += f"ğŸ“… {row.get('å‘å¸ƒæ—¶é—´', 'æ— æ—¶é—´')}\n"
                            
                            if 'final_score' in row:
                                report += f"â­ ç›¸å…³æ€§è¯„åˆ†: {row['final_score']:.1f}åˆ†\n"
                            
                            report += f"ğŸ”— {row.get('æ–°é—»é“¾æ¥', 'æ— é“¾æ¥')}\n\n"
                            report += f"{row.get('æ–°é—»å†…å®¹', 'æ— å†…å®¹')}\n\n"
                        
                        logger.info(f"[å¢å¼ºå®æ—¶æ–°é—»] âœ… æˆåŠŸç”Ÿæˆè¿‡æ»¤æ–°é—»æŠ¥å‘Šï¼ŒåŒ…å« {news_count} æ¡é«˜è´¨é‡æ–°é—»")
                        return report
                    else:
                        logger.warning(f"[å¢å¼ºå®æ—¶æ–°é—»] è¿‡æ»¤åæ— ç¬¦åˆæ¡ä»¶çš„æ–°é—»ï¼Œè¿”å›åŸå§‹æŠ¥å‘Š")
                        return original_report
                        
                except Exception as filter_error:
                    logger.error(f"[å¢å¼ºå®æ—¶æ–°é—»] æ–°é—»è¿‡æ»¤å¤±è´¥: {filter_error}")
                    return original_report
            else:
                logger.info(f"[å¢å¼ºå®æ—¶æ–°é—»] éAè‚¡ä»£ç ï¼Œè¿”å›åŸå§‹æŠ¥å‘Š")
                return original_report
                
        except Exception as e:
            logger.error(f"[å¢å¼ºå®æ—¶æ–°é—»] å¢å¼ºæ–°é—»è·å–å¤±è´¥: {e}")
            return f"âŒ æ–°é—»è·å–å¤±è´¥: {str(e)}"
    
    return get_filtered_realtime_stock_news


# è‡ªåŠ¨åº”ç”¨è¡¥ä¸
def apply_news_filtering_patches():
    """
    è‡ªåŠ¨åº”ç”¨æ–°é—»è¿‡æ»¤è¡¥ä¸
    """
    logger.info("[æ–°é—»è¿‡æ»¤é›†æˆ] å¼€å§‹åº”ç”¨æ–°é—»è¿‡æ»¤è¡¥ä¸...")
    
    # 1. å¢å¼ºakshare_utils
    patch_akshare_utils()
    
    # 2. åˆ›å»ºå¢å¼ºç‰ˆå®æ—¶æ–°é—»å‡½æ•°
    enhanced_function = create_filtered_realtime_news_function()
    
    logger.info("[æ–°é—»è¿‡æ»¤é›†æˆ] âœ… æ–°é—»è¿‡æ»¤è¡¥ä¸åº”ç”¨å®Œæˆ")
    
    return enhanced_function


if __name__ == "__main__":
    # æµ‹è¯•é›†æˆåŠŸèƒ½
    print("=== æµ‹è¯•æ–°é—»è¿‡æ»¤é›†æˆ ===")
    
    # åº”ç”¨è¡¥ä¸
    enhanced_news_function = apply_news_filtering_patches()
    
    # æµ‹è¯•å¢å¼ºç‰ˆå‡½æ•°
    test_result = enhanced_news_function(
        ticker="600036",
        curr_date="2024-07-28",
        enable_filter=True,
        min_score=30
    )
    
    print(f"æµ‹è¯•ç»“æœé•¿åº¦: {len(test_result)} å­—ç¬¦")
    print(f"æµ‹è¯•ç»“æœé¢„è§ˆ: {test_result[:200]}...")