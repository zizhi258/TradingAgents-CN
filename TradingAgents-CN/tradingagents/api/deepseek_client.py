"""
DeepSeek API å®¢æˆ·ç«¯
ä½¿ç”¨DeepSeekå®˜æ–¹APIç«¯ç‚¹
"""

import os
import time
import requests
from typing import Dict, Any, Optional
from datetime import datetime

from ..core.base_multi_model_adapter import (
    BaseMultiModelAdapter, ModelSpec, TaskSpec, TaskResult, 
    ModelProvider
)

# å¯¼å…¥ç»Ÿä¸€æ—¥å¿—ç³»ç»Ÿ
from tradingagents.utils.logging_init import get_logger
logger = get_logger('deepseek_client')


class DeepSeekClient(BaseMultiModelAdapter):
    """DeepSeekå®˜æ–¹APIå®¢æˆ·ç«¯"""
    
    # DeepSeekæ”¯æŒçš„æ¨¡å‹é…ç½®
    SUPPORTED_MODELS = {
        "deepseek-chat": {
            "type": "general",
            "cost_per_1k": 0.008,
            "max_tokens": 8192,
            "context_window": 128000,
            "description": "DeepSeek-V3-0324ï¼ŒMoE 671Bå‚æ•°ï¼Œè¶…è¶ŠGPT-4.5æ€§èƒ½"
        },
        "deepseek-reasoner": {
            "type": "reasoning",
            "cost_per_1k": 0.012,
            "max_tokens": 8192,
            "context_window": 160000,
            "description": "DeepSeek-R1-0528ï¼Œå¼ºåŒ–å­¦ä¹ æ¨ç†æ¨¡å‹ï¼Œé¡¶çº§æ€§èƒ½"
        }
    }
    
    def __init__(self, config: Dict[str, Any]):
        """
        åˆå§‹åŒ–DeepSeekå®¢æˆ·ç«¯
        
        Args:
            config: é…ç½®å­—å…¸
        """
        super().__init__(ModelProvider.OPENAI, config)  # ä½¿ç”¨OPENAIä½œä¸ºæä¾›å•†ç±»å‹ï¼Œå› ä¸ºå…¼å®¹
        
        # é…ç½®å‚æ•°
        self.base_url = config.get('base_url', 'https://api.deepseek.com')
        self.api_key = config.get('api_key') or os.getenv('DEEPSEEK_API_KEY')
        self.default_model = config.get('default_model', 'deepseek-chat')
        self.timeout = config.get('timeout', 60)
        
        if not self.api_key:
            raise ValueError("DeepSeek APIå¯†é’¥æœªé…ç½®")
            
        self.initialize_client()
        logger.info(f"âœ… DeepSeekå®¢æˆ·ç«¯åˆå§‹åŒ–æˆåŠŸï¼Œæ”¯æŒ{len(self.SUPPORTED_MODELS)}ä¸ªæ¨¡å‹")
    
    def initialize_client(self) -> None:
        """åˆå§‹åŒ–APIå®¢æˆ·ç«¯"""
        self.headers = {
            'Authorization': f'Bearer {self.api_key}',
            'Content-Type': 'application/json'
        }
        
        # åˆå§‹åŒ–æ”¯æŒçš„æ¨¡å‹è§„æ ¼
        self._supported_models = {}
        for model_name, model_info in self.SUPPORTED_MODELS.items():
            self._supported_models[model_name] = ModelSpec(
                name=model_name,
                provider=self.provider,
                model_type=model_info['type'],
                cost_per_1k_tokens=model_info['cost_per_1k'],
                max_tokens=model_info['max_tokens'],
                supports_streaming=True,
                context_window=model_info['context_window']
            )
    
    def get_supported_models(self) -> Dict[str, ModelSpec]:
        """è·å–æ”¯æŒçš„æ¨¡å‹åˆ—è¡¨"""
        return self._supported_models.copy()
    
    def execute_task(self, 
                    model_name: str,
                    prompt: str,
                    task_spec: TaskSpec,
                    **kwargs) -> TaskResult:
        """
        æ‰§è¡Œå…·ä½“ä»»åŠ¡
        
        Args:
            model_name: æ¨¡å‹åç§°
            prompt: æç¤ºè¯
            task_spec: ä»»åŠ¡è§„æ ¼
            **kwargs: å…¶ä»–å‚æ•°
            
        Returns:
            TaskResult: ä»»åŠ¡æ‰§è¡Œç»“æœ
        """
        if model_name not in self._supported_models:
            return TaskResult(
                result="",
                model_used=None,
                execution_time=0,
                actual_cost=0.0,
                token_usage={},
                success=False,
                error_message=f"ä¸æ”¯æŒçš„æ¨¡å‹: {model_name}"
            )
        
        model_spec = self._supported_models[model_name]
        start_time = time.time()
        
        try:
            # æ„å»ºè¯·æ±‚æ•°æ®
            streaming = bool(kwargs.get('stream', False))
            on_token = kwargs.get('on_token')
            request_data = {
                "model": model_name,
                "messages": [
                    {"role": "user", "content": prompt}
                ],
                "max_tokens": kwargs.get('max_tokens', model_spec.max_tokens),
                "temperature": kwargs.get('temperature', 0.7),
                "top_p": kwargs.get('top_p', 0.8),
                "stream": streaming
            }
            
            # æ ¹æ®æ¨¡å‹åŠ¨æ€è°ƒæ•´è¶…æ—¶æ—¶é—´
            model_timeout = self.timeout
            if model_name == 'deepseek-reasoner':
                # DeepSeek-R1 æ¨ç†æ¨¡å‹éœ€è¦æ›´é•¿æ—¶é—´
                model_timeout = 120  # 2åˆ†é’Ÿ
                logger.info(f"ä½¿ç”¨DeepSeekæ¨ç†æ¨¡å‹ï¼Œè¶…æ—¶æ—¶é—´è°ƒæ•´ä¸º{model_timeout}ç§’")
            
            # å‘é€APIè¯·æ±‚
            logger.info(f"ğŸ¤– è°ƒç”¨DeepSeek API: {model_name}")
            if streaming and callable(on_token):
                response = requests.post(
                    f"{self.base_url}/chat/completions",
                    headers=self.headers,
                    json=request_data,
                    timeout=model_timeout,
                    stream=True
                )

                if response.status_code != 200:
                    execution_time = int((time.time() - start_time) * 1000)
                    error_msg = f"DeepSeek APIè¯·æ±‚å¤±è´¥: {response.status_code} - {response.text}"
                    logger.error(error_msg)
                    return TaskResult(
                        result="",
                        model_used=model_spec,
                        execution_time=execution_time,
                        actual_cost=0.0,
                        token_usage={},
                        success=False,
                        error_message=error_msg
                    )

                full_text = ""
                usage = {}
                try:
                    # æ˜¾å¼æŒ‰UTF-8è§£ç SSEï¼Œé¿å…åœ¨æŸäº›ç¯å¢ƒä¸‹å‡ºç°ä¹±ç 
                    for raw_line in response.iter_lines(decode_unicode=False):
                        if not raw_line:
                            continue
                        try:
                            line = raw_line.decode('utf-8', errors='ignore').strip()
                        except Exception:
                            line = str(raw_line).strip()
                        if line.startswith("data: "):
                            line = line[6:].strip()
                        if line in ("[DONE]", "{\"event\":\"done\"}"):
                            break
                        try:
                            chunk = json.loads(line)
                        except Exception:
                            continue
                        # DeepSeekå…¼å®¹ï¼šchoices[0].delta.content
                        delta_text = ""
                        if isinstance(chunk, dict):
                            if 'choices' in chunk and chunk['choices']:
                                choice = chunk['choices'][0]
                                delta_text = (
                                    (choice.get('delta') or {}).get('content') or
                                    (choice.get('message') or {}).get('content') or
                                    ""
                                )
                            if 'usage' in chunk and not usage:
                                usage = chunk.get('usage') or {}
                        if delta_text:
                            full_text += delta_text
                            try:
                                on_token(delta_text)
                            except Exception:
                                pass
                finally:
                    execution_time = int((time.time() - start_time) * 1000)

                # è®¡ç®—æˆæœ¬/ç”¨é‡å…œåº•
                total_tokens = usage.get('total_tokens') if isinstance(usage, dict) else None
                if not total_tokens and full_text:
                    approx_in = max(1, int(len(prompt) / 2))
                    approx_out = int(len(full_text) / 2)
                    usage = {
                        'prompt_tokens': approx_in,
                        'completion_tokens': approx_out,
                        'total_tokens': approx_in + approx_out
                    }
                actual_cost = ((usage.get('total_tokens', 0)) / 1000) * model_spec.cost_per_1k_tokens if isinstance(usage, dict) else 0.0

                # æ›´æ–°æ€§èƒ½æŒ‡æ ‡
                self.update_performance_metrics(
                    model_name, task_spec.task_type, execution_time, True
                )

                logger.info(f"âœ… DeepSeek APIè°ƒç”¨æˆåŠŸ(æµå¼): {model_name}, è€—æ—¶: {execution_time}ms")
                return TaskResult(
                    result=full_text,
                    model_used=model_spec,
                    execution_time=execution_time,
                    actual_cost=actual_cost,
                    token_usage=usage if isinstance(usage, dict) else {},
                    success=True
                )
            else:
                response = requests.post(
                    f"{self.base_url}/chat/completions",
                    headers=self.headers,
                    json=request_data,
                    timeout=model_timeout
                )

                execution_time = int((time.time() - start_time) * 1000)

                if response.status_code != 200:
                    error_msg = f"DeepSeek APIè¯·æ±‚å¤±è´¥: {response.status_code} - {response.text}"
                    logger.error(error_msg)
                    return TaskResult(
                        result="",
                        model_used=model_spec,
                        execution_time=execution_time,
                        actual_cost=0.0,
                        token_usage={},
                        success=False,
                        error_message=error_msg
                    )

                response_data = response.json()

                # è§£æå“åº”
                if 'choices' not in response_data or not response_data['choices']:
                    error_msg = "DeepSeek APIè¿”å›æ ¼å¼é”™è¯¯"
                    logger.error(f"{error_msg}: {response_data}")
                    return TaskResult(
                        result="",
                        model_used=model_spec,
                        execution_time=execution_time,
                        actual_cost=0.0,
                        token_usage={},
                        success=False,
                        error_message=error_msg
                    )

                # æå–ç»“æœ
                result_text = response_data['choices'][0]['message']['content']

                # è®¡ç®—tokenä½¿ç”¨é‡å’Œæˆæœ¬
                token_usage = response_data.get('usage', {})
                input_tokens = token_usage.get('prompt_tokens', 0)
                output_tokens = token_usage.get('completion_tokens', 0)
                total_tokens = token_usage.get('total_tokens', input_tokens + output_tokens)

                # è®¡ç®—æˆæœ¬ (æŒ‰åƒtokenè®¡ç®—)
                actual_cost = (total_tokens / 1000) * model_spec.cost_per_1k_tokens

                # æ›´æ–°æ€§èƒ½æŒ‡æ ‡
                self.update_performance_metrics(
                    model_name, task_spec.task_type, execution_time, True
                )

                logger.info(f"âœ… DeepSeek APIè°ƒç”¨æˆåŠŸ: {model_name}, è€—æ—¶: {execution_time}ms, tokens: {total_tokens}")

                return TaskResult(
                    result=result_text,
                    model_used=model_spec,
                    execution_time=execution_time,
                    actual_cost=actual_cost,
                    token_usage={
                        'input_tokens': input_tokens,
                        'output_tokens': output_tokens,
                        'total_tokens': total_tokens
                    },
                    success=True
                )
                
        except requests.exceptions.Timeout:
            execution_time = int((time.time() - start_time) * 1000)
            # ä½¿ç”¨å®é™…çš„è¶…æ—¶æ—¶é—´
            actual_timeout = model_timeout if 'model_timeout' in locals() else self.timeout
            error_msg = f"DeepSeek APIè¯·æ±‚è¶…æ—¶ ({actual_timeout}s)"
            logger.error(error_msg)
            
            # æ›´æ–°æ€§èƒ½æŒ‡æ ‡
            self.update_performance_metrics(
                model_name, task_spec.task_type, execution_time, False
            )
            
            return TaskResult(
                result="",
                model_used=model_spec,
                execution_time=execution_time,
                actual_cost=0.0,
                token_usage={},
                success=False,
                error_message=error_msg
            )
            
        except Exception as e:
            execution_time = int((time.time() - start_time) * 1000)
            error_msg = f"DeepSeek APIè°ƒç”¨å¼‚å¸¸: {str(e)}"
            logger.error(error_msg, exc_info=True)
            
            # æ›´æ–°æ€§èƒ½æŒ‡æ ‡
            self.update_performance_metrics(
                model_name, task_spec.task_type, execution_time, False
            )
            
            return TaskResult(
                result="",
                model_used=model_spec,
                execution_time=execution_time,
                actual_cost=0.0,
                token_usage={},
                success=False,
                error_message=error_msg
            )
    
    def estimate_cost(self, model_name: str, estimated_tokens: int) -> float:
        """ä¼°ç®—ä»»åŠ¡æˆæœ¬"""
        if model_name not in self._supported_models:
            return 0.0
        
        model_spec = self._supported_models[model_name]
        return (estimated_tokens / 1000) * model_spec.cost_per_1k_tokens
    
    def health_check(self) -> bool:
        """å¥åº·æ£€æŸ¥ï¼Œç¡®è®¤APIå¯ç”¨æ€§"""
        try:
            # å‘é€ä¸€ä¸ªç®€å•çš„æµ‹è¯•è¯·æ±‚
            test_data = {
                "model": "deepseek-chat",
                "messages": [{"role": "user", "content": "Hello"}],
                "max_tokens": 10
            }
            
            response = requests.post(
                f"{self.base_url}/chat/completions",
                headers=self.headers,
                json=test_data,
                timeout=10
            )
            
            success = response.status_code == 200
            if success:
                logger.info("âœ… DeepSeek APIå¥åº·æ£€æŸ¥é€šè¿‡")
            else:
                logger.warning(f"âš ï¸ DeepSeek APIå¥åº·æ£€æŸ¥å¤±è´¥: {response.status_code}")
            
            return success
            
        except Exception as e:
            logger.error(f"âŒ DeepSeek APIå¥åº·æ£€æŸ¥å¼‚å¸¸: {e}")
            return False
