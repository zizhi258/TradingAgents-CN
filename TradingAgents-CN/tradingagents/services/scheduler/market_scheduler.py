#!/usr/bin/env python3
"""
å¸‚åœºæ”¶å¸‚è°ƒåº¦å™¨
æ ¹æ®ä¸åŒäº¤æ˜“æ‰€çš„æ”¶å¸‚æ—¶é—´è‡ªåŠ¨è§¦å‘ç ”æŠ¥ç”Ÿæˆå’Œå‘é€
æ”¯æŒæ¯æ—¥å’Œæ¯å‘¨å®šæ—¶ä»»åŠ¡
"""

import os
import json
import glob
from datetime import datetime, time
from typing import Dict, List, Optional, Callable, Any
import pytz
from apscheduler.schedulers.background import BackgroundScheduler
from apscheduler.triggers.cron import CronTrigger
from apscheduler.events import EVENT_JOB_ERROR, EVENT_JOB_EXECUTED
from pathlib import Path

from tradingagents.utils.logging_manager import get_logger
from tradingagents.config.config_manager import ConfigManager

logger = get_logger('scheduler')


class MarketScheduler:
    """å¸‚åœºæ”¶å¸‚è°ƒåº¦å™¨"""
    
    # å„äº¤æ˜“æ‰€æ”¶å¸‚æ—¶é—´é…ç½®
    MARKET_CLOSE_TIMES = {
        'Aè‚¡': {
            'timezone': 'Asia/Shanghai',
            'close_time': time(15, 5),  # 15:05 æ”¶å¸‚å5åˆ†é’Ÿ
            'trading_days': 'mon-fri',   # å‘¨ä¸€åˆ°å‘¨äº”
            'exchanges': ['SH', 'SZ'],
            'name_cn': 'Aè‚¡å¸‚åœº'
        },
        'æ¸¯è‚¡': {
            'timezone': 'Asia/Hong_Kong', 
            'close_time': time(16, 10),  # 16:10 æ”¶å¸‚å10åˆ†é’Ÿ
            'trading_days': 'mon-fri',
            'exchanges': ['HK'],
            'name_cn': 'æ¸¯è‚¡å¸‚åœº'
        },
        'ç¾è‚¡': {
            'timezone': 'America/New_York',
            'close_time': time(16, 5),   # 16:05 æ”¶å¸‚å5åˆ†é’Ÿ
            'trading_days': 'mon-fri',
            'exchanges': ['NYSE', 'NASDAQ'],
            'name_cn': 'ç¾è‚¡å¸‚åœº'
        }
    }
    
    def __init__(self):
        """åˆå§‹åŒ–è°ƒåº¦å™¨"""
        self.scheduler = BackgroundScheduler()
        self.config_manager = ConfigManager()
        self._subscription_manager = None
        self._email_sender = None
        self._analysis_runner = None
        self._running = False
        
        # é…ç½®è°ƒåº¦å™¨ç›‘å¬å™¨
        self.scheduler.add_listener(
            self._job_listener,
            EVENT_JOB_ERROR | EVENT_JOB_EXECUTED
        )
        
    @property
    def subscription_manager(self):
        """å»¶è¿ŸåŠ è½½è®¢é˜…ç®¡ç†å™¨ï¼Œé¿å…å¾ªç¯ä¾èµ–"""
        if self._subscription_manager is None:
            from tradingagents.services.subscription.subscription_manager import SubscriptionManager
            self._subscription_manager = SubscriptionManager()
        return self._subscription_manager
        
    @property
    def email_sender(self):
        """å»¶è¿ŸåŠ è½½é‚®ä»¶å‘é€å™¨"""
        if self._email_sender is None:
            from tradingagents.services.mailer.email_sender import EmailSender
            self._email_sender = EmailSender()
        return self._email_sender
        
    @property
    def analysis_runner(self):
        """å»¶è¿ŸåŠ è½½åˆ†æè¿è¡Œå™¨"""
        if self._analysis_runner is None:
            from tradingagents.web.utils.analysis_runner import run_stock_analysis
            self._analysis_runner = run_stock_analysis
        return self._analysis_runner
        
    def start(self):
        """å¯åŠ¨è°ƒåº¦å™¨"""
        if self._running:
            logger.warning("è°ƒåº¦å™¨å·²ç»åœ¨è¿è¡Œä¸­")
            return
            
        logger.info("ğŸ“… æ­£åœ¨å¯åŠ¨å¸‚åœºæ”¶å¸‚è°ƒåº¦å™¨...")
        
        # æ£€æŸ¥æ˜¯å¦å¯ç”¨è°ƒåº¦åŠŸèƒ½
        if not os.getenv('SCHEDULER_ENABLED', 'false').lower() == 'true':
            logger.warning("âš ï¸ è°ƒåº¦åŠŸèƒ½æœªå¯ç”¨ï¼Œè¯·åœ¨.envä¸­è®¾ç½® SCHEDULER_ENABLED=true")
            return
            
        # ä¸ºæ¯ä¸ªå¸‚åœºæ·»åŠ æ”¶å¸‚ä»»åŠ¡
        for market_type, config in self.MARKET_CLOSE_TIMES.items():
            self._add_market_job(market_type, config)
            
        # å¯åŠ¨è°ƒåº¦å™¨
        self.scheduler.start()
        self._running = True
        
        # åŠ è½½Emailè°ƒåº¦ä»»åŠ¡
        self.refresh_jobs_from_settings()
        
        logger.info("âœ… å¸‚åœºæ”¶å¸‚è°ƒåº¦å™¨å¯åŠ¨æˆåŠŸ")
        self._log_scheduled_jobs()
        
    def stop(self):
        """åœæ­¢è°ƒåº¦å™¨"""
        if not self._running:
            return
            
        logger.info("â¹ï¸ æ­£åœ¨åœæ­¢è°ƒåº¦å™¨...")
        self.scheduler.shutdown()
        self._running = False
        logger.info("âœ… è°ƒåº¦å™¨å·²åœæ­¢")
        
    def _add_market_job(self, market_type: str, config: Dict):
        """æ·»åŠ å¸‚åœºæ”¶å¸‚ä»»åŠ¡"""
        try:
            trigger = CronTrigger(
                hour=config['close_time'].hour,
                minute=config['close_time'].minute,
                day_of_week=config['trading_days'],
                timezone=config['timezone']
            )
            
            job_id = f'close_report_{market_type}'
            job_name = f'{config["name_cn"]}æ”¶å¸‚æŠ¥å‘Š'
            
            self.scheduler.add_job(
                func=self._run_close_report,
                trigger=trigger,
                args=[market_type, config],
                id=job_id,
                name=job_name,
                replace_existing=True
            )
            
            logger.info(f"âœ… æ·»åŠ å®šæ—¶ä»»åŠ¡: {job_name} "
                       f"({config['timezone']} {config['close_time']})")
                       
        except Exception as e:
            logger.error(f"âŒ æ·»åŠ {market_type}ä»»åŠ¡å¤±è´¥: {e}")
            
    def _run_close_report(self, market_type: str, config: Dict):
        """æ‰§è¡Œæ”¶å¸‚æŠ¥å‘Šä»»åŠ¡"""
        start_time = datetime.now()
        logger.info(f"ğŸ”” {config['name_cn']}æ”¶å¸‚ï¼Œå¼€å§‹ç”Ÿæˆåˆ†ææŠ¥å‘Š...")
        
        try:
            # è·å–è¯¥å¸‚åœºçš„è®¢é˜…åˆ—è¡¨
            subscriptions = self.subscription_manager.get_subscriptions_by_market(
                config['exchanges']
            )
            
            if not subscriptions:
                logger.info(f"ğŸ“­ {market_type}æš‚æ— è®¢é˜…")
                return
                
            logger.info(f"ğŸ“‹ æ‰¾åˆ° {len(subscriptions)} ä¸ªè®¢é˜…")
            
            # æŒ‰è‚¡ç¥¨åˆ†ç»„ï¼Œé¿å…é‡å¤åˆ†æ
            stock_groups = self._group_subscriptions_by_stock(subscriptions)
            
            # æ‰¹é‡åˆ†æ
            analysis_results = {}
            for symbol, subs in stock_groups.items():
                try:
                    logger.info(f"ğŸ“Š æ­£åœ¨åˆ†æ {symbol}...")
                    result = self._analyze_stock(symbol, subs[0]['market_type'])
                    analysis_results[symbol] = result
                    
                except Exception as e:
                    logger.error(f"âŒ åˆ†æ{symbol}å¤±è´¥: {e}")
                    
            # å‘é€é‚®ä»¶
            self._send_batch_emails(stock_groups, analysis_results)

            # åŒæ­¥å‘é€å¸‚åœºæ‘˜è¦ç»™å¸‚åœºçº§è®¢é˜…
            try:
                market_subs = self.subscription_manager.get_market_subscriptions(scope=market_type, frequency_filter=['close'])
                if market_subs:
                    logger.info(f"ğŸ“¬ ä¸ºå¸‚åœºæ‘˜è¦è®¢é˜…å‘é€ {market_type} æ”¶å¸‚æ‘˜è¦: {len(market_subs)} ä¸ªè®¢é˜…")
                    self._send_market_digest(scope=market_type, subscriptions=market_subs, mode='close')
                else:
                    logger.info(f"ğŸ“­ {market_type} æ— å¸‚åœºæ‘˜è¦è®¢é˜…")
            except Exception as e:
                logger.error(f"âŒ å‘é€{market_type}å¸‚åœºæ‘˜è¦å¤±è´¥: {e}")

            # å‘é€è¯¥å¸‚åœºç›¸å…³çš„æŒ‡æ•°è®¢é˜…ï¼ˆæ”¶å¸‚é¢‘ç‡ï¼‰
            try:
                index_subs = self.subscription_manager.get_index_subscriptions(market=market_type, frequency_filter=['close'])
                if index_subs:
                    self._send_index_digests(index_subs, mode='close')
                else:
                    logger.info(f"ğŸ“­ {market_type} æ— æŒ‡æ•°è®¢é˜…éœ€è¦å‘é€ï¼ˆæ”¶å¸‚ï¼‰")
            except Exception as e:
                logger.error(f"âŒ å‘é€{market_type}æŒ‡æ•°æ‘˜è¦å¤±è´¥: {e}")
            
            # è®°å½•å®Œæˆæ—¶é—´
            elapsed = (datetime.now() - start_time).total_seconds()
            logger.info(f"âœ… {config['name_cn']}æ”¶å¸‚æŠ¥å‘Šå®Œæˆï¼Œè€—æ—¶ {elapsed:.1f}ç§’")
            
        except Exception as e:
            logger.error(f"âŒ æ‰§è¡Œ{market_type}æ”¶å¸‚æŠ¥å‘Šå¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
            
    def _group_subscriptions_by_stock(self, subscriptions: List[Dict]) -> Dict[str, List[Dict]]:
        """æŒ‰è‚¡ç¥¨ä»£ç åˆ†ç»„è®¢é˜…"""
        groups = {}
        for sub in subscriptions:
            symbol = sub['symbol']
            if symbol not in groups:
                groups[symbol] = []
            groups[symbol].append(sub)
        return groups
        
    def _analyze_stock(self, symbol: str, market_type: str) -> Dict:
        """åˆ†æå•åªè‚¡ç¥¨"""
        # ä½¿ç”¨å¿«é€Ÿåˆ†æé…ç½®
        analysis_date = datetime.now().strftime('%Y-%m-%d')
        
        # é…ç½®å¿«é€Ÿåˆ†æå‚æ•°
        config = {
            'selected_analysts': ['market', 'fundamentals'],  # åªç”¨å…³é”®åˆ†æå¸ˆ
            'research_depth': 2,  # åŸºç¡€æ·±åº¦
            'llm_provider': os.getenv('LLM_PROVIDER', 'dashscope'),
            'llm_model': os.getenv('QUICK_THINK_LLM', 'qwen-turbo')
        }
        
        # æ‰§è¡Œåˆ†æ
        state, decision = self.analysis_runner(
            stock_symbol=symbol,
            analysis_date=analysis_date,
            analysts=config['selected_analysts'],
            research_depth=config['research_depth'],
            llm_provider=config['llm_provider'],
            llm_model=config['llm_model'],
            market_type=market_type
        )
        
        return {
            'symbol': symbol,
            'analysis_date': analysis_date,
            'decision': decision,
            'state': state,
            'market_type': market_type
        }
        
    def _send_batch_emails(self, stock_groups: Dict, analysis_results: Dict):
        """æ‰¹é‡å‘é€é‚®ä»¶"""
        for symbol, subscriptions in stock_groups.items():
            if symbol not in analysis_results:
                continue
                
            result = analysis_results[symbol]
            
            # æŒ‰é™„ä»¶é…ç½®åˆ†ç»„é‚®ä»¶ï¼Œé¿å…é‡å¤ç”Ÿæˆé™„ä»¶
            attachment_groups = {}
            for sub in subscriptions:
                attachment_config = sub.get('attachment_config', {})
                # å°†é…ç½®è½¬æ¢ä¸ºå­—ç¬¦ä¸²ä½œä¸ºåˆ†ç»„key
                config_key = str(sorted(attachment_config.items()))
                if config_key not in attachment_groups:
                    attachment_groups[config_key] = {
                        'emails': [],
                        'config': attachment_config
                    }
                attachment_groups[config_key]['emails'].append(sub['email'])
            
            # ä¸ºæ¯ä¸ªé™„ä»¶é…ç½®ç»„å‘é€é‚®ä»¶
            for config_key, group in attachment_groups.items():
                emails = group['emails']
                attachment_config = group['config']
                
                try:
                    # ç”Ÿæˆé™„ä»¶åˆ—è¡¨
                    attachments = self._generate_attachments(result, symbol, attachment_config)
                    
                    self.email_sender.send_analysis_report(
                        recipients=emails,
                        stock_symbol=symbol,
                        analysis_result=result,
                        attachments=attachments
                    )
                    
                    attachment_info = f"ï¼ˆé™„ä»¶ï¼š{', '.join([att['filename'] for att in attachments])}ï¼‰" if attachments else "ï¼ˆæ— é™„ä»¶ï¼‰"
                    logger.info(f"âœ‰ï¸ å·²å‘é€ {symbol} æŠ¥å‘Šè‡³ {len(emails)} ä¸ªé‚®ç®± {attachment_info}")
                    
                except Exception as e:
                    logger.error(f"âŒ å‘é€{symbol}é‚®ä»¶å¤±è´¥: {e}")
    
    def _generate_attachments(self, analysis_result: Dict, symbol: str, attachment_config: Dict) -> List[Dict]:
        """æ ¹æ®é…ç½®ç”Ÿæˆé™„ä»¶åˆ—è¡¨
        
        Args:
            analysis_result: åˆ†æç»“æœ
            symbol: è‚¡ç¥¨ä»£ç 
            attachment_config: é™„ä»¶é…ç½®
            
        Returns:
            é™„ä»¶åˆ—è¡¨
        """
        attachments = []
        
        if not attachment_config:
            return attachments
            
        try:
            # PDFæŠ¥å‘Š
            if attachment_config.get('pdf_report', False):
                attachments.append({
                    'type': 'report',
                    'format': 'pdf',
                    'filename': f'{symbol}_è‚¡ç¥¨åˆ†ææŠ¥å‘Š_{analysis_result.get("analysis_date", "")}.pdf',
                    'analysis_result': analysis_result,
                    'stock_symbol': symbol
                })
            
            # WordæŠ¥å‘Š  
            if attachment_config.get('word_report', False):
                attachments.append({
                    'type': 'report',
                    'format': 'docx',
                    'filename': f'{symbol}_è‚¡ç¥¨åˆ†ææŠ¥å‘Š_{analysis_result.get("analysis_date", "")}.docx',
                    'analysis_result': analysis_result,
                    'stock_symbol': symbol
                })
                
            # MarkdownæŠ¥å‘Š
            if attachment_config.get('markdown_report', False):
                attachments.append({
                    'type': 'report',
                    'format': 'md',
                    'filename': f'{symbol}_è‚¡ç¥¨åˆ†ææŠ¥å‘Š_{analysis_result.get("analysis_date", "")}.md',
                    'analysis_result': analysis_result,
                    'stock_symbol': symbol
                })
            
            # å…¶ä»–é™„ä»¶ç±»å‹å¯ä»¥åœ¨è¿™é‡Œæ‰©å±•
            # ä¾‹å¦‚ï¼šæŠ€æœ¯å›¾è¡¨ã€æ•°æ®Excelç­‰
            
        except Exception as e:
            logger.error(f"âŒ ç”Ÿæˆ{symbol}é™„ä»¶å¤±è´¥: {e}")
            
        return attachments

    # === å¸‚åœºæ‘˜è¦æ”¯æŒ ===
    def _send_market_digest(self, scope: str, subscriptions: List[Dict], mode: str = 'daily'):
        """å‘é€å¸‚åœºæ‘˜è¦é‚®ä»¶ï¼ˆæŒ‰èŒƒå›´èšåˆï¼‰"""
        if not subscriptions:
            return

        try:
            # èšåˆé‚®ä»¶åˆ—è¡¨ï¼ˆä¸åŒºåˆ†é™„ä»¶é…ç½®ï¼Œæ‘˜è¦é»˜è®¤æ— é™„ä»¶ï¼‰
            recipients = list({sub['email'] for sub in subscriptions})
            digest = self._generate_market_digest(scope)
            subject_symbol = f"MARKET-{scope}"
            self.email_sender.send_analysis_report(
                recipients=recipients,
                stock_symbol=subject_symbol,
                analysis_result=digest,
                attachments=None
            )
            logger.info(f"âœ‰ï¸ å·²å‘é€{scope}å¸‚åœºæ‘˜è¦è‡³ {len(recipients)} ä¸ªé‚®ç®±")
        except Exception as e:
            logger.error(f"âŒ å‘é€{scope}å¸‚åœºæ‘˜è¦å¤±è´¥: {e}")

    def _generate_market_digest(self, scope: str) -> Dict:
        """åŸºäºæœ€è¿‘çš„å¸‚åœºæ‰«æç»“æœç”Ÿæˆæ‘˜è¦å†…å®¹ã€‚

        ä¼˜å…ˆä½¿ç”¨ data/market_sessions/results ä¸‹çš„æœ€è¿‘ç»“æœï¼›è‹¥ä¸å¯ç”¨ï¼Œåˆ™æä¾›ç®€è¦å ä½å†…å®¹ã€‚
        """
        from pathlib import Path
        import json
        now_date = datetime.now().strftime('%Y-%m-%d')

        results_dir = Path(__file__).parent.parent.parent.parent / 'data' / 'market_sessions' / 'results'
        best_file = None
        best_mtime = None

        # æ˜ å°„èŒƒå›´åˆ°ç»“æœæ–‡ä»¶å†…å¯èƒ½çš„æç¤ºï¼ˆæ–‡ä»¶å†…å®¹é€šå¸¸å«â€œæ‰«æå®Œæˆï¼šå…±è¯„ä¼°â€ + å¸‚åœºåï¼‰
        # æˆ‘ä»¬é€šè¿‡æ–‡ä»¶å†…å®¹ summary.key_insights çš„é¦–é¡¹æ˜¯å¦åŒ…å«å¯¹åº”å¸‚åœºå­—æ ·æ¥ç²—åŒ¹é…
        def file_matches_scope(payload: Dict) -> bool:
            try:
                res = payload.get('results') or payload
                summary = res.get('summary', {})
                insights = summary.get('key_insights', [])
                text = '\n'.join(insights)
                if scope == 'å…¨çƒ':
                    return True  # å…¨å±€ä¸é™åˆ¶
                return scope in text
            except Exception:
                return False

        if results_dir.exists():
            for p in results_dir.glob('*.json'):
                try:
                    stat = p.stat()
                    with open(p, 'r', encoding='utf-8') as f:
                        data = json.load(f)
                    if file_matches_scope(data):
                        if (best_mtime is None) or (stat.st_mtime > best_mtime):
                            best_file = p
                            best_mtime = stat.st_mtime
                except Exception:
                    continue

        if best_file is not None:
            try:
                with open(best_file, 'r', encoding='utf-8') as f:
                    data = json.load(f)
                res = data.get('results') or data
                summary = res.get('summary', {})
                key_insights = summary.get('key_insights', [])
                # ç»„è£…ç®€è¦åˆ†æ
                reasoning = '\n'.join(f"- {item}" for item in key_insights[:6]) or f"{scope} å¸‚åœºæ‘˜è¦"
                decision = {
                    'action': 'DIGEST',
                    'confidence': 0.0,
                    'risk_score': 0.0,
                    'reasoning': reasoning
                }
                return {
                    'analysis_date': now_date,
                    'decision': decision,
                    'full_analysis': json.dumps(summary, ensure_ascii=False, indent=2)
                }
            except Exception:
                pass

        # é€€åŒ–ï¼šæ— æ‰«æç»“æœï¼Œè¾“å‡ºå ä½æ‘˜è¦
        reasoning = f"{scope} å¸‚åœºæ‘˜è¦ï¼š\n- æœ¬æ¬¡æœªæ‰¾åˆ°å¯ç”¨çš„æ‰«æç»“æœæ•°æ®\n- è¯·åœ¨Webç•Œé¢æ‰§è¡Œä¸€æ¬¡â€˜å…¨çƒå¸‚åœºåˆ†æâ€™ä»¥ç”Ÿæˆæ‘˜è¦æ•°æ®"
        return {
            'analysis_date': now_date,
            'decision': {
                'action': 'DIGEST',
                'confidence': 0.0,
                'risk_score': 0.0,
                'reasoning': reasoning
            },
            'full_analysis': reasoning
        }

    # === æŒ‡æ•°æ‘˜è¦æ”¯æŒ ===
    def _send_index_digests(self, subscriptions: List[Dict], mode: str = 'daily'):
        """åˆ†ç»„å¹¶å‘é€æŒ‡æ•°è®¢é˜…æ‘˜è¦ã€‚"""
        if not subscriptions:
            return
        # æŒ‰æŒ‡æ•°ä»£ç åˆ†ç»„
        groups: Dict[str, Dict[str, Any]] = {}
        for sub in subscriptions:
            code = (sub.get('symbol') or '').upper()
            name = sub.get('index_name') or None
            if code not in groups:
                groups[code] = {'name': name, 'subs': []}
            groups[code]['subs'].append(sub)

        for code, info in groups.items():
            try:
                name = info.get('name')
                digest = self._generate_index_digest(code, name)
                recipients = list({s['email'] for s in info['subs']})
                subject_symbol = f"{name}({code})" if name else f"INDEX-{code}"
                self.email_sender.send_analysis_report(
                    recipients=recipients,
                    stock_symbol=subject_symbol,
                    analysis_result=digest,
                    attachments=None
                )
                logger.info(f"âœ‰ï¸ å·²å‘é€æŒ‡æ•°æ‘˜è¦ {subject_symbol} è‡³ {len(recipients)} ä¸ªé‚®ç®±")
            except Exception as e:
                logger.error(f"âŒ å‘é€æŒ‡æ•°æ‘˜è¦å¤±è´¥: {code}: {e}")

    def _generate_index_digest(self, index_code: str, index_name: Optional[str] = None) -> Dict:
        """ç”ŸæˆæŒ‡æ•°æ‘˜è¦å†…å®¹ã€‚å°½é‡æŸ¥è¯¢å½“æ—¥æ¶¨è·Œä¸æƒé‡å‰åˆ—æˆåˆ†ï¼›å¤±è´¥åˆ™é€€åŒ–ä¸ºå ä½æ‘˜è¦ã€‚"""
        from datetime import datetime as _dt, timedelta as _td
        now_date = _dt.now().strftime('%Y-%m-%d')
        reasoning_parts: List[str] = []
        last_text = None
        try:
            # ä½¿ç”¨Tushareï¼ˆè‹¥å¯ç”¨ï¼‰æŸ¥è¯¢è¿‘5ä¸ªäº¤æ˜“æ—¥ï¼Œå–æœ€æ–°ä¸€æ—¥
            try:
                from tradingagents.dataflows.tushare_utils import get_tushare_provider
                prov = get_tushare_provider()
                api = getattr(prov, 'api', None)
            except Exception:
                api = None

            if api is not None:
                start = (_dt.now() - _td(days=14)).strftime('%Y%m%d')
                end = _dt.now().strftime('%Y%m%d')
                try:
                    df = api.index_daily(ts_code=index_code, start_date=start, end_date=end)
                    if df is not None and hasattr(df, 'empty') and not df.empty:
                        df = df.sort_values('trade_date')
                        row = df.iloc[-1]
                        close_v = float(row.get('close', 0.0))
                        pct = float(row.get('pct_chg', 0.0))
                        last_text = f"æ”¶ç›˜ {close_v:.2f}ï¼Œæ¶¨è·Œå¹… {pct:+.2f}%"
                        reasoning_parts.append(f"- æœ€æ–°ï¼š{last_text}")
                except Exception:
                    pass

                # è¯»å–å½“æœˆæˆåˆ†æƒé‡
                try:
                    month = _dt.now().strftime('%Y%m')
                    w = api.index_weight(index_code=index_code, trade_date=month)
                    if w is not None and hasattr(w, 'empty') and not w.empty:
                        w = w.sort_values('weight', ascending=False)
                        top = w.head(10)
                        items = [f"{it.get('con_name', it.get('con_code'))}:{float(it.get('weight', 0.0)):.2f}%" for it in top.to_dict('records')]
                        reasoning_parts.append("- å‰åå¤§æƒé‡ï¼š" + ", ".join(items))
                except Exception:
                    pass

        except Exception as e:
            logger.error(f"æŒ‡æ•°æ‘˜è¦ç”Ÿæˆå¤±è´¥: {index_code}: {e}")

        title = index_name or index_code
        if not reasoning_parts:
            reasoning_parts = [f"- {title} æŒ‡æ•°æ‘˜è¦ï¼šæš‚æ— æ•°æ®æºï¼Œç¨åé‡è¯•"]

        return {
            'analysis_date': now_date,
            'decision': {
                'action': 'INDEX_DIGEST',
                'confidence': 0.0,
                'risk_score': 0.0,
                'reasoning': "\n".join(reasoning_parts)
            },
            'full_analysis': "\n".join(reasoning_parts)
        }
                
    def _job_listener(self, event):
        """ç›‘å¬ä»»åŠ¡æ‰§è¡Œäº‹ä»¶"""
        if event.exception:
            logger.error(f"âŒ ä»»åŠ¡æ‰§è¡Œå¤±è´¥: {event.job_id}")
            logger.error(f"é”™è¯¯ä¿¡æ¯: {event.exception}")
        else:
            logger.debug(f"âœ… ä»»åŠ¡æ‰§è¡ŒæˆåŠŸ: {event.job_id}")
            
    def _log_scheduled_jobs(self):
        """è®°å½•å·²è°ƒåº¦çš„ä»»åŠ¡"""
        jobs = self.scheduler.get_jobs()
        if jobs:
            logger.info("ğŸ“‹ å·²è°ƒåº¦çš„ä»»åŠ¡:")
            for job in jobs:
                logger.info(f"  - {job.name}: {job.next_run_time}")
        else:
            logger.info("ğŸ“‹ æš‚æ— è°ƒåº¦ä»»åŠ¡")
            
    def add_custom_job(self, 
                      job_id: str,
                      func: Callable,
                      trigger: str = 'interval',
                      **trigger_args):
        """æ·»åŠ è‡ªå®šä¹‰ä»»åŠ¡
        
        Args:
            job_id: ä»»åŠ¡ID
            func: è¦æ‰§è¡Œçš„å‡½æ•°
            trigger: è§¦å‘å™¨ç±»å‹ ('interval', 'cron', 'date')
            **trigger_args: è§¦å‘å™¨å‚æ•°
        """
        self.scheduler.add_job(
            func=func,
            trigger=trigger,
            id=job_id,
            replace_existing=True,
            **trigger_args
        )
        logger.info(f"âœ… æ·»åŠ è‡ªå®šä¹‰ä»»åŠ¡: {job_id}")
        
    def remove_job(self, job_id: str):
        """ç§»é™¤ä»»åŠ¡"""
        try:
            self.scheduler.remove_job(job_id)
            logger.info(f"âœ… å·²ç§»é™¤ä»»åŠ¡: {job_id}")
        except Exception as e:
            logger.error(f"âŒ ç§»é™¤ä»»åŠ¡å¤±è´¥: {e}")
            
    def get_job_status(self, job_id: str) -> Optional[Dict]:
        """è·å–ä»»åŠ¡çŠ¶æ€"""
        job = self.scheduler.get_job(job_id)
        if job:
            return {
                'id': job.id,
                'name': job.name,
                'next_run': job.next_run_time,
                'pending': job.pending
            }
        return None
        
    @property
    def is_running(self) -> bool:
        """è°ƒåº¦å™¨æ˜¯å¦æ­£åœ¨è¿è¡Œ"""
        return self._running
    
    def refresh_jobs_from_settings(self):
        """ä»è®¾ç½®ä¸­åˆ·æ–°emailè°ƒåº¦ä»»åŠ¡"""
        try:
            settings = self.config_manager.load_settings()
            email_schedules = settings.get('email_schedules', {})
            
            # ç§»é™¤ç°æœ‰çš„digestä»»åŠ¡
            self._remove_digest_jobs()
            
            # æ·»åŠ æ¯æ—¥ä»»åŠ¡
            daily_config = email_schedules.get('daily', {})
            if daily_config.get('enabled', False):
                self._add_daily_digest_job(daily_config)
            
            # æ·»åŠ æ¯å‘¨ä»»åŠ¡
            weekly_config = email_schedules.get('weekly', {})
            if weekly_config.get('enabled', False):
                self._add_weekly_digest_job(weekly_config)
                
            # æ·»åŠ è§¦å‘å™¨ç›‘æ§ä»»åŠ¡
            self._add_trigger_watcher_job()
                
            logger.info("âœ… é‚®ä»¶è°ƒåº¦ä»»åŠ¡å·²ä»è®¾ç½®ä¸­åˆ·æ–°")
            
        except Exception as e:
            logger.error(f"âŒ åˆ·æ–°é‚®ä»¶è°ƒåº¦ä»»åŠ¡å¤±è´¥: {e}")
    
    def _remove_digest_jobs(self):
        """ç§»é™¤digestç›¸å…³ä»»åŠ¡"""
        digest_job_ids = ['daily_digest', 'weekly_digest', 'trigger_watcher']
        for job_id in digest_job_ids:
            try:
                self.scheduler.remove_job(job_id)
            except:
                pass  # ä»»åŠ¡ä¸å­˜åœ¨æ—¶å¿½ç•¥
    
    def _add_daily_digest_job(self, daily_config: Dict):
        """æ·»åŠ æ¯æ—¥æ‘˜è¦ä»»åŠ¡"""
        try:
            timezone = os.getenv('SCHEDULER_TIMEZONE', 'Asia/Shanghai')
            hour = daily_config.get('hour', 18)
            minute = daily_config.get('minute', 0)
            
            trigger = CronTrigger(
                hour=hour,
                minute=minute,
                timezone=timezone
            )
            
            self.scheduler.add_job(
                func=self._run_digest_report,
                trigger=trigger,
                args=['daily'],
                id='daily_digest',
                name='æ¯æ—¥é‚®ä»¶æ‘˜è¦',
                replace_existing=True
            )
            
            logger.info(f"âœ… æ·»åŠ æ¯æ—¥æ‘˜è¦ä»»åŠ¡: {hour:02d}:{minute:02d} ({timezone})")
            
        except Exception as e:
            logger.error(f"âŒ æ·»åŠ æ¯æ—¥æ‘˜è¦ä»»åŠ¡å¤±è´¥: {e}")
    
    def _add_weekly_digest_job(self, weekly_config: Dict):
        """æ·»åŠ æ¯å‘¨æ‘˜è¦ä»»åŠ¡"""
        try:
            timezone = os.getenv('SCHEDULER_TIMEZONE', 'Asia/Shanghai')
            hour = weekly_config.get('hour', 9)
            minute = weekly_config.get('minute', 0)
            weekdays = weekly_config.get('weekday', [1])  # é»˜è®¤å‘¨ä¸€
            
            # è½¬æ¢weekdayæ ¼å¼ (APScheduler uses 0=Monday, 6=Sunday)
            if isinstance(weekdays, int):
                weekdays = [weekdays]
            
            # ç¡®ä¿weekdayåœ¨æœ‰æ•ˆèŒƒå›´å†…
            valid_weekdays = [w for w in weekdays if 0 <= w <= 6]
            if not valid_weekdays:
                valid_weekdays = [0]  # é»˜è®¤å‘¨ä¸€
            
            trigger = CronTrigger(
                hour=hour,
                minute=minute,
                day_of_week=','.join(map(str, valid_weekdays)),
                timezone=timezone
            )
            
            self.scheduler.add_job(
                func=self._run_digest_report,
                trigger=trigger,
                args=['weekly'],
                id='weekly_digest',
                name='æ¯å‘¨é‚®ä»¶æ‘˜è¦',
                replace_existing=True
            )
            
            weekday_names = ['å‘¨ä¸€', 'å‘¨äºŒ', 'å‘¨ä¸‰', 'å‘¨å››', 'å‘¨äº”', 'å‘¨å…­', 'å‘¨æ—¥']
            weekday_str = ','.join([weekday_names[w] for w in valid_weekdays])
            logger.info(f"âœ… æ·»åŠ æ¯å‘¨æ‘˜è¦ä»»åŠ¡: {weekday_str} {hour:02d}:{minute:02d} ({timezone})")
            
        except Exception as e:
            logger.error(f"âŒ æ·»åŠ æ¯å‘¨æ‘˜è¦ä»»åŠ¡å¤±è´¥: {e}")
    
    def _add_trigger_watcher_job(self):
        """æ·»åŠ è§¦å‘å™¨æ–‡ä»¶ç›‘æ§ä»»åŠ¡"""
        try:
            # æ¯30ç§’æ£€æŸ¥ä¸€æ¬¡è§¦å‘å™¨æ–‡ä»¶
            self.scheduler.add_job(
                func=self._check_trigger_files,
                trigger='interval',
                seconds=30,
                id='trigger_watcher',
                name='è§¦å‘å™¨æ–‡ä»¶ç›‘æ§',
                replace_existing=True
            )
            
            logger.info("âœ… æ·»åŠ è§¦å‘å™¨æ–‡ä»¶ç›‘æ§ä»»åŠ¡")
            
        except Exception as e:
            logger.error(f"âŒ æ·»åŠ è§¦å‘å™¨æ–‡ä»¶ç›‘æ§ä»»åŠ¡å¤±è´¥: {e}")
    
    def _check_trigger_files(self):
        """æ£€æŸ¥å¹¶å¤„ç†è§¦å‘å™¨æ–‡ä»¶"""
        try:
            # è·å–é¡¹ç›®æ ¹ç›®å½•ä¸‹çš„data/triggersç›®å½•
            project_root = Path(__file__).parent.parent.parent.parent
            trigger_dir = project_root / "data" / "triggers"
            
            if not trigger_dir.exists():
                return
            
            # æŸ¥æ‰¾æ‰€æœ‰è§¦å‘å™¨æ–‡ä»¶
            trigger_files = list(trigger_dir.glob("*.json"))
            
            for trigger_file in trigger_files:
                try:
                    with open(trigger_file, 'r', encoding='utf-8') as f:
                        trigger_data = json.load(f)
                    
                    # è§£æè§¦å‘å™¨ç±»å‹
                    trigger_type = trigger_data.get('type', 'manual')
                    
                    if trigger_type in ['daily', 'weekly', 'manual']:
                        logger.info(f"ğŸ”” å¤„ç†è§¦å‘å™¨: {trigger_file.name} (ç±»å‹: {trigger_type})")
                        self._run_digest_report(trigger_type, trigger_data)
                    
                    # å¤„ç†å®Œæˆååˆ é™¤è§¦å‘å™¨æ–‡ä»¶
                    trigger_file.unlink()
                    
                except Exception as e:
                    logger.error(f"âŒ å¤„ç†è§¦å‘å™¨æ–‡ä»¶ {trigger_file.name} å¤±è´¥: {e}")
                    # åˆ é™¤æŸåçš„è§¦å‘å™¨æ–‡ä»¶
                    try:
                        trigger_file.unlink()
                    except:
                        pass
                        
        except Exception as e:
            logger.error(f"âŒ æ£€æŸ¥è§¦å‘å™¨æ–‡ä»¶å¤±è´¥: {e}")
    
    def _run_digest_report(self, mode: str, trigger_data: Optional[Dict] = None):
        """æ‰§è¡Œæ‘˜è¦æŠ¥å‘Šä»»åŠ¡
        
        Args:
            mode: 'daily', 'weekly', 'manual'
            trigger_data: è§¦å‘å™¨æ•°æ®ï¼ˆç”¨äºæ‰‹åŠ¨è§¦å‘ï¼‰
        """
        start_time = datetime.now()
        logger.info(f"ğŸ”” å¼€å§‹æ‰§è¡Œ{mode}é‚®ä»¶æ‘˜è¦ä»»åŠ¡...")
        
        try:
            # è·å–æ‰€æœ‰æ´»è·ƒè®¢é˜…
            frequency_filter = None
            if mode == 'daily':
                frequency_filter = ['daily', 'close']
            elif mode == 'weekly':
                frequency_filter = ['weekly']
            
            # ä½¿ç”¨è®¢é˜…ç®¡ç†å™¨è·å–è®¢é˜…åˆ—è¡¨
            subscriptions = self.subscription_manager.get_active_subscriptions(
                frequency_filter=frequency_filter
            )
            
            if not subscriptions:
                logger.info(f"ğŸ“­ {mode}æ‘˜è¦æš‚æ— æ´»è·ƒè®¢é˜…")
                return
                
            logger.info(f"ğŸ“‹ æ‰¾åˆ° {len(subscriptions)} ä¸ªæ´»è·ƒè®¢é˜…")
            
            # æŒ‰è‚¡ç¥¨åˆ†ç»„ï¼Œé¿å…é‡å¤åˆ†æ
            stock_groups = self._group_subscriptions_by_stock(subscriptions)
            
            # æ‰¹é‡åˆ†æ
            analysis_results = {}
            success_count = 0
            error_count = 0
            
            for symbol, subs in stock_groups.items():
                try:
                    logger.info(f"ğŸ“Š æ­£åœ¨åˆ†æ {symbol}...")
                    result = self._analyze_stock(symbol, subs[0]['market_type'])
                    analysis_results[symbol] = result
                    success_count += 1
                    
                except Exception as e:
                    logger.error(f"âŒ åˆ†æ{symbol}å¤±è´¥: {e}")
                    error_count += 1
                    
            # å‘é€ä¸ªè‚¡è®¢é˜…é‚®ä»¶
            email_success_count = 0
            email_error_count = 0
            
            for symbol, subscriptions_list in stock_groups.items():
                if symbol not in analysis_results:
                    continue
                    
                try:
                    result = analysis_results[symbol]
                    self._send_batch_emails({symbol: subscriptions_list}, {symbol: result})
                    email_success_count += len(subscriptions_list)
                    
                except Exception as e:
                    logger.error(f"âŒ å‘é€{symbol}é‚®ä»¶å¤±è´¥: {e}")
                    email_error_count += len(subscriptions_list)
            
            # å‘é€å¸‚åœºæ‘˜è¦ï¼ˆå¸‚åœºçº§è®¢é˜…ï¼‰
            try:
                market_subs = self.subscription_manager.get_market_subscriptions(
                    frequency_filter=frequency_filter
                )
                # æŒ‰scopeåˆ†ç»„
                subs_by_scope = {}
                for sub in market_subs:
                    scope = sub.get('market_scope') or 'å…¨çƒ'
                    subs_by_scope.setdefault(scope, []).append(sub)
                for scope, subs in subs_by_scope.items():
                    self._send_market_digest(scope=scope, subscriptions=subs, mode=mode)
            except Exception as e:
                logger.error(f"âŒ å‘é€å¸‚åœºæ‘˜è¦å¤±è´¥: {e}")

            # å‘é€æŒ‡æ•°æ‘˜è¦ï¼ˆæŒ‡æ•°è®¢é˜…ï¼‰
            try:
                idx_subs = self.subscription_manager.get_index_subscriptions(
                    market=None,
                    frequency_filter=frequency_filter
                )
                if idx_subs:
                    self._send_index_digests(idx_subs, mode=mode)
            except Exception as e:
                logger.error(f"âŒ å‘é€æŒ‡æ•°æ‘˜è¦å¤±è´¥: {e}")

            # è®°å½•å®Œæˆæ—¶é—´å’Œç»Ÿè®¡
            elapsed = (datetime.now() - start_time).total_seconds()
            logger.info(f"âœ… {mode}é‚®ä»¶æ‘˜è¦å®Œæˆ - è€—æ—¶: {elapsed:.1f}ç§’, "
                       f"åˆ†æ: {success_count}æˆåŠŸ/{error_count}å¤±è´¥, "
                       f"é‚®ä»¶: {email_success_count}æˆåŠŸ/{email_error_count}å¤±è´¥")
            
        except Exception as e:
            logger.error(f"âŒ æ‰§è¡Œ{mode}é‚®ä»¶æ‘˜è¦å¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
    
    def create_manual_trigger(self, trigger_type: str = 'daily', custom_data: Optional[Dict] = None):
        """åˆ›å»ºæ‰‹åŠ¨è§¦å‘å™¨æ–‡ä»¶"""
        try:
            # è·å–é¡¹ç›®æ ¹ç›®å½•ä¸‹çš„data/triggersç›®å½•
            project_root = Path(__file__).parent.parent.parent.parent
            trigger_dir = project_root / "data" / "triggers"
            trigger_dir.mkdir(parents=True, exist_ok=True)
            
            # ç”Ÿæˆè§¦å‘å™¨æ–‡ä»¶å
            timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
            trigger_file = trigger_dir / f"trigger_{trigger_type}_{timestamp}.json"
            
            # åˆ›å»ºè§¦å‘å™¨æ•°æ®
            trigger_data = {
                'type': trigger_type,
                'created_at': datetime.now().isoformat(),
                'source': 'manual'
            }
            
            if custom_data:
                trigger_data.update(custom_data)
            
            # å†™å…¥è§¦å‘å™¨æ–‡ä»¶
            with open(trigger_file, 'w', encoding='utf-8') as f:
                json.dump(trigger_data, f, ensure_ascii=False, indent=2)
            
            logger.info(f"âœ… åˆ›å»ºæ‰‹åŠ¨è§¦å‘å™¨: {trigger_file.name}")
            return str(trigger_file)
            
        except Exception as e:
            logger.error(f"âŒ åˆ›å»ºæ‰‹åŠ¨è§¦å‘å™¨å¤±è´¥: {e}")
            return None
    
    def get_scheduler_status(self) -> Dict:
        """è·å–è°ƒåº¦å™¨çŠ¶æ€ä¿¡æ¯"""
        try:
            jobs = self.scheduler.get_jobs()
            job_info = []
            
            for job in jobs:
                job_info.append({
                    'id': job.id,
                    'name': job.name,
                    'next_run_time': job.next_run_time.isoformat() if job.next_run_time else None,
                    'trigger': str(job.trigger)
                })
            
            return {
                'running': self.is_running,
                'jobs': job_info,
                'timezone': os.getenv('SCHEDULER_TIMEZONE', 'Asia/Shanghai'),
                'total_jobs': len(jobs)
            }
            
        except Exception as e:
            logger.error(f"âŒ è·å–è°ƒåº¦å™¨çŠ¶æ€å¤±è´¥: {e}")
            return {
                'running': False,
                'jobs': [],
                'error': str(e)
            }
