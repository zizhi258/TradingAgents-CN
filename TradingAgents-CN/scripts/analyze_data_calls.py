#!/usr/bin/env python3
"""
æ•°æ®è·å–è°ƒç”¨åˆ†æå·¥å…·
ä¸“é—¨åˆ†ææ•°æ®è·å–ç›¸å…³çš„æ—¥å¿—ï¼Œæä¾›è¯¦ç»†çš„è°ƒç”¨ç»Ÿè®¡å’Œæ€§èƒ½åˆ†æ
"""

import json
import re
import sys
from pathlib import Path
from datetime import datetime, timedelta
from typing import Dict, List, Any, Optional
from collections import defaultdict, Counter
import argparse

# å¯¼å…¥æ—¥å¿—æ¨¡å—
from tradingagents.utils.logging_manager import get_logger
logger = get_logger('scripts')



class DataCallAnalyzer:
    """æ•°æ®è·å–è°ƒç”¨åˆ†æå™¨"""
    
    def __init__(self, log_file: Path):
        self.log_file = log_file
        self.data_calls = []
        self.tool_calls = []
        self.data_source_calls = []
        
    def parse_logs(self):
        """è§£ææ—¥å¿—æ–‡ä»¶"""
        if not self.log_file.exists():
            logger.error(f"âŒ æ—¥å¿—æ–‡ä»¶ä¸å­˜åœ¨: {self.log_file}")
            return
            
        logger.info(f"ğŸ“– è§£ææ•°æ®è·å–æ—¥å¿—: {self.log_file}")
        
        with open(self.log_file, 'r', encoding='utf-8') as f:
            for line_num, line in enumerate(f, 1):
                line = line.strip()
                if not line:
                    continue
                    
                # å°è¯•è§£æç»“æ„åŒ–æ—¥å¿—ï¼ˆJSONï¼‰
                if line.startswith('{'):
                    try:
                        entry = json.loads(line)
                        self._process_structured_entry(entry, line_num)
                        continue
                    except json.JSONDecodeError:
                        pass
                
                # è§£ææ™®é€šæ—¥å¿—
                self._process_regular_log(line, line_num)
        
        logger.info(f"âœ… è§£æå®Œæˆ: {len(self.data_calls)} æ¡æ•°æ®è°ƒç”¨, {len(self.tool_calls)} æ¡å·¥å…·è°ƒç”¨, {len(self.data_source_calls)} æ¡æ•°æ®æºè°ƒç”¨")
    
    def _process_structured_entry(self, entry: Dict[str, Any], line_num: int):
        """å¤„ç†ç»“æ„åŒ–æ—¥å¿—æ¡ç›®"""
        event_type = entry.get('event_type', '')
        
        if 'data_fetch' in event_type:
            self.data_calls.append({
                'type': 'structured',
                'line_num': line_num,
                'timestamp': entry.get('timestamp'),
                'event_type': event_type,
                'symbol': entry.get('symbol'),
                'start_date': entry.get('start_date'),
                'end_date': entry.get('end_date'),
                'data_source': entry.get('data_source'),
                'duration': entry.get('duration'),
                'result_length': entry.get('result_length'),
                'result_preview': entry.get('result_preview'),
                'error': entry.get('error'),
                'entry': entry
            })
        
        elif 'tool_call' in event_type:
            self.tool_calls.append({
                'type': 'structured',
                'line_num': line_num,
                'timestamp': entry.get('timestamp'),
                'event_type': event_type,
                'tool_name': entry.get('tool_name'),
                'duration': entry.get('duration'),
                'args_info': entry.get('args_info'),
                'result_info': entry.get('result_info'),
                'error': entry.get('error'),
                'entry': entry
            })
        
        elif 'unified_data_call' in event_type:
            self.data_source_calls.append({
                'type': 'structured',
                'line_num': line_num,
                'timestamp': entry.get('timestamp'),
                'event_type': event_type,
                'function': entry.get('function'),
                'ticker': entry.get('ticker'),
                'start_date': entry.get('start_date'),
                'end_date': entry.get('end_date'),
                'duration': entry.get('duration'),
                'result_length': entry.get('result_length'),
                'result_preview': entry.get('result_preview'),
                'error': entry.get('error'),
                'entry': entry
            })
    
    def _process_regular_log(self, line: str, line_num: int):
        """å¤„ç†æ™®é€šæ—¥å¿—è¡Œ"""
        # åŒ¹é…æ•°æ®è·å–ç›¸å…³çš„æ—¥å¿—
        patterns = [
            (r'ğŸ“Š.*\[æ•°æ®è·å–\].*symbol=(\w+).*start_date=([^,]+).*end_date=([^,]+)', 'data_fetch'),
            (r'ğŸ”§.*\[å·¥å…·è°ƒç”¨\].*(\w+)', 'tool_call'),
            (r'ğŸ“Š.*\[ç»Ÿä¸€æ¥å£\].*è·å–(\w+)è‚¡ç¥¨æ•°æ®', 'unified_call'),
            (r'ğŸ“Š.*\[(Tushare|AKShare|BaoStock|TDX)\].*è°ƒç”¨å‚æ•°.*symbol=(\w+)', 'data_source_call')
        ]
        
        for pattern, call_type in patterns:
            match = re.search(pattern, line)
            if match:
                # æå–æ—¶é—´æˆ³
                timestamp_match = re.match(r'(\d{4}-\d{2}-\d{2} \d{2}:\d{2}:\d{2},\d{3})', line)
                timestamp = timestamp_match.group(1) if timestamp_match else None
                
                if call_type == 'data_fetch':
                    self.data_calls.append({
                        'type': 'regular',
                        'line_num': line_num,
                        'timestamp': timestamp,
                        'symbol': match.group(1),
                        'start_date': match.group(2),
                        'end_date': match.group(3),
                        'raw_line': line
                    })
                elif call_type == 'tool_call':
                    self.tool_calls.append({
                        'type': 'regular',
                        'line_num': line_num,
                        'timestamp': timestamp,
                        'tool_name': match.group(1),
                        'raw_line': line
                    })
                elif call_type == 'data_source_call':
                    self.data_source_calls.append({
                        'type': 'regular',
                        'line_num': line_num,
                        'timestamp': timestamp,
                        'data_source': match.group(1),
                        'symbol': match.group(2),
                        'raw_line': line
                    })
                break
    
    def analyze_data_calls(self) -> Dict[str, Any]:
        """åˆ†ææ•°æ®è·å–è°ƒç”¨"""
        logger.info(f"\nğŸ“Š æ•°æ®è·å–è°ƒç”¨åˆ†æ")
        logger.info(f"=")
        
        analysis = {
            'total_calls': len(self.data_calls),
            'by_symbol': defaultdict(int),
            'by_data_source': defaultdict(int),
            'by_date_range': defaultdict(int),
            'performance': {
                'total_duration': 0,
                'avg_duration': 0,
                'slow_calls': [],
                'fast_calls': []
            },
            'success_rate': {
                'total': 0,
                'success': 0,
                'warning': 0,
                'error': 0
            }
        }
        
        durations = []
        
        for call in self.data_calls:
            # ç»Ÿè®¡è‚¡ç¥¨ä»£ç 
            symbol = call.get('symbol')
            if symbol:
                analysis['by_symbol'][symbol] += 1
            
            # ç»Ÿè®¡æ•°æ®æº
            data_source = call.get('data_source')
            if data_source:
                analysis['by_data_source'][data_source] += 1
            
            # ç»Ÿè®¡æ—¥æœŸèŒƒå›´
            start_date = call.get('start_date')
            end_date = call.get('end_date')
            if start_date and end_date:
                date_range = f"{start_date} to {end_date}"
                analysis['by_date_range'][date_range] += 1
            
            # æ€§èƒ½åˆ†æ
            duration = call.get('duration')
            if duration:
                durations.append(duration)
                analysis['performance']['total_duration'] += duration
                
                if duration > 5.0:  # è¶…è¿‡5ç§’çš„æ…¢è°ƒç”¨
                    analysis['performance']['slow_calls'].append({
                        'symbol': symbol,
                        'duration': duration,
                        'data_source': data_source,
                        'line_num': call.get('line_num')
                    })
                elif duration < 1.0:  # å°äº1ç§’çš„å¿«è°ƒç”¨
                    analysis['performance']['fast_calls'].append({
                        'symbol': symbol,
                        'duration': duration,
                        'data_source': data_source,
                        'line_num': call.get('line_num')
                    })
            
            # æˆåŠŸç‡åˆ†æ
            event_type = call.get('event_type', '')
            if 'success' in event_type:
                analysis['success_rate']['success'] += 1
            elif 'warning' in event_type:
                analysis['success_rate']['warning'] += 1
            elif 'error' in event_type or 'exception' in event_type:
                analysis['success_rate']['error'] += 1
            
            analysis['success_rate']['total'] += 1
        
        # è®¡ç®—å¹³å‡æ—¶é—´
        if durations:
            analysis['performance']['avg_duration'] = sum(durations) / len(durations)
        
        # è¾“å‡ºåˆ†æç»“æœ
        logger.info(f"ğŸ“ˆ æ€»è°ƒç”¨æ¬¡æ•°: {analysis['total_calls']}")
        
        if analysis['by_symbol']:
            logger.info(f"\nğŸ“Š æŒ‰è‚¡ç¥¨ä»£ç ç»Ÿè®¡ (å‰10):")
            for symbol, count in Counter(analysis['by_symbol']).most_common(10):
                logger.info(f"  - {symbol}: {count} æ¬¡")
        
        if analysis['by_data_source']:
            logger.info(f"\nğŸ”§ æŒ‰æ•°æ®æºç»Ÿè®¡:")
            for source, count in Counter(analysis['by_data_source']).most_common():
                logger.info(f"  - {source}: {count} æ¬¡")
        
        if durations:
            logger.info(f"\nâ±ï¸  æ€§èƒ½ç»Ÿè®¡:")
            logger.info(f"  - æ€»è€—æ—¶: {analysis['performance']['total_duration']:.2f}s")
            logger.info(f"  - å¹³å‡è€—æ—¶: {analysis['performance']['avg_duration']:.2f}s")
            logger.info(f"  - æ…¢è°ƒç”¨ (>5s): {len(analysis['performance']['slow_calls'])} æ¬¡")
            logger.info(f"  - å¿«è°ƒç”¨ (<1s): {len(analysis['performance']['fast_calls'])} æ¬¡")
        
        if analysis['success_rate']['total'] > 0:
            success_pct = (analysis['success_rate']['success'] / analysis['success_rate']['total']) * 100
            logger.info(f"\nâœ… æˆåŠŸç‡ç»Ÿè®¡:")
            logger.info(f"  - æˆåŠŸ: {analysis['success_rate']['success']} ({success_pct:.1f}%)")
            logger.warning(f"  - è­¦å‘Š: {analysis['success_rate']['warning']}")
            logger.error(f"  - é”™è¯¯: {analysis['success_rate']['error']}")
        
        return analysis
    
    def analyze_tool_calls(self) -> Dict[str, Any]:
        """åˆ†æå·¥å…·è°ƒç”¨"""
        logger.info(f"\nğŸ”§ å·¥å…·è°ƒç”¨åˆ†æ")
        logger.info(f"=")
        
        analysis = {
            'total_calls': len(self.tool_calls),
            'by_tool': defaultdict(int),
            'performance': defaultdict(list),
            'success_rate': defaultdict(int)
        }
        
        for call in self.tool_calls:
            tool_name = call.get('tool_name', 'unknown')
            analysis['by_tool'][tool_name] += 1
            
            duration = call.get('duration')
            if duration:
                analysis['performance'][tool_name].append(duration)
            
            event_type = call.get('event_type', '')
            if 'success' in event_type:
                analysis['success_rate'][f"{tool_name}_success"] += 1
            elif 'error' in event_type:
                analysis['success_rate'][f"{tool_name}_error"] += 1
        
        # è¾“å‡ºç»“æœ
        logger.info(f"ğŸ”§ æ€»å·¥å…·è°ƒç”¨: {analysis['total_calls']}")
        
        if analysis['by_tool']:
            logger.info(f"\nğŸ“Š æŒ‰å·¥å…·ç»Ÿè®¡:")
            for tool, count in Counter(analysis['by_tool']).most_common():
                logger.info(f"  - {tool}: {count} æ¬¡")
                
                # æ€§èƒ½ç»Ÿè®¡
                if tool in analysis['performance']:
                    durations = analysis['performance'][tool]
                    avg_duration = sum(durations) / len(durations)
                    logger.info(f"    å¹³å‡è€—æ—¶: {avg_duration:.2f}s")
        
        return analysis
    
    def generate_report(self) -> str:
        """ç”Ÿæˆåˆ†ææŠ¥å‘Š"""
        logger.info(f"\nğŸ“‹ ç”Ÿæˆæ•°æ®è·å–åˆ†ææŠ¥å‘Š")
        logger.info(f"=")
        
        data_analysis = self.analyze_data_calls()
        tool_analysis = self.analyze_tool_calls()
        
        report = f"""
# æ•°æ®è·å–è°ƒç”¨åˆ†ææŠ¥å‘Š

ç”Ÿæˆæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}
æ—¥å¿—æ–‡ä»¶: {self.log_file}

## æ¦‚è§ˆ
- æ•°æ®è·å–è°ƒç”¨: {data_analysis['total_calls']}
- å·¥å…·è°ƒç”¨: {tool_analysis['total_calls']}
- æ•°æ®æºè°ƒç”¨: {len(self.data_source_calls)}

## æ•°æ®è·å–æ€§èƒ½
- æ€»è€—æ—¶: {data_analysis['performance']['total_duration']:.2f}s
- å¹³å‡è€—æ—¶: {data_analysis['performance']['avg_duration']:.2f}s
- æ…¢è°ƒç”¨æ•°é‡: {len(data_analysis['performance']['slow_calls'])}

## æˆåŠŸç‡
- æˆåŠŸè°ƒç”¨: {data_analysis['success_rate']['success']}
- è­¦å‘Šè°ƒç”¨: {data_analysis['success_rate']['warning']}
- é”™è¯¯è°ƒç”¨: {data_analysis['success_rate']['error']}

## å»ºè®®
"""
        
        # æ·»åŠ å»ºè®®
        if data_analysis['performance']['avg_duration'] > 3.0:
            report += "- âš ï¸ å¹³å‡æ•°æ®è·å–æ—¶é—´è¾ƒé•¿ï¼Œå»ºè®®ä¼˜åŒ–ç¼“å­˜ç­–ç•¥\n"
        
        if data_analysis['success_rate']['error'] > 0:
            report += f"- âŒ å‘ç° {data_analysis['success_rate']['error']} ä¸ªæ•°æ®è·å–é”™è¯¯ï¼Œå»ºè®®æ£€æŸ¥æ•°æ®æºé…ç½®\n"
        
        if len(data_analysis['performance']['slow_calls']) > 5:
            report += "- ğŸŒ æ…¢è°ƒç”¨è¾ƒå¤šï¼Œå»ºè®®åˆ†æç½‘ç»œè¿æ¥å’ŒAPIé™åˆ¶\n"
        
        return report


def main():
    parser = argparse.ArgumentParser(description='æ•°æ®è·å–è°ƒç”¨åˆ†æå·¥å…·')
    parser.add_argument('log_file', help='æ—¥å¿—æ–‡ä»¶è·¯å¾„')
    parser.add_argument('--output', '-o', help='è¾“å‡ºæŠ¥å‘Šæ–‡ä»¶è·¯å¾„')
    parser.add_argument('--format', choices=['text', 'json'], default='text', help='è¾“å‡ºæ ¼å¼')
    
    args = parser.parse_args()
    
    log_file = Path(args.log_file)
    analyzer = DataCallAnalyzer(log_file)
    
    try:
        analyzer.parse_logs()
        report = analyzer.generate_report()
        
        if args.output:
            with open(args.output, 'w', encoding='utf-8') as f:
                f.write(report)
            logger.info(f"ğŸ“„ æŠ¥å‘Šå·²ä¿å­˜åˆ°: {args.output}")
        else:
            print(report)
            
    except Exception as e:
        logger.error(f"âŒ åˆ†æå¤±è´¥: {e}")
        sys.exit(1)


if __name__ == "__main__":
    main()
