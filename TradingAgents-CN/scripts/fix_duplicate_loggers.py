#!/usr/bin/env python3
"""
ä¿®å¤é‡å¤loggerå®šä¹‰é—®é¢˜çš„è„šæœ¬

è¿™ä¸ªè„šæœ¬ä¼š:
1. æ‰«ææ‰€æœ‰Pythonæ–‡ä»¶
2. æ£€æµ‹é‡å¤çš„logger = get_logger()å®šä¹‰
3. ç§»é™¤é‡å¤å®šä¹‰ï¼Œåªä¿ç•™æ–‡ä»¶å¤´éƒ¨çš„ç¬¬ä¸€ä¸ªå®šä¹‰
4. ç”Ÿæˆè¯¦ç»†çš„ä¿®å¤æŠ¥å‘Š
"""

import os
import re
from pathlib import Path
from typing import List, Dict, Tuple

def find_python_files(root_dir: str, exclude_dirs: List[str] = None) -> List[str]:
    """æŸ¥æ‰¾æ‰€æœ‰Pythonæ–‡ä»¶"""
    if exclude_dirs is None:
        exclude_dirs = ['env', '.env', '__pycache__', '.git', 'node_modules', '.venv']
    
    python_files = []
    for root, dirs, files in os.walk(root_dir):
        # æ’é™¤æŒ‡å®šç›®å½•
        dirs[:] = [d for d in dirs if d not in exclude_dirs]
        
        for file in files:
            if file.endswith('.py'):
                python_files.append(os.path.join(root, file))
    
    return python_files

def analyze_logger_definitions(file_path: str) -> Dict:
    """åˆ†ææ–‡ä»¶ä¸­çš„loggerå®šä¹‰"""
    try:
        with open(file_path, 'r', encoding='utf-8') as f:
            lines = f.readlines()
    except Exception as e:
        return {'error': str(e), 'logger_lines': []}
    
    logger_lines = []
    logger_pattern = re.compile(r'^\s*logger\s*=\s*get_logger\s*\(')
    
    for i, line in enumerate(lines, 1):
        if logger_pattern.match(line):
            logger_lines.append({
                'line_number': i,
                'content': line.strip(),
                'indentation': len(line) - len(line.lstrip())
            })
    
    return {
        'total_lines': len(lines),
        'logger_lines': logger_lines,
        'has_duplicates': len(logger_lines) > 1
    }

def find_import_section_end(lines: List[str]) -> int:
    """æ‰¾åˆ°importè¯­å¥ç»“æŸçš„ä½ç½®"""
    import_end = 0
    in_docstring = False
    docstring_char = None
    
    for i, line in enumerate(lines):
        stripped = line.strip()
        
        # å¤„ç†æ–‡æ¡£å­—ç¬¦ä¸²
        if not in_docstring:
            if stripped.startswith('"""') or stripped.startswith("'''"):
                docstring_char = stripped[:3]
                if stripped.count(docstring_char) == 1:  # å¼€å§‹æ–‡æ¡£å­—ç¬¦ä¸²
                    in_docstring = True
                # å¦‚æœåŒä¸€è¡ŒåŒ…å«å¼€å§‹å’Œç»“æŸï¼Œåˆ™ä¸è¿›å…¥æ–‡æ¡£å­—ç¬¦ä¸²çŠ¶æ€
        else:
            if docstring_char in stripped:
                in_docstring = False
                continue
        
        if in_docstring:
            continue
            
        # è·³è¿‡æ³¨é‡Šå’Œç©ºè¡Œ
        if not stripped or stripped.startswith('#'):
            continue
            
        # æ£€æŸ¥æ˜¯å¦æ˜¯importè¯­å¥
        if (stripped.startswith('import ') or 
            stripped.startswith('from ') or
            stripped.startswith('sys.path.') or
            stripped.startswith('load_dotenv(')):
            import_end = i + 1
        elif stripped and not stripped.startswith('#'):
            # é‡åˆ°éimportè¯­å¥ï¼Œåœæ­¢
            break
    
    return import_end

def fix_duplicate_loggers(file_path: str) -> Dict:
    """ä¿®å¤æ–‡ä»¶ä¸­çš„é‡å¤loggerå®šä¹‰"""
    try:
        with open(file_path, 'r', encoding='utf-8') as f:
            lines = f.readlines()
    except Exception as e:
        return {'success': False, 'error': f'è¯»å–æ–‡ä»¶å¤±è´¥: {str(e)}'}
    
    analysis = analyze_logger_definitions(file_path)
    
    if not analysis['has_duplicates']:
        return {'success': True, 'message': 'æ— éœ€ä¿®å¤', 'changes': 0}
    
    logger_lines = analysis['logger_lines']
    if len(logger_lines) <= 1:
        return {'success': True, 'message': 'æ— éœ€ä¿®å¤', 'changes': 0}
    
    # æ‰¾åˆ°importè¯­å¥ç»“æŸä½ç½®
    import_end = find_import_section_end(lines)
    
    # ç¡®å®šè¦ä¿ç•™çš„loggerå®šä¹‰
    keep_logger = None
    remove_lines = []
    
    # ä¼˜å…ˆä¿ç•™åœ¨importåŒºåŸŸé™„è¿‘çš„loggerå®šä¹‰
    for logger_info in logger_lines:
        line_num = logger_info['line_number'] - 1  # è½¬æ¢ä¸º0ç´¢å¼•
        if line_num <= import_end + 5:  # åœ¨importåŒºåŸŸé™„è¿‘
            if keep_logger is None:
                keep_logger = logger_info
            else:
                remove_lines.append(line_num)
        else:
            remove_lines.append(line_num)
    
    # å¦‚æœæ²¡æœ‰åœ¨importåŒºåŸŸæ‰¾åˆ°ï¼Œä¿ç•™ç¬¬ä¸€ä¸ª
    if keep_logger is None:
        keep_logger = logger_lines[0]
        remove_lines = [info['line_number'] - 1 for info in logger_lines[1:]]
    
    # ç§»é™¤é‡å¤çš„loggerå®šä¹‰ï¼ˆä»åå¾€å‰åˆ é™¤ä»¥ä¿æŒè¡Œå·æ­£ç¡®ï¼‰
    remove_lines.sort(reverse=True)
    changes_made = 0
    
    for line_num in remove_lines:
        if 0 <= line_num < len(lines):
            # æ£€æŸ¥æ˜¯å¦ç¡®å®æ˜¯loggerå®šä¹‰
            if 'logger = get_logger(' in lines[line_num]:
                lines.pop(line_num)
                changes_made += 1
    
    if changes_made > 0:
        try:
            with open(file_path, 'w', encoding='utf-8') as f:
                f.writelines(lines)
            return {
                'success': True, 
                'message': f'ç§»é™¤äº†{changes_made}ä¸ªé‡å¤çš„loggerå®šä¹‰',
                'changes': changes_made,
                'kept_logger': keep_logger['content'],
                'removed_count': changes_made
            }
        except Exception as e:
            return {'success': False, 'error': f'å†™å…¥æ–‡ä»¶å¤±è´¥: {str(e)}'}
    
    return {'success': True, 'message': 'æ— éœ€ä¿®å¤', 'changes': 0}

def main():
    """ä¸»å‡½æ•°"""
    root_dir = "c:\\code\\TradingAgentsCN"
    
    print("ğŸ” å¼€å§‹æ‰«æPythonæ–‡ä»¶...")
    python_files = find_python_files(root_dir)
    print(f"ğŸ“ æ‰¾åˆ° {len(python_files)} ä¸ªPythonæ–‡ä»¶")
    
    # åˆ†ææ‰€æœ‰æ–‡ä»¶
    print("\nğŸ“Š åˆ†æloggerå®šä¹‰...")
    files_with_duplicates = []
    total_duplicates = 0
    
    for file_path in python_files:
        analysis = analyze_logger_definitions(file_path)
        if analysis.get('has_duplicates', False):
            files_with_duplicates.append((file_path, analysis))
            total_duplicates += len(analysis['logger_lines']) - 1
    
    print(f"âš ï¸  å‘ç° {len(files_with_duplicates)} ä¸ªæ–‡ä»¶æœ‰é‡å¤loggerå®šä¹‰")
    print(f"ğŸ“ˆ æ€»å…±æœ‰ {total_duplicates} ä¸ªé‡å¤å®šä¹‰éœ€è¦ä¿®å¤")
    
    if not files_with_duplicates:
        print("âœ… æ²¡æœ‰å‘ç°é‡å¤çš„loggerå®šä¹‰ï¼")
        return
    
    # ä¿®å¤é‡å¤å®šä¹‰
    print("\nğŸ”§ å¼€å§‹ä¿®å¤é‡å¤loggerå®šä¹‰...")
    fixed_files = 0
    total_changes = 0
    errors = []
    
    for file_path, analysis in files_with_duplicates:
        rel_path = os.path.relpath(file_path, root_dir)
        print(f"\nğŸ“ å¤„ç†: {rel_path}")
        print(f"   å‘ç° {len(analysis['logger_lines'])} ä¸ªloggerå®šä¹‰")
        
        result = fix_duplicate_loggers(file_path)
        
        if result['success']:
            if result['changes'] > 0:
                fixed_files += 1
                total_changes += result['changes']
                print(f"   âœ… {result['message']}")
                if 'kept_logger' in result:
                    print(f"   ğŸ“Œ ä¿ç•™: {result['kept_logger']}")
            else:
                print(f"   â„¹ï¸  {result['message']}")
        else:
            errors.append((rel_path, result['error']))
            print(f"   âŒ {result['error']}")
    
    # ç”ŸæˆæŠ¥å‘Š
    print("\n" + "="*60)
    print("ğŸ“‹ ä¿®å¤æŠ¥å‘Š")
    print("="*60)
    print(f"âœ… æˆåŠŸä¿®å¤æ–‡ä»¶æ•°: {fixed_files}")
    print(f"ğŸ”§ æ€»å…±ç§»é™¤é‡å¤å®šä¹‰: {total_changes}")
    print(f"âŒ ä¿®å¤å¤±è´¥æ–‡ä»¶æ•°: {len(errors)}")
    
    if errors:
        print("\nâŒ ä¿®å¤å¤±è´¥çš„æ–‡ä»¶:")
        for file_path, error in errors:
            print(f"   - {file_path}: {error}")
    
    # ä¿å­˜è¯¦ç»†æŠ¥å‘Š
    report_file = "duplicate_logger_fix_report.md"
    with open(report_file, 'w', encoding='utf-8') as f:
        f.write("# é‡å¤Loggerå®šä¹‰ä¿®å¤æŠ¥å‘Š\n\n")
        f.write(f"## æ¦‚è¦\n\n")
        f.write(f"- æ‰«ææ–‡ä»¶æ€»æ•°: {len(python_files)}\n")
        f.write(f"- å‘ç°é‡å¤å®šä¹‰æ–‡ä»¶æ•°: {len(files_with_duplicates)}\n")
        f.write(f"- æˆåŠŸä¿®å¤æ–‡ä»¶æ•°: {fixed_files}\n")
        f.write(f"- æ€»å…±ç§»é™¤é‡å¤å®šä¹‰: {total_changes}\n")
        f.write(f"- ä¿®å¤å¤±è´¥æ–‡ä»¶æ•°: {len(errors)}\n\n")
        
        if errors:
            f.write("## ä¿®å¤å¤±è´¥çš„æ–‡ä»¶\n\n")
            for file_path, error in errors:
                f.write(f"- `{file_path}`: {error}\n")
            f.write("\n")
        
        f.write("## ä¿®å¤è¯¦æƒ…\n\n")
        for file_path, analysis in files_with_duplicates:
            rel_path = os.path.relpath(file_path, root_dir)
            f.write(f"### {rel_path}\n\n")
            f.write(f"- åŸæœ‰loggerå®šä¹‰æ•°: {len(analysis['logger_lines'])}\n")
            for i, logger_info in enumerate(analysis['logger_lines']):
                f.write(f"  - ç¬¬{logger_info['line_number']}è¡Œ: `{logger_info['content']}`\n")
            f.write("\n")
    
    print(f"\nğŸ“„ è¯¦ç»†æŠ¥å‘Šå·²ä¿å­˜åˆ°: {report_file}")
    print("\nğŸ‰ ä¿®å¤å®Œæˆï¼")

if __name__ == "__main__":
    main()