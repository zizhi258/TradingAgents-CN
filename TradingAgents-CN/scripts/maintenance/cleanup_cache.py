#!/usr/bin/env python3
"""
ç¼“å­˜æ¸…ç†å·¥å…·
æ¸…ç†è¿‡æœŸçš„ç¼“å­˜æ–‡ä»¶å’Œæ•°æ®åº“è®°å½•
"""

import os
import sys
from datetime import datetime, timedelta
from pathlib import Path

# å¯¼å…¥æ—¥å¿—æ¨¡å—
from tradingagents.utils.logging_manager import get_logger
logger = get_logger('scripts')

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
project_root = Path(__file__).parent.parent.parent
sys.path.insert(0, str(project_root))

def cleanup_file_cache(max_age_days: int = 7):
    """æ¸…ç†æ–‡ä»¶ç¼“å­˜"""
    logger.info(f"ğŸ§¹ æ¸…ç† {max_age_days} å¤©å‰çš„æ–‡ä»¶ç¼“å­˜...")
    
    cache_dirs = [
        project_root / "cache",
        project_root / "data" / "cache", 
        project_root / "tradingagents" / "dataflows" / "data_cache"
    ]
    
    total_cleaned = 0
    cutoff_time = datetime.now() - timedelta(days=max_age_days)
    
    for cache_dir in cache_dirs:
        if not cache_dir.exists():
            continue
            
        logger.info(f"ğŸ“ æ£€æŸ¥ç¼“å­˜ç›®å½•: {cache_dir}")
        
        for cache_file in cache_dir.rglob("*"):
            if cache_file.is_file():
                try:
                    file_time = datetime.fromtimestamp(cache_file.stat().st_mtime)
                    if file_time < cutoff_time:
                        cache_file.unlink()
                        total_cleaned += 1
                        logger.info(f"  âœ… åˆ é™¤: {cache_file.name}")
                except Exception as e:
                    logger.error(f"  âŒ åˆ é™¤å¤±è´¥: {cache_file.name} - {e}")
    
    logger.info(f"âœ… æ–‡ä»¶ç¼“å­˜æ¸…ç†å®Œæˆï¼Œåˆ é™¤äº† {total_cleaned} ä¸ªæ–‡ä»¶")
    return total_cleaned

def cleanup_database_cache(max_age_days: int = 7):
    """æ¸…ç†æ•°æ®åº“ç¼“å­˜"""
    logger.info(f"ğŸ—„ï¸ æ¸…ç† {max_age_days} å¤©å‰çš„æ•°æ®åº“ç¼“å­˜...")
    
    try:
        from tradingagents.dataflows.integrated_cache import get_cache
        
        cache = get_cache()
        
        if hasattr(cache, 'clear_old_cache'):
            cleared_count = cache.clear_old_cache(max_age_days)
            logger.info(f"âœ… æ•°æ®åº“ç¼“å­˜æ¸…ç†å®Œæˆï¼Œåˆ é™¤äº† {cleared_count} æ¡è®°å½•")
            return cleared_count
        else:
            logger.info(f"â„¹ï¸ å½“å‰ç¼“å­˜ç³»ç»Ÿä¸æ”¯æŒè‡ªåŠ¨æ¸…ç†")
            return 0
            
    except Exception as e:
        logger.error(f"âŒ æ•°æ®åº“ç¼“å­˜æ¸…ç†å¤±è´¥: {e}")
        return 0

def cleanup_python_cache():
    """æ¸…ç†Pythonç¼“å­˜æ–‡ä»¶"""
    logger.info(f"ğŸ æ¸…ç†Pythonç¼“å­˜æ–‡ä»¶...")
    
    cache_patterns = ["__pycache__", "*.pyc", "*.pyo"]
    total_cleaned = 0
    
    for pattern in cache_patterns:
        if pattern == "__pycache__":
            cache_dirs = list(project_root.rglob(pattern))
            for cache_dir in cache_dirs:
                try:
                    import shutil
                    shutil.rmtree(cache_dir)
                    total_cleaned += 1
                    logger.info(f"  âœ… åˆ é™¤ç›®å½•: {cache_dir.relative_to(project_root)}")
                except Exception as e:
                    logger.error(f"  âŒ åˆ é™¤å¤±è´¥: {cache_dir.relative_to(project_root)} - {e}")
        else:
            cache_files = list(project_root.rglob(pattern))
            for cache_file in cache_files:
                try:
                    cache_file.unlink()
                    total_cleaned += 1
                    logger.info(f"  âœ… åˆ é™¤æ–‡ä»¶: {cache_file.relative_to(project_root)}")
                except Exception as e:
                    logger.error(f"  âŒ åˆ é™¤å¤±è´¥: {cache_file.relative_to(project_root)} - {e}")
    
    logger.info(f"âœ… Pythonç¼“å­˜æ¸…ç†å®Œæˆï¼Œåˆ é™¤äº† {total_cleaned} ä¸ªé¡¹ç›®")
    return total_cleaned

def get_cache_statistics():
    """è·å–ç¼“å­˜ç»Ÿè®¡ä¿¡æ¯"""
    logger.info(f"ğŸ“Š è·å–ç¼“å­˜ç»Ÿè®¡ä¿¡æ¯...")
    
    try:
        from tradingagents.dataflows.integrated_cache import get_cache
        
        cache = get_cache()
        
        logger.info(f"ğŸ¯ ç¼“å­˜æ¨¡å¼: {cache.get_performance_mode()}")
        logger.info(f"ğŸ—„ï¸ æ•°æ®åº“å¯ç”¨: {'æ˜¯' if cache.is_database_available() else 'å¦'}")
        
        # ç»Ÿè®¡æ–‡ä»¶ç¼“å­˜
        cache_dirs = [
            project_root / "cache",
            project_root / "data" / "cache",
            project_root / "tradingagents" / "dataflows" / "data_cache"
        ]
        
        total_files = 0
        total_size = 0
        
        for cache_dir in cache_dirs:
            if cache_dir.exists():
                for cache_file in cache_dir.rglob("*"):
                    if cache_file.is_file():
                        total_files += 1
                        total_size += cache_file.stat().st_size
        
        logger.info(f"ğŸ“ æ–‡ä»¶ç¼“å­˜: {total_files} ä¸ªæ–‡ä»¶ï¼Œ{total_size / 1024 / 1024:.2f} MB")
        
    except Exception as e:
        logger.error(f"âŒ è·å–ç¼“å­˜ç»Ÿè®¡å¤±è´¥: {e}")

def main():
    """ä¸»å‡½æ•°"""
    logger.info(f"ğŸ§¹ TradingAgents ç¼“å­˜æ¸…ç†å·¥å…·")
    logger.info(f"=")
    
    import argparse

    parser = argparse.ArgumentParser(description="æ¸…ç†TradingAgentsç¼“å­˜")
    parser.add_argument("--days", type=int, default=7, help="æ¸…ç†å¤šå°‘å¤©å‰çš„ç¼“å­˜ (é»˜è®¤: 7)")
    parser.add_argument("--type", choices=["all", "file", "database", "python"], 
                       default="all", help="æ¸…ç†ç±»å‹ (é»˜è®¤: all)")
    parser.add_argument("--stats", action="store_true", help="åªæ˜¾ç¤ºç»Ÿè®¡ä¿¡æ¯ï¼Œä¸æ¸…ç†")
    
    args = parser.parse_args()
    
    if args.stats:
        get_cache_statistics()
        return
    
    total_cleaned = 0
    
    if args.type in ["all", "file"]:
        total_cleaned += cleanup_file_cache(args.days)
    
    if args.type in ["all", "database"]:
        total_cleaned += cleanup_database_cache(args.days)
    
    if args.type in ["all", "python"]:
        total_cleaned += cleanup_python_cache()
    
    logger.info(f"\n")
    logger.info(f"ğŸ‰ ç¼“å­˜æ¸…ç†å®Œæˆï¼æ€»å…±æ¸…ç†äº† {total_cleaned} ä¸ªé¡¹ç›®")
    logger.info(f"\nğŸ’¡ ä½¿ç”¨æç¤º:")
    logger.info(f"  --stats     æŸ¥çœ‹ç¼“å­˜ç»Ÿè®¡")
    logger.info(f"  --days 3    æ¸…ç†3å¤©å‰çš„ç¼“å­˜")
    logger.info(f"  --type file åªæ¸…ç†æ–‡ä»¶ç¼“å­˜")

if __name__ == "__main__":
    main()
