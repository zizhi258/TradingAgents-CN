#!/usr/bin/env python3
"""
ç³»ç»Ÿåˆå§‹åŒ–è„šæœ¬
åˆå§‹åŒ–æ•°æ®åº“é…ç½®ï¼Œç¡®ä¿ç³»ç»Ÿå¯ä»¥åœ¨æœ‰æˆ–æ²¡æœ‰æ•°æ®åº“çš„æƒ…å†µä¸‹è¿è¡Œ
"""

import sys
import os
import json
from pathlib import Path

# å¯¼å…¥æ—¥å¿—æ¨¡å—
from tradingagents.utils.logging_manager import get_logger
logger = get_logger('scripts')

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
project_root = Path(__file__).parent.parent.parent
sys.path.insert(0, str(project_root))

def initialize_system():
    """åˆå§‹åŒ–ç³»ç»Ÿ"""
    logger.info(f"ğŸš€ TradingAgents ç³»ç»Ÿåˆå§‹åŒ–")
    logger.info(f"=")
    
    # 1. åˆ›å»ºé…ç½®ç›®å½•
    logger.info(f"\nğŸ“ åˆ›å»ºé…ç½®ç›®å½•...")
    config_dir = project_root / "config"
    config_dir.mkdir(exist_ok=True)
    logger.info(f"âœ… é…ç½®ç›®å½•: {config_dir}")
    
    # 2. åˆ›å»ºæ•°æ®ç¼“å­˜ç›®å½•
    logger.info(f"\nğŸ“ åˆ›å»ºç¼“å­˜ç›®å½•...")
    cache_dir = project_root / "data" / "cache"
    cache_dir.mkdir(parents=True, exist_ok=True)
    logger.info(f"âœ… ç¼“å­˜ç›®å½•: {cache_dir}")
    
    # 3. æ£€æŸ¥å¹¶åˆ›å»ºæ•°æ®åº“é…ç½®æ–‡ä»¶
    logger.info(f"\nâš™ï¸ é…ç½®æ•°æ®åº“è®¾ç½®...")
    config_file = config_dir / "database_config.json"
    
    if config_file.exists():
        logger.info(f"â„¹ï¸ é…ç½®æ–‡ä»¶å·²å­˜åœ¨: {config_file}")
        
        # è¯»å–ç°æœ‰é…ç½®
        try:
            with open(config_file, 'r', encoding='utf-8') as f:
                existing_config = json.load(f)
            logger.info(f"âœ… ç°æœ‰é…ç½®åŠ è½½æˆåŠŸ")
        except Exception as e:
            logger.error(f"âš ï¸ ç°æœ‰é…ç½®è¯»å–å¤±è´¥: {e}")
            existing_config = None
    else:
        existing_config = None
    
    # 4. æ£€æµ‹æ•°æ®åº“å¯ç”¨æ€§
    logger.debug(f"\nğŸ” æ£€æµ‹æ•°æ®åº“å¯ç”¨æ€§...")
    
    # æ£€æµ‹MongoDB
    mongodb_available = False
    try:
        import pymongo
        from pymongo import MongoClient
        
        client = MongoClient('localhost', 27017, serverSelectionTimeoutMS=2000)
        client.server_info()
        client.close()
        mongodb_available = True
        logger.info(f"âœ… MongoDB: å¯ç”¨")
    except ImportError:
        logger.error(f"âŒ MongoDB: pymongoæœªå®‰è£…")
    except Exception as e:
        logger.error(f"âŒ MongoDB: è¿æ¥å¤±è´¥ - {e}")
    
    # æ£€æµ‹Redis
    redis_available = False
    try:
        import redis
        
        r = redis.Redis(host='localhost', port=6379, socket_timeout=2)
        r.ping()
        redis_available = True
        logger.info(f"âœ… Redis: å¯ç”¨")
    except ImportError:
        logger.error(f"âŒ Redis: redisæœªå®‰è£…")
    except Exception as e:
        logger.error(f"âŒ Redis: è¿æ¥å¤±è´¥ - {e}")
    
    # 5. ç”Ÿæˆé…ç½®
    logger.info(f"\nâš™ï¸ ç”Ÿæˆç³»ç»Ÿé…ç½®...")
    
    # ç¡®å®šä¸»è¦ç¼“å­˜åç«¯
    if redis_available:
        primary_backend = "redis"
        logger.info(f"ğŸš€ é€‰æ‹©Redisä½œä¸ºä¸»è¦ç¼“å­˜åç«¯")
    elif mongodb_available:
        primary_backend = "mongodb"
        logger.info(f"ğŸ’¾ é€‰æ‹©MongoDBä½œä¸ºä¸»è¦ç¼“å­˜åç«¯")
    else:
        primary_backend = "file"
        logger.info(f"ğŸ“ é€‰æ‹©æ–‡ä»¶ä½œä¸ºä¸»è¦ç¼“å­˜åç«¯")
    
    # åˆ›å»ºé…ç½®
    config = {
        "database": {
            "enabled": mongodb_available or redis_available,
            "auto_detect": True,
            "fallback_to_file": True,
            "mongodb": {
                "enabled": mongodb_available,
                "host": "localhost",
                "port": 27017,
                "database": "tradingagents",
                "timeout": 2000,
                "auto_detect": True
            },
            "redis": {
                "enabled": redis_available,
                "host": "localhost",
                "port": 6379,
                "timeout": 2,
                "auto_detect": True
            }
        },
        "cache": {
            "enabled": True,
            "primary_backend": primary_backend,
            "fallback_enabled": True,
            "file_cache": {
                "enabled": True,
                "directory": "data/cache",
                "max_size_mb": 1000,
                "cleanup_interval_hours": 24
            },
            "ttl_settings": {
                "us_stock_data": 7200,      # 2å°æ—¶
                "china_stock_data": 3600,   # 1å°æ—¶
                "us_news": 21600,           # 6å°æ—¶
                "china_news": 14400,        # 4å°æ—¶
                "us_fundamentals": 86400,   # 24å°æ—¶
                "china_fundamentals": 43200  # 12å°æ—¶
            }
        },
        "performance": {
            "enable_compression": True,
            "enable_async_cache": False,
            "max_concurrent_requests": 10
        },
        "logging": {
            "level": "INFO",
            "log_database_operations": True,
            "log_cache_operations": False
        }
    }
    
    # 6. ä¿å­˜é…ç½®
    logger.info(f"\nğŸ’¾ ä¿å­˜é…ç½®æ–‡ä»¶...")
    try:
        with open(config_file, 'w', encoding='utf-8') as f:
            json.dump(config, f, indent=2, ensure_ascii=False)
        logger.info(f"âœ… é…ç½®å·²ä¿å­˜: {config_file}")
    except Exception as e:
        logger.error(f"âŒ é…ç½®ä¿å­˜å¤±è´¥: {e}")
        return False
    
    # 7. æµ‹è¯•ç³»ç»Ÿ
    logger.info(f"\nğŸ§ª æµ‹è¯•ç³»ç»Ÿåˆå§‹åŒ–...")
    try:
        # æµ‹è¯•æ•°æ®åº“ç®¡ç†å™¨
        from tradingagents.config.database_manager import get_database_manager
        
        db_manager = get_database_manager()
        status = db_manager.get_status_report()
        
        logger.info(f"ğŸ“Š ç³»ç»ŸçŠ¶æ€:")
        logger.error(f"  æ•°æ®åº“å¯ç”¨: {'âœ… æ˜¯' if status['database_available'] else 'âŒ å¦'}")
        logger.error(f"  MongoDB: {'âœ… å¯ç”¨' if status['mongodb']['available'] else 'âŒ ä¸å¯ç”¨'}")
        logger.error(f"  Redis: {'âœ… å¯ç”¨' if status['redis']['available'] else 'âŒ ä¸å¯ç”¨'}")
        logger.info(f"  ç¼“å­˜åç«¯: {status['cache_backend']}")
        
        # æµ‹è¯•ç¼“å­˜ç³»ç»Ÿ
        from tradingagents.dataflows.integrated_cache import get_cache
        
        cache = get_cache()
        performance_mode = cache.get_performance_mode()
        logger.info(f"  æ€§èƒ½æ¨¡å¼: {performance_mode}")
        
        # ç®€å•åŠŸèƒ½æµ‹è¯•
        test_key = cache.save_stock_data("INIT_TEST", "åˆå§‹åŒ–æµ‹è¯•æ•°æ®", data_source="init")
        test_data = cache.load_stock_data(test_key)
        
        if test_data == "åˆå§‹åŒ–æµ‹è¯•æ•°æ®":
            logger.info(f"âœ… ç¼“å­˜åŠŸèƒ½æµ‹è¯•é€šè¿‡")
        else:
            logger.error(f"âŒ ç¼“å­˜åŠŸèƒ½æµ‹è¯•å¤±è´¥")
            return False
        
    except Exception as e:
        logger.error(f"âŒ ç³»ç»Ÿæµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False
    
    # 8. ç”Ÿæˆä½¿ç”¨æŒ‡å—
    logger.info(f"\nğŸ“‹ ç”Ÿæˆä½¿ç”¨æŒ‡å—...")
    
    usage_guide = f"""# TradingAgents ç³»ç»Ÿé…ç½®

## å½“å‰é…ç½®

- **æ•°æ®åº“å¯ç”¨**: {'æ˜¯' if mongodb_available or redis_available else 'å¦'}
- **MongoDB**: {'âœ… å¯ç”¨' if mongodb_available else 'âŒ ä¸å¯ç”¨'}
- **Redis**: {'âœ… å¯ç”¨' if redis_available else 'âŒ ä¸å¯ç”¨'}
- **ä¸»è¦ç¼“å­˜åç«¯**: {primary_backend}
- **æ€§èƒ½æ¨¡å¼**: {cache.get_performance_mode() if 'cache' in locals() else 'æœªçŸ¥'}

## ç³»ç»Ÿç‰¹æ€§

### è‡ªåŠ¨é™çº§æ”¯æŒ
- ç³»ç»Ÿä¼šè‡ªåŠ¨æ£€æµ‹å¯ç”¨çš„æ•°æ®åº“æœåŠ¡
- å¦‚æœæ•°æ®åº“ä¸å¯ç”¨ï¼Œè‡ªåŠ¨ä½¿ç”¨æ–‡ä»¶ç¼“å­˜
- ä¿è¯ç³»ç»Ÿåœ¨ä»»ä½•ç¯å¢ƒä¸‹éƒ½èƒ½æ­£å¸¸è¿è¡Œ

### æ€§èƒ½ä¼˜åŒ–
- æ™ºèƒ½ç¼“å­˜ç­–ç•¥ï¼Œå‡å°‘APIè°ƒç”¨
- æ”¯æŒå¤šç§æ•°æ®ç±»å‹çš„TTLç®¡ç†
- è‡ªåŠ¨æ¸…ç†è¿‡æœŸç¼“å­˜

## ä½¿ç”¨æ–¹æ³•

### åŸºæœ¬ä½¿ç”¨
```python
from tradingagents.dataflows.integrated_cache import get_cache

# è·å–ç¼“å­˜å®ä¾‹
cache = get_cache()

# ä¿å­˜æ•°æ®
cache_key = cache.save_stock_data("AAPL", stock_data)

# åŠ è½½æ•°æ®
data = cache.load_stock_data(cache_key)
```

### æ£€æŸ¥ç³»ç»ŸçŠ¶æ€
```bash
python scripts/validation/check_system_status.py
```

## æ€§èƒ½æå‡å»ºè®®

"""

    if not mongodb_available and not redis_available:
        usage_guide += """
### å®‰è£…æ•°æ®åº“ä»¥è·å¾—æ›´å¥½æ€§èƒ½

1. **å®‰è£…Pythonä¾èµ–**:
   ```bash
   pip install pymongo redis
   ```

2. **å¯åŠ¨MongoDB** (å¯é€‰):
   ```bash
   docker run -d -p 27017:27017 --name mongodb mongo:4.4
   ```

3. **å¯åŠ¨Redis** (å¯é€‰):
   ```bash
   docker run -d -p 6379:6379 --name redis redis:alpine
   ```

4. **é‡æ–°åˆå§‹åŒ–ç³»ç»Ÿ**:
   ```bash
   python scripts/setup/initialize_system.py
   ```
"""
    else:
        usage_guide += """
### ç³»ç»Ÿå·²ä¼˜åŒ–
âœ… æ•°æ®åº“æœåŠ¡å¯ç”¨ï¼Œç³»ç»Ÿè¿è¡Œåœ¨æœ€ä½³æ€§èƒ½æ¨¡å¼
"""
    
    usage_file = project_root / "SYSTEM_SETUP_GUIDE.md"
    try:
        with open(usage_file, 'w', encoding='utf-8') as f:
            f.write(usage_guide)
        logger.info(f"âœ… ä½¿ç”¨æŒ‡å—å·²ç”Ÿæˆ: {usage_file}")
    except Exception as e:
        logger.error(f"âš ï¸ ä½¿ç”¨æŒ‡å—ç”Ÿæˆå¤±è´¥: {e}")
    
    # 9. æ€»ç»“
    logger.info(f"\n")
    logger.info(f"ğŸ‰ ç³»ç»Ÿåˆå§‹åŒ–å®Œæˆ!")
    logger.info(f"\nğŸ“Š åˆå§‹åŒ–ç»“æœ:")
    logger.info(f"  é…ç½®æ–‡ä»¶: âœ… å·²åˆ›å»º")
    logger.info(f"  ç¼“å­˜ç›®å½•: âœ… å·²åˆ›å»º")
    logger.info(f"  æ•°æ®åº“æ£€æµ‹: âœ… å·²å®Œæˆ")
    logger.info(f"  ç³»ç»Ÿæµ‹è¯•: âœ… å·²é€šè¿‡")
    logger.info(f"  ä½¿ç”¨æŒ‡å—: âœ… å·²ç”Ÿæˆ")
    
    if mongodb_available or redis_available:
        logger.info(f"\nğŸš€ ç³»ç»Ÿè¿è¡Œåœ¨é«˜æ€§èƒ½æ¨¡å¼!")
    else:
        logger.info(f"\nğŸ“ ç³»ç»Ÿè¿è¡Œåœ¨æ–‡ä»¶ç¼“å­˜æ¨¡å¼")
        logger.info(f"ğŸ’¡ å®‰è£…MongoDB/Rediså¯è·å¾—æ›´å¥½æ€§èƒ½")
    
    logger.info(f"\nğŸ¯ ä¸‹ä¸€æ­¥:")
    logger.info(f"1. è¿è¡Œç³»ç»ŸçŠ¶æ€æ£€æŸ¥: python scripts/validation/check_system_status.py")
    logger.info(f"2. æŸ¥çœ‹ä½¿ç”¨æŒ‡å—: {usage_file}")
    logger.info(f"3. å¼€å§‹ä½¿ç”¨TradingAgents!")
    
    return True

def main():
    """ä¸»å‡½æ•°"""
    try:
        success = initialize_system()
        return success
    except Exception as e:
        logger.error(f"âŒ ç³»ç»Ÿåˆå§‹åŒ–å¤±è´¥: {e}")
        import traceback

        traceback.print_exc()
        return False

if __name__ == "__main__":
    success = main()
    sys.exit(0 if success else 1)
