#!/usr/bin/env python3
"""
ç³»ç»ŸçŠ¶æ€æ£€æŸ¥è„šæœ¬
æ£€æŸ¥æ•°æ®åº“é…ç½®å’Œç¼“å­˜ç³»ç»ŸçŠ¶æ€
"""

import sys
import os
from pathlib import Path

# å¯¼å…¥æ—¥å¿—æ¨¡å—
from tradingagents.utils.logging_manager import get_logger
logger = get_logger('scripts')

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
project_root = Path(__file__).parent.parent.parent
sys.path.insert(0, str(project_root))

def check_system_status():
    """æ£€æŸ¥ç³»ç»ŸçŠ¶æ€"""
    logger.debug(f"ğŸ” TradingAgents ç³»ç»ŸçŠ¶æ€æ£€æŸ¥")
    logger.info(f"=")
    
    # æ£€æŸ¥ç¯å¢ƒé…ç½®æ–‡ä»¶
    logger.info(f"\nğŸ“ æ£€æŸ¥ç¯å¢ƒé…ç½®...")
    env_file = project_root / ".env"
    env_example_file = project_root / ".env.example"

    if env_file.exists():
        logger.info(f"âœ… ç¯å¢ƒé…ç½®æ–‡ä»¶å­˜åœ¨: {env_file}")

        try:
            import os
            from dotenv import load_dotenv

            # åŠ è½½ç¯å¢ƒå˜é‡
            load_dotenv(env_file)

            logger.info(f"ğŸ“Š æ•°æ®åº“é…ç½®çŠ¶æ€:")
            mongodb_enabled = os.getenv('MONGODB_ENABLED', 'false').lower() == 'true'
            redis_enabled = os.getenv('REDIS_ENABLED', 'false').lower() == 'true'
            mongodb_host = os.getenv('MONGODB_HOST', 'localhost')
            mongodb_port = os.getenv('MONGODB_PORT', '27017')
            redis_host = os.getenv('REDIS_HOST', 'localhost')
            redis_port = os.getenv('REDIS_PORT', '6379')

            logger.error(f"  MongoDBå¯ç”¨: {'âœ… æ˜¯' if mongodb_enabled else 'âŒ å¦'}")
            logger.info(f"  MongoDBåœ°å€: {mongodb_host}:{mongodb_port}")
            logger.error(f"  Rediså¯ç”¨: {'âœ… æ˜¯' if redis_enabled else 'âŒ å¦'}")
            logger.info(f"  Redisåœ°å€: {redis_host}:{redis_port}")

            logger.info(f"\nğŸ“Š APIå¯†é’¥é…ç½®çŠ¶æ€:")
            api_keys = {
                'DASHSCOPE_API_KEY': 'é˜¿é‡Œç™¾ç‚¼',
                'FINNHUB_API_KEY': 'FinnHub',
                'TUSHARE_TOKEN': 'Tushare',
                'GOOGLE_API_KEY': 'Google AI',
                'DEEPSEEK_API_KEY': 'DeepSeek'
            }

            for key, name in api_keys.items():
                value = os.getenv(key, '')
                if value and value != f'your_{key.lower()}_here':
                    logger.info(f"  {name}: âœ… å·²é…ç½®")
                else:
                    logger.error(f"  {name}: âŒ æœªé…ç½®")

        except ImportError:
            logger.warning(f"âš ï¸ python-dotenvæœªå®‰è£…ï¼Œæ— æ³•è§£æ.envæ–‡ä»¶")
        except Exception as e:
            logger.error(f"âŒ ç¯å¢ƒé…ç½®è§£æå¤±è´¥: {e}")
    else:
        logger.error(f"âŒ ç¯å¢ƒé…ç½®æ–‡ä»¶ä¸å­˜åœ¨: {env_file}")
        if env_example_file.exists():
            logger.info(f"ğŸ’¡ è¯·å¤åˆ¶ {env_example_file} ä¸º {env_file} å¹¶é…ç½®APIå¯†é’¥")
    
    # æ£€æŸ¥æ•°æ®åº“ç®¡ç†å™¨
    logger.info(f"\nğŸ”§ æ£€æŸ¥æ•°æ®åº“ç®¡ç†å™¨...")
    try:
        from tradingagents.config.database_manager import get_database_manager
        
        db_manager = get_database_manager()
        status = db_manager.get_status_report()
        
        logger.info(f"ğŸ“Š æ•°æ®åº“çŠ¶æ€:")
        logger.error(f"  æ•°æ®åº“å¯ç”¨: {'âœ… æ˜¯' if status['database_available'] else 'âŒ å¦'}")
        logger.error(f"  MongoDB: {'âœ… å¯ç”¨' if status['mongodb']['available'] else 'âŒ ä¸å¯ç”¨'}")
        logger.error(f"  Redis: {'âœ… å¯ç”¨' if status['redis']['available'] else 'âŒ ä¸å¯ç”¨'}")
        logger.info(f"  ç¼“å­˜åç«¯: {status['cache_backend']}")
        logger.error(f"  é™çº§æ”¯æŒ: {'âœ… å¯ç”¨' if status['fallback_enabled'] else 'âŒ ç¦ç”¨'}")
        
    except Exception as e:
        logger.error(f"âŒ æ•°æ®åº“ç®¡ç†å™¨æ£€æŸ¥å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
    
    # æ£€æŸ¥ç¼“å­˜ç³»ç»Ÿ
    logger.info(f"\nğŸ’¾ æ£€æŸ¥ç¼“å­˜ç³»ç»Ÿ...")
    try:
        from tradingagents.dataflows.integrated_cache import get_cache
        
        cache = get_cache()
        backend_info = cache.get_cache_backend_info()
        
        logger.info(f"ğŸ“Š ç¼“å­˜ç³»ç»ŸçŠ¶æ€:")
        logger.info(f"  ç¼“å­˜ç³»ç»Ÿ: {backend_info['system']}")
        logger.info(f"  ä¸»è¦åç«¯: {backend_info['primary_backend']}")
        logger.error(f"  é™çº§æ”¯æŒ: {'âœ… å¯ç”¨' if backend_info['fallback_enabled'] else 'âŒ ç¦ç”¨'}")
        logger.info(f"  æ€§èƒ½æ¨¡å¼: {cache.get_performance_mode()}")
        
        # è·å–è¯¦ç»†ç»Ÿè®¡
        stats = cache.get_cache_stats()
        if 'adaptive_cache' in stats:
            adaptive_stats = stats['adaptive_cache']
            logger.info(f"  æ–‡ä»¶ç¼“å­˜æ•°é‡: {adaptive_stats.get('file_cache_count', 0)}")
            if 'redis_keys' in adaptive_stats:
                logger.info(f"  Redisé”®æ•°é‡: {adaptive_stats['redis_keys']}")
            if 'mongodb_cache_count' in adaptive_stats:
                logger.info(f"  MongoDBç¼“å­˜æ•°é‡: {adaptive_stats['mongodb_cache_count']}")
        
    except Exception as e:
        logger.error(f"âŒ ç¼“å­˜ç³»ç»Ÿæ£€æŸ¥å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
    
    # æµ‹è¯•ç¼“å­˜åŠŸèƒ½
    logger.info(f"\nğŸ§ª æµ‹è¯•ç¼“å­˜åŠŸèƒ½...")
    try:
        from tradingagents.dataflows.integrated_cache import get_cache
        from datetime import datetime
        
        cache = get_cache()
        
        # æµ‹è¯•æ•°æ®ä¿å­˜
        test_data = f"æµ‹è¯•æ•°æ® - {datetime.now()}"
        cache_key = cache.save_stock_data(
            symbol="TEST",
            data=test_data,
            start_date="2024-01-01",
            end_date="2024-12-31",
            data_source="system_test"
        )
        logger.info(f"âœ… æ•°æ®ä¿å­˜æˆåŠŸ: {cache_key}")
        
        # æµ‹è¯•æ•°æ®åŠ è½½
        loaded_data = cache.load_stock_data(cache_key)
        if loaded_data == test_data:
            logger.info(f"âœ… æ•°æ®åŠ è½½æˆåŠŸï¼Œå†…å®¹åŒ¹é…")
        else:
            logger.error(f"âŒ æ•°æ®åŠ è½½å¤±è´¥æˆ–å†…å®¹ä¸åŒ¹é…")
        
        # æµ‹è¯•æ•°æ®æŸ¥æ‰¾
        found_key = cache.find_cached_stock_data(
            symbol="TEST",
            start_date="2024-01-01",
            end_date="2024-12-31",
            data_source="system_test"
        )
        
        if found_key:
            logger.info(f"âœ… ç¼“å­˜æŸ¥æ‰¾æˆåŠŸ: {found_key}")
        else:
            logger.error(f"âŒ ç¼“å­˜æŸ¥æ‰¾å¤±è´¥")
        
    except Exception as e:
        logger.error(f"âŒ ç¼“å­˜åŠŸèƒ½æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
    
    # æ€§èƒ½æµ‹è¯•
    logger.info(f"\nâš¡ ç®€å•æ€§èƒ½æµ‹è¯•...")
    try:
        import time
        from tradingagents.dataflows.integrated_cache import get_cache
        
        cache = get_cache()
        
        # ä¿å­˜æ€§èƒ½æµ‹è¯•
        start_time = time.time()
        cache_key = cache.save_stock_data(
            symbol="PERF",
            data="æ€§èƒ½æµ‹è¯•æ•°æ®",
            start_date="2024-01-01",
            end_date="2024-12-31",
            data_source="perf_test"
        )
        save_time = time.time() - start_time
        
        # åŠ è½½æ€§èƒ½æµ‹è¯•
        start_time = time.time()
        data = cache.load_stock_data(cache_key)
        load_time = time.time() - start_time
        
        logger.info(f"ğŸ“Š æ€§èƒ½æµ‹è¯•ç»“æœ:")
        logger.info(f"  ä¿å­˜æ—¶é—´: {save_time:.4f}ç§’")
        logger.info(f"  åŠ è½½æ—¶é—´: {load_time:.4f}ç§’")
        
        if load_time < 0.1:
            logger.info(f"âœ… ç¼“å­˜æ€§èƒ½è‰¯å¥½ (<0.1ç§’)")
        else:
            logger.warning(f"âš ï¸ ç¼“å­˜æ€§èƒ½éœ€è¦ä¼˜åŒ–")
        
        # è®¡ç®—æ€§èƒ½æ”¹è¿›
        api_simulation_time = 2.0  # å‡è®¾APIè°ƒç”¨éœ€è¦2ç§’
        if load_time < api_simulation_time:
            improvement = ((api_simulation_time - load_time) / api_simulation_time) * 100
            logger.info(f"ğŸš€ ç›¸æ¯”APIè°ƒç”¨æ€§èƒ½æå‡: {improvement:.1f}%")
        
    except Exception as e:
        logger.error(f"âŒ æ€§èƒ½æµ‹è¯•å¤±è´¥: {e}")
    
    # ç³»ç»Ÿå»ºè®®
    logger.info(f"\nğŸ’¡ ç³»ç»Ÿå»ºè®®:")
    try:
        from tradingagents.dataflows.integrated_cache import get_cache
        
        cache = get_cache()
        
        if cache.is_database_available():
            logger.info(f"âœ… æ•°æ®åº“å¯ç”¨ï¼Œç³»ç»Ÿè¿è¡Œåœ¨æœ€ä½³æ€§èƒ½æ¨¡å¼")
        else:
            logger.info(f"â„¹ï¸ æ•°æ®åº“ä¸å¯ç”¨ï¼Œç³»ç»Ÿä½¿ç”¨æ–‡ä»¶ç¼“å­˜æ¨¡å¼")
            logger.info(f"ğŸ’¡ æå‡æ€§èƒ½å»ºè®®:")
            logger.info(f"  1. é…ç½®ç¯å¢ƒå˜é‡å¯ç”¨æ•°æ®åº“:")
            logger.info(f"     MONGODB_ENABLED=true")
            logger.info(f"     REDIS_ENABLED=true")
            logger.info(f"  2. å¯åŠ¨æ•°æ®åº“æœåŠ¡:")
            logger.info(f"     docker-compose up -d  # æ¨èæ–¹å¼")
            logger.info(f"     æˆ–æ‰‹åŠ¨å¯åŠ¨:")
            logger.info(f"     - MongoDB: docker run -d -p 27017:27017 mongo:4.4")
            logger.info(f"     - Redis: docker run -d -p 6379:6379 redis:alpine")
        
        performance_mode = cache.get_performance_mode()
        logger.info(f"ğŸ¯ å½“å‰æ€§èƒ½æ¨¡å¼: {performance_mode}")
        
    except Exception as e:
        logger.warning(f"âš ï¸ æ— æ³•ç”Ÿæˆç³»ç»Ÿå»ºè®®: {e}")
    
    logger.info(f"\n")
    logger.info(f"ğŸ‰ ç³»ç»ŸçŠ¶æ€æ£€æŸ¥å®Œæˆ!")

def main():
    """ä¸»å‡½æ•°"""
    try:
        check_system_status()
        return True
    except Exception as e:
        logger.error(f"âŒ ç³»ç»Ÿæ£€æŸ¥å¤±è´¥: {e}")
        import traceback

        traceback.print_exc()
        return False

if __name__ == "__main__":
    success = main()
    sys.exit(0 if success else 1)
