#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Finnhubæ•°æ®ä¸‹è½½è„šæœ¬

è¿™ä¸ªè„šæœ¬ç”¨äºä»Finnhub APIä¸‹è½½æ–°é—»æ•°æ®ã€å†…éƒ¨äººæƒ…ç»ªæ•°æ®å’Œå†…éƒ¨äººäº¤æ˜“æ•°æ®ã€‚
æ”¯æŒæ‰¹é‡ä¸‹è½½å’Œå¢é‡æ›´æ–°ã€‚

ä½¿ç”¨æ–¹æ³•:
    python scripts/download_finnhub_data.py --data-type news --symbols AAPL,TSLA,MSFT
    python scripts/download_finnhub_data.py --all
    python scripts/download_finnhub_data.py --force-refresh
"""

import os
import sys
import json
import argparse
import requests
import time
from pathlib import Path
from datetime import datetime, timedelta
from typing import List, Dict, Any

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

# å¯¼å…¥é¡¹ç›®æ¨¡å—
try:
    from tradingagents.utils.logging_manager import get_logger
    from tradingagents.config.config_manager import config_manager
    logger = get_logger('finnhub_downloader')
except ImportError as e:
    print(f"âŒ å¯¼å…¥æ¨¡å—å¤±è´¥: {e}")
    print("è¯·ç¡®ä¿åœ¨é¡¹ç›®æ ¹ç›®å½•è¿è¡Œæ­¤è„šæœ¬")
    sys.exit(1)

class FinnhubDataDownloader:
    """Finnhubæ•°æ®ä¸‹è½½å™¨"""
    
    def __init__(self, api_key: str = None, data_dir: str = None):
        """
        åˆå§‹åŒ–ä¸‹è½½å™¨
        
        Args:
            api_key: Finnhub APIå¯†é’¥
            data_dir: æ•°æ®å­˜å‚¨ç›®å½•
        """
        # è·å–APIå¯†é’¥
        self.api_key = api_key or os.getenv('FINNHUB_API_KEY')
        if not self.api_key:
            raise ValueError("âŒ æœªæ‰¾åˆ°Finnhub APIå¯†é’¥ï¼Œè¯·è®¾ç½®FINNHUB_API_KEYç¯å¢ƒå˜é‡")
        
        # è·å–æ•°æ®ç›®å½•
        if data_dir:
            self.data_dir = data_dir
        else:
            # ä¼˜å…ˆä½¿ç”¨ç¯å¢ƒå˜é‡ï¼Œç„¶åæ˜¯é¡¹ç›®æ ¹ç›®å½•
            env_data_dir = os.getenv('TRADINGAGENTS_DATA_DIR')
            if env_data_dir:
                self.data_dir = env_data_dir
            else:
                # ä½¿ç”¨é¡¹ç›®æ ¹ç›®å½•ä¸‹çš„dataç›®å½•
                self.data_dir = str(project_root / "data")

            logger.info(f"ğŸ” æ•°æ®ç›®å½•æ¥æº: {'ç¯å¢ƒå˜é‡' if env_data_dir else 'é¡¹ç›®æ ¹ç›®å½•'}")
        
        self.base_url = "https://finnhub.io/api/v1"
        self.session = requests.Session()
        
        logger.info(f"ğŸ“ æ•°æ®ç›®å½•: {self.data_dir}")
        logger.info(f"ğŸ”‘ APIå¯†é’¥: {self.api_key[:8]}...")
    
    def _make_request(self, endpoint: str, params: Dict[str, Any]) -> Dict[str, Any]:
        """
        å‘é€APIè¯·æ±‚
        
        Args:
            endpoint: APIç«¯ç‚¹
            params: è¯·æ±‚å‚æ•°
            
        Returns:
            APIå“åº”æ•°æ®
        """
        params['token'] = self.api_key
        url = f"{self.base_url}/{endpoint}"
        
        try:
            response = self.session.get(url, params=params, timeout=30)
            response.raise_for_status()
            
            # æ£€æŸ¥APIé™åˆ¶
            if response.status_code == 429:
                logger.warning("âš ï¸ APIè°ƒç”¨é¢‘ç‡é™åˆ¶ï¼Œç­‰å¾…60ç§’...")
                time.sleep(60)
                return self._make_request(endpoint, params)
            
            return response.json()
            
        except requests.exceptions.RequestException as e:
            logger.error(f"âŒ APIè¯·æ±‚å¤±è´¥: {e}")
            return {}
    
    def download_news_data(self, symbols: List[str], days: int = 7, force_refresh: bool = False):
        """
        ä¸‹è½½æ–°é—»æ•°æ®
        
        Args:
            symbols: è‚¡ç¥¨ä»£ç åˆ—è¡¨
            days: ä¸‹è½½å¤šå°‘å¤©çš„æ•°æ®
            force_refresh: æ˜¯å¦å¼ºåˆ¶åˆ·æ–°
        """
        logger.info(f"ğŸ“° å¼€å§‹ä¸‹è½½æ–°é—»æ•°æ®ï¼Œè‚¡ç¥¨: {symbols}, å¤©æ•°: {days}")
        
        # åˆ›å»ºç›®å½•
        news_dir = Path(self.data_dir) / "finnhub_data" / "news_data"
        news_dir.mkdir(parents=True, exist_ok=True)
        
        # è®¡ç®—æ—¥æœŸèŒƒå›´
        end_date = datetime.now()
        start_date = end_date - timedelta(days=days)
        
        for symbol in symbols:
            logger.info(f"ğŸ“° ä¸‹è½½ {symbol} çš„æ–°é—»æ•°æ®...")
            
            # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨ä¸”æœ‰æ•ˆ
            file_path = news_dir / f"{symbol}_data_formatted.json"
            if file_path.exists() and not force_refresh:
                # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦æœ‰å†…å®¹
                try:
                    file_size = file_path.stat().st_size
                    if file_size > 10:  # æ–‡ä»¶å¤§å°å¤§äº10å­—èŠ‚æ‰è®¤ä¸ºæœ‰æ•ˆ
                        logger.info(f"ğŸ“„ {symbol} æ•°æ®æ–‡ä»¶å·²å­˜åœ¨ä¸”æœ‰æ•ˆ (å¤§å°: {file_size} å­—èŠ‚)ï¼Œè·³è¿‡ä¸‹è½½")
                        continue
                    else:
                        logger.warning(f"âš ï¸ {symbol} æ•°æ®æ–‡ä»¶å­˜åœ¨ä½†ä¸ºç©º (å¤§å°: {file_size} å­—èŠ‚)ï¼Œé‡æ–°ä¸‹è½½")
                except Exception as e:
                    logger.warning(f"âš ï¸ æ£€æŸ¥ {symbol} æ–‡ä»¶çŠ¶æ€å¤±è´¥: {e}ï¼Œé‡æ–°ä¸‹è½½")

            logger.info(f"ğŸ“¥ å¼€å§‹ä¸‹è½½ {symbol} çš„æ–°é—»æ•°æ®...")
            
            # ä¸‹è½½æ–°é—»æ•°æ®
            params = {
                'symbol': symbol,
                'from': start_date.strftime('%Y-%m-%d'),
                'to': end_date.strftime('%Y-%m-%d')
            }
            
            news_data = self._make_request('company-news', params)

            logger.info(f"ğŸ” APIå“åº”ç±»å‹: {type(news_data)}, é•¿åº¦: {len(news_data) if isinstance(news_data, list) else 'N/A'}")

            if news_data and isinstance(news_data, list) and len(news_data) > 0:
                # æ ¼å¼åŒ–æ•°æ®
                formatted_data = []
                for item in news_data:
                    formatted_item = {
                        'datetime': item.get('datetime', 0),
                        'headline': item.get('headline', ''),
                        'summary': item.get('summary', ''),
                        'url': item.get('url', ''),
                        'source': item.get('source', ''),
                        'category': item.get('category', ''),
                        'sentiment': item.get('sentiment', {})
                    }
                    formatted_data.append(formatted_item)

                # ä¿å­˜æ•°æ®
                try:
                    with open(file_path, 'w', encoding='utf-8') as f:
                        json.dump(formatted_data, f, ensure_ascii=False, indent=2)

                    # éªŒè¯æ–‡ä»¶ä¿å­˜
                    if file_path.exists():
                        file_size = file_path.stat().st_size
                        logger.info(f"âœ… {symbol} æ–°é—»æ•°æ®å·²ä¿å­˜: {len(formatted_data)} æ¡, æ–‡ä»¶å¤§å°: {file_size} å­—èŠ‚")
                    else:
                        logger.error(f"âŒ {symbol} æ–‡ä»¶ä¿å­˜å¤±è´¥ï¼Œæ–‡ä»¶ä¸å­˜åœ¨")

                except Exception as e:
                    logger.error(f"âŒ {symbol} æ–‡ä»¶ä¿å­˜å¼‚å¸¸: {e}")

            elif news_data and isinstance(news_data, dict):
                logger.warning(f"âš ï¸ {symbol} APIè¿”å›å­—å…¸è€Œéåˆ—è¡¨: {news_data}")
            else:
                logger.warning(f"âš ï¸ {symbol} æ–°é—»æ•°æ®ä¸‹è½½å¤±è´¥æˆ–ä¸ºç©º")
            
            # é¿å…APIé™åˆ¶
            time.sleep(1)
    
    def download_insider_sentiment(self, symbols: List[str], force_refresh: bool = False):
        """
        ä¸‹è½½å†…éƒ¨äººæƒ…ç»ªæ•°æ®
        
        Args:
            symbols: è‚¡ç¥¨ä»£ç åˆ—è¡¨
            force_refresh: æ˜¯å¦å¼ºåˆ¶åˆ·æ–°
        """
        logger.info(f"ğŸ’­ å¼€å§‹ä¸‹è½½å†…éƒ¨äººæƒ…ç»ªæ•°æ®ï¼Œè‚¡ç¥¨: {symbols}")
        
        # åˆ›å»ºç›®å½•
        sentiment_dir = Path(self.data_dir) / "finnhub_data" / "insider_senti"
        sentiment_dir.mkdir(parents=True, exist_ok=True)
        
        for symbol in symbols:
            logger.info(f"ğŸ’­ ä¸‹è½½ {symbol} çš„å†…éƒ¨äººæƒ…ç»ªæ•°æ®...")
            
            # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
            file_path = sentiment_dir / f"{symbol}_data_formatted.json"
            if file_path.exists() and not force_refresh:
                logger.info(f"ğŸ“„ {symbol} æƒ…ç»ªæ•°æ®æ–‡ä»¶å·²å­˜åœ¨ï¼Œè·³è¿‡ä¸‹è½½")
                continue
            
            # ä¸‹è½½æƒ…ç»ªæ•°æ®
            params = {'symbol': symbol}
            sentiment_data = self._make_request('stock/insider-sentiment', params)
            
            if sentiment_data and 'data' in sentiment_data:
                # ä¿å­˜æ•°æ®
                with open(file_path, 'w', encoding='utf-8') as f:
                    json.dump(sentiment_data, f, ensure_ascii=False, indent=2)
                
                logger.info(f"âœ… {symbol} å†…éƒ¨äººæƒ…ç»ªæ•°æ®å·²ä¿å­˜")
            else:
                logger.warning(f"âš ï¸ {symbol} å†…éƒ¨äººæƒ…ç»ªæ•°æ®ä¸‹è½½å¤±è´¥")
            
            # é¿å…APIé™åˆ¶
            time.sleep(1)
    
    def download_insider_transactions(self, symbols: List[str], force_refresh: bool = False):
        """
        ä¸‹è½½å†…éƒ¨äººäº¤æ˜“æ•°æ®
        
        Args:
            symbols: è‚¡ç¥¨ä»£ç åˆ—è¡¨
            force_refresh: æ˜¯å¦å¼ºåˆ¶åˆ·æ–°
        """
        logger.info(f"ğŸ’° å¼€å§‹ä¸‹è½½å†…éƒ¨äººäº¤æ˜“æ•°æ®ï¼Œè‚¡ç¥¨: {symbols}")
        
        # åˆ›å»ºç›®å½•
        trans_dir = Path(self.data_dir) / "finnhub_data" / "insider_trans"
        trans_dir.mkdir(parents=True, exist_ok=True)
        
        for symbol in symbols:
            logger.info(f"ğŸ’° ä¸‹è½½ {symbol} çš„å†…éƒ¨äººäº¤æ˜“æ•°æ®...")
            
            # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
            file_path = trans_dir / f"{symbol}_data_formatted.json"
            if file_path.exists() and not force_refresh:
                logger.info(f"ğŸ“„ {symbol} äº¤æ˜“æ•°æ®æ–‡ä»¶å·²å­˜åœ¨ï¼Œè·³è¿‡ä¸‹è½½")
                continue
            
            # ä¸‹è½½äº¤æ˜“æ•°æ®
            params = {'symbol': symbol}
            trans_data = self._make_request('stock/insider-transactions', params)
            
            if trans_data and 'data' in trans_data:
                # ä¿å­˜æ•°æ®
                with open(file_path, 'w', encoding='utf-8') as f:
                    json.dump(trans_data, f, ensure_ascii=False, indent=2)
                
                logger.info(f"âœ… {symbol} å†…éƒ¨äººäº¤æ˜“æ•°æ®å·²ä¿å­˜")
            else:
                logger.warning(f"âš ï¸ {symbol} å†…éƒ¨äººäº¤æ˜“æ•°æ®ä¸‹è½½å¤±è´¥")
            
            # é¿å…APIé™åˆ¶
            time.sleep(1)

def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(description='Finnhubæ•°æ®ä¸‹è½½è„šæœ¬')
    
    parser.add_argument('--data-type', 
                       choices=['news', 'sentiment', 'transactions', 'all'],
                       default='all',
                       help='è¦ä¸‹è½½çš„æ•°æ®ç±»å‹')
    
    parser.add_argument('--symbols',
                       type=str,
                       default='AAPL,TSLA,MSFT,GOOGL,AMZN',
                       help='è‚¡ç¥¨ä»£ç ï¼Œç”¨é€—å·åˆ†éš”')
    
    parser.add_argument('--days',
                       type=int,
                       default=7,
                       help='ä¸‹è½½å¤šå°‘å¤©çš„æ–°é—»æ•°æ®')
    
    parser.add_argument('--force-refresh',
                       action='store_true',
                       help='å¼ºåˆ¶åˆ·æ–°å·²å­˜åœ¨çš„æ•°æ®')
    
    parser.add_argument('--all',
                       action='store_true',
                       help='ä¸‹è½½æ‰€æœ‰ç±»å‹çš„æ•°æ®')
    
    parser.add_argument('--api-key',
                       type=str,
                       help='Finnhub APIå¯†é’¥')
    
    parser.add_argument('--data-dir',
                       type=str,
                       help='æ•°æ®å­˜å‚¨ç›®å½•')
    
    args = parser.parse_args()
    
    # è§£æè‚¡ç¥¨ä»£ç 
    symbols = [s.strip().upper() for s in args.symbols.split(',')]
    
    try:
        # åˆ›å»ºä¸‹è½½å™¨
        downloader = FinnhubDataDownloader(
            api_key=args.api_key,
            data_dir=args.data_dir
        )
        
        # ç¡®å®šè¦ä¸‹è½½çš„æ•°æ®ç±»å‹
        if args.all:
            data_types = ['news', 'sentiment', 'transactions']
        else:
            data_types = [args.data_type] if args.data_type != 'all' else ['news', 'sentiment', 'transactions']
        
        logger.info(f"ğŸš€ å¼€å§‹ä¸‹è½½Finnhubæ•°æ®")
        logger.info(f"ğŸ“Š è‚¡ç¥¨ä»£ç : {symbols}")
        logger.info(f"ğŸ“‹ æ•°æ®ç±»å‹: {data_types}")
        logger.info(f"ğŸ”„ å¼ºåˆ¶åˆ·æ–°: {args.force_refresh}")
        
        # ä¸‹è½½æ•°æ®
        for data_type in data_types:
            if data_type == 'news':
                downloader.download_news_data(symbols, args.days, args.force_refresh)
            elif data_type == 'sentiment':
                downloader.download_insider_sentiment(symbols, args.force_refresh)
            elif data_type == 'transactions':
                downloader.download_insider_transactions(symbols, args.force_refresh)
        
        logger.info("ğŸ‰ æ•°æ®ä¸‹è½½å®Œæˆï¼")
        
    except Exception as e:
        logger.error(f"âŒ ä¸‹è½½å¤±è´¥: {e}")
        sys.exit(1)

if __name__ == "__main__":
    main()
