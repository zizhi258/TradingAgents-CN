"""
å¢å¼ºçš„å¤šæ¨¡å‹åä½œåˆ†æè¡¨å•ç»„ä»¶
æ”¹è¿›ç”¨æˆ·ä½“éªŒã€é”™è¯¯å¤„ç†å’Œè¿›åº¦åé¦ˆ
"""

import streamlit as st
import datetime
import os
import time
import asyncio
from pathlib import Path
from typing import Dict, Any, Optional, List
import traceback

# å¯¼å…¥æ—¥å¿—æ¨¡å—
from tradingagents.utils.logging_manager import get_logger
logger = get_logger('web')

# å¯¼å…¥é”™è¯¯å¤„ç†å™¨
from tradingagents.core.user_friendly_error_handler import handle_user_friendly_error

# å¯¼å…¥å¯å¤ç”¨æ¨¡å‹é€‰æ‹©é¢æ¿ï¼ˆå¸¦å¼€å…³çš„ç²¾ç®€ç‰ˆï¼‰
from .model_selection_panel import (
    render_model_selection_panel,
    render_routing_section,
    render_advanced_overrides_section,
    render_basic_advanced_settings,
)


class AnalysisProgressTracker:
    """åˆ†æè¿›åº¦è·Ÿè¸ªå™¨"""
    
    def __init__(self):
        self.start_time = None
        self.current_stage = "å‡†å¤‡ä¸­"
        self.progress_percentage = 0
        self.stage_details = ""
        self.estimated_time_remaining = None
        self.is_cancellable = True
        self.cancel_requested = False
        
        # å®šä¹‰åˆ†æé˜¶æ®µ
        self.stages = {
            "preparation": {
                "name": "ğŸ› ï¸ å‡†å¤‡åˆ†æç¯å¢ƒ",
                "progress_range": (0, 10),
                "estimated_seconds": 5
            },
            "data_collection": {
                "name": "ğŸ“Š æ”¶é›†è‚¡ç¥¨æ•°æ®",
                "progress_range": (10, 25),
                "estimated_seconds": 15
            },
            "model_initialization": {
                "name": "ğŸ¤– åˆå§‹åŒ–AIæ¨¡å‹",
                "progress_range": (25, 35),
                "estimated_seconds": 10
            },
            "agent_analysis": {
                "name": "ğŸ’¼ æ™ºèƒ½ä½“åä½œåˆ†æ",
                "progress_range": (35, 80),
                "estimated_seconds": 120
            },
            "result_synthesis": {
                "name": "ğŸ“‹ ç»“æœæ•´åˆä¸ç”Ÿæˆ",
                "progress_range": (80, 95),
                "estimated_seconds": 15
            },
            "completion": {
                "name": "âœ¨ åˆ†æå®Œæˆ",
                "progress_range": (95, 100),
                "estimated_seconds": 5
            }
        }
    
    def start_analysis(self):
        """å¼€å§‹åˆ†æ"""
        self.start_time = time.time()
        self.current_stage = "preparation"
        self.progress_percentage = 0
        self.cancel_requested = False
        
        # è®¡ç®—æ€»ä¼°è®¡æ—¶é—´
        total_estimated = sum(stage["estimated_seconds"] for stage in self.stages.values())
        self.estimated_total_time = total_estimated
    
    def update_stage(self, stage_key: str, details: str = ""):
        """æ›´æ–°å½“å‰é˜¶æ®µ"""
        if stage_key in self.stages:
            self.current_stage = stage_key
            self.stage_details = details
            
            # æ›´æ–°è¿›åº¦ç™¾åˆ†æ¯”åˆ°é˜¶æ®µèµ·å§‹ç‚¹
            stage_info = self.stages[stage_key]
            self.progress_percentage = stage_info["progress_range"][0]
            
            # æ›´æ–°é¢„ä¼°å‰©ä½™æ—¶é—´
            elapsed = time.time() - self.start_time if self.start_time else 0
            remaining_stages = [k for k in self.stages.keys() if list(self.stages.keys()).index(k) > list(self.stages.keys()).index(stage_key)]
            remaining_time = sum(self.stages[k]["estimated_seconds"] for k in remaining_stages)
            self.estimated_time_remaining = remaining_time
    
    def update_progress(self, percentage: float, details: str = ""):
        """æ›´æ–°è¿›åº¦ç™¾åˆ†æ¯”"""
        self.progress_percentage = min(100, max(0, percentage))
        if details:
            self.stage_details = details
    
    def request_cancel(self):
        """è¯·æ±‚å–æ¶ˆåˆ†æ"""
        self.cancel_requested = True
        self.is_cancellable = False
    
    def is_cancelled(self) -> bool:
        """æ£€æŸ¥æ˜¯å¦å·²è¯·æ±‚å–æ¶ˆ"""
        return self.cancel_requested
    
    def get_display_info(self) -> Dict[str, Any]:
        """è·å–ç”¨äºç•Œé¢æ˜¾ç¤ºçš„ä¿¡æ¯"""
        current_stage_info = self.stages.get(self.current_stage, {})
        
        return {
            "current_stage": current_stage_info.get("name", self.current_stage),
            "progress_percentage": self.progress_percentage,
            "details": self.stage_details,
            "estimated_time_remaining": self.estimated_time_remaining,
            "elapsed_time": time.time() - self.start_time if self.start_time else 0,
            "is_cancellable": self.is_cancellable,
            "status": "running" if not self.cancel_requested else "cancelling"
        }


def render_enhanced_multi_model_analysis_form():
    """æ¸²æŸ“å¢å¼ºçš„å¤šæ¨¡å‹åä½œåˆ†æè¡¨å•"""
    
    st.subheader("ğŸ¤– æ™ºèƒ½å¤šæ¨¡å‹åä½œåˆ†æ")
    
    # æ£€æŸ¥ç³»ç»ŸçŠ¶æ€
    system_status = check_system_health()
    display_system_status(system_status)
    
    # è·å–ç¼“å­˜çš„è¡¨å•é…ç½®ï¼ˆç¡®ä¿ä¸ä¸ºNoneï¼‰
    cached_config = st.session_state.get('enhanced_multi_model_config') or {}
    
    # åˆ›å»ºè¡¨å•
    with st.form("enhanced_multi_model_analysis_form", clear_on_submit=False):
        # ä½¿ç”¨åˆ†æ /é¡µç­¾çš„ç²¾ç®€é…ç½®é¢æ¿ï¼Œæ›¿ä»£å†—é•¿ç«–æ’
        full_config = render_compact_multi_model_config_panel(cached_config)
        
        # æäº¤æŒ‰é’®
        st.markdown("---")
        col1, col2, col3 = st.columns([1, 2, 1])
        
        with col2:
            submitted = st.form_submit_button(
                "ğŸš€ å¼€å§‹æ™ºèƒ½åˆ†æ",
                use_container_width=True,
                type="primary"
            )
    
    # å¤„ç†è¡¨å•æäº¤
    if submitted:
        handle_analysis_submission(full_config)


def render_compact_multi_model_config_panel(cached_config: Dict[str, Any]) -> Dict[str, Any]:
    """åˆ†åŒºåˆ†é¡µçš„å¤šæ¨¡å‹é…ç½®é¢æ¿ï¼ˆå»é™¤é‡å¤çš„è§’è‰²é…ç½®ï¼Œé›†ä¸­åˆ°â€˜ğŸ§­ è§’è‰²ä¸­å¿ƒâ€™ï¼‰"""
    tabs = st.tabs(["åŸºç¡€ä¿¡æ¯", "æ¨¡å‹ä¸æä¾›å•†", "åä½œä¸æ™ºèƒ½ä½“", "è·¯ç”±ä¸é¢„ç®—", "é«˜çº§è®¾ç½®"])

    # 1) åŸºç¡€ä¿¡æ¯
    with tabs[0]:
        st.markdown("### ğŸ“Š åŸºç¡€é…ç½®")
        base_cfg = render_basic_config_section(cached_config)

    # 2) æ¨¡å‹ä¸æä¾›å•†ï¼ˆéšè—è·¯ç”±/é«˜çº§ï¼Œä¸“æ³¨æ¨¡å‹ï¼‰
    with tabs[1]:
        model_cfg = render_model_selection_panel(location="main", show_routing=False, show_advanced=False)

    # 3) åä½œä¸æ™ºèƒ½ä½“
    with tabs[2]:
        st.markdown("### ğŸ¤ åä½œé…ç½®")
        ai_cfg = render_ai_collaboration_config(cached_config)

    # 4) è·¯ç”±ä¸é¢„ç®—ï¼ˆç‹¬ç«‹é¡µç­¾ï¼Œé¿å…ä¸æ¨¡å‹é€‰æ‹©æ··åœ¨ä¸€èµ·ï¼‰
    with tabs[3]:
        st.markdown("### ğŸ§­ è·¯ç”±ä¸é¢„ç®—")
        routing_strategy, fallbacks, max_budget = render_routing_section(location="main")

    # 5) é«˜çº§è®¾ç½®ï¼ˆåŸºç¡€é¡¹ï¼‰
    with tabs[4]:
        adv_cfg = render_basic_advanced_settings(location="main")

    # æ±‡æ€»é…ç½®ï¼ˆä¸åŸæœ‰é”®ä¿æŒå…¼å®¹ï¼‰
    full_cfg = {
        **base_cfg,
        **model_cfg,
        **ai_cfg,
        **adv_cfg,
        'routing_strategy': routing_strategy,
        'fallbacks': fallbacks,
        'max_budget': max_budget,
        'analysis_mode': 'multi_model',
    }
    return full_cfg


def check_system_health() -> Dict[str, Any]:
    """æ£€æŸ¥ç³»ç»Ÿå¥åº·çŠ¶æ€"""
    try:
        # æ£€æŸ¥ç¯å¢ƒå˜é‡
        required_env_vars = {
            'MULTI_MODEL_ENABLED': os.getenv('MULTI_MODEL_ENABLED', 'false'),
            # 'DASHSCOPE_API_KEY' å·²ç§»é™¤
            'FINNHUB_API_KEY': bool(os.getenv('FINNHUB_API_KEY'))
        }
        
        health_status = {
            'overall_health': 'healthy',
            'multi_model_enabled': required_env_vars['MULTI_MODEL_ENABLED'].lower() in ['true', '1', 'yes'],
            'api_keys_configured': required_env_vars['FINNHUB_API_KEY'],
            'system_load': 'normal',
            'recommendations': []
        }
        
        # æ£€æŸ¥å¤šæ¨¡å‹åŠŸèƒ½æ˜¯å¦å¯ç”¨
        if not health_status['multi_model_enabled']:
            health_status['overall_health'] = 'limited'
            health_status['recommendations'].append(
                'å¯ç”¨å¤šæ¨¡å‹åŠŸèƒ½ï¼šè®¾ç½® MULTI_MODEL_ENABLED=true'
            )
        
        # æ£€æŸ¥APIå¯†é’¥
        if not health_status['api_keys_configured']:
            health_status['overall_health'] = 'limited'
            health_status['recommendations'].append(
                'é…ç½®APIå¯†é’¥ï¼šè¯·æ£€æŸ¥.envæ–‡ä»¶ä¸­çš„APIå¯†é’¥è®¾ç½®'
            )
        
        return health_status
        
    except Exception as e:
        logger.error(f"ç³»ç»Ÿå¥åº·æ£€æŸ¥å¤±è´¥: {e}")
        return {
            'overall_health': 'unknown',
            'error': str(e),
            'recommendations': ['è¯·æ£€æŸ¥ç³»ç»Ÿé…ç½®æˆ–è”ç³»æŠ€æœ¯æ”¯æŒ']
        }


def display_system_status(status: Dict[str, Any]):
    """æ˜¾ç¤ºç³»ç»ŸçŠ¶æ€"""
    health = status['overall_health']
    
    if health == 'healthy':
        st.success("âœ… ç³»ç»ŸçŠ¶æ€æ­£å¸¸ï¼Œæ‰€æœ‰åŠŸèƒ½å¯æ­£å¸¸ä½¿ç”¨")
    elif health == 'limited':
        st.warning("âš ï¸ ç³»ç»ŸåŠŸèƒ½æœ‰é™ï¼Œéƒ¨åˆ†åŠŸèƒ½å¯èƒ½ä¸å¯ç”¨")
        
        if status.get('recommendations'):
            with st.expander("ğŸ’¡ ä¼˜åŒ–å»ºè®®", expanded=True):
                for recommendation in status['recommendations']:
                    st.info(recommendation)
    
    elif health == 'unknown':
        st.error("âŒ ç³»ç»ŸçŠ¶æ€æœªçŸ¥ï¼Œè¯·æ£€æŸ¥ç³»ç»Ÿé…ç½®")
        if 'error' in status:
            with st.expander("ğŸ” é”™è¯¯è¯¦æƒ…"):
                st.code(status['error'])


def render_basic_config_section(cached_config: Dict[str, Any]) -> Dict[str, Any]:
    """æ¸²æŸ“åŸºç¡€é…ç½®éƒ¨åˆ†"""
    col1, col2 = st.columns(2)
    
    with col1:
        # å¸‚åœºé€‰æ‹©
        market_options = ["ç¾è‚¡", "Aè‚¡", "æ¸¯è‚¡"]
        cached_market = cached_config.get('market_type', 'Aè‚¡')
        try:
            market_index = market_options.index(cached_market)
        except (ValueError, TypeError):
            market_index = 1  # é»˜è®¤Aè‚¡
        
        market_type = st.selectbox(
            "é€‰æ‹©å¸‚åœº ğŸŒ",
            options=market_options,
            index=market_index,
            help="é€‰æ‹©è¦åˆ†æçš„è‚¡ç¥¨å¸‚åœº"
        )
        
        # è‚¡ç¥¨ä»£ç è¾“å…¥ä¸éªŒè¯
        stock_symbol = render_stock_input(market_type, cached_config)
        
    with col2:
        # åˆ†ææ—¥æœŸ
        analysis_date = st.date_input(
            "åˆ†ææ—¥æœŸ ğŸ“…",
            value=datetime.date.today(),
            help="é€‰æ‹©åˆ†æçš„åŸºå‡†æ—¥æœŸ",
            max_value=datetime.date.today()
        )
    
    return {
        'market_type': market_type,
        'stock_symbol': stock_symbol,
        'analysis_date': analysis_date.isoformat(),
        'analysis_mode': 'multi_model'  # å³ä¾§ä¸å†é€‰æ‹©ï¼Œå›ºå®šä¸ºå¤šæ¨¡å‹
    }


def render_stock_input(market_type: str, cached_config: Dict[str, Any]) -> str:
    """æ¸²æŸ“è‚¡ç¥¨ä»£ç è¾“å…¥æ¡†å¹¶éªŒè¯"""
    # è·å–ç¼“å­˜çš„è‚¡ç¥¨ä»£ç 
    cached_stock = cached_config.get('stock_symbol', '')
    
    # æ ¹æ®å¸‚åœºç±»å‹è®¾ç½®æç¤ºä¿¡æ¯
    if market_type == "ç¾è‚¡":
        placeholder = "è¾“å…¥ç¾è‚¡ä»£ç ï¼Œå¦‚ AAPL, TSLA, NVDA"
        help_text = "è¾“å…¥è¦åˆ†æçš„ç¾è‚¡ä»£ç "
        validation_pattern = r'^[A-Z]{1,5}$'
        default_value = cached_stock if cached_config.get('market_type') == 'ç¾è‚¡' else ''
    elif market_type == "æ¸¯è‚¡":
        placeholder = "è¾“å…¥æ¸¯è‚¡ä»£ç ï¼Œå¦‚ 0700.HK, 9988.HK"
        help_text = "è¾“å…¥è¦åˆ†æçš„æ¸¯è‚¡ä»£ç "
        validation_pattern = r'^\d{4,5}\.HK$'
        default_value = cached_stock if cached_config.get('market_type') == 'æ¸¯è‚¡' else ''
    else:  # Aè‚¡
        placeholder = "è¾“å…¥Aè‚¡ä»£ç ï¼Œå¦‚ 000001, 600519"
        help_text = "è¾“å…¥è¦åˆ†æçš„Aè‚¡ä»£ç "
        validation_pattern = r'^\d{6}$'
        default_value = cached_stock if cached_config.get('market_type') == 'Aè‚¡' else ''
    
    # è‚¡ç¥¨ä»£ç è¾“å…¥
    stock_symbol = st.text_input(
        "è‚¡ç¥¨ä»£ç  ğŸ“ˆ",
        value=default_value,
        placeholder=placeholder,
        help=help_text,
        key=f"enhanced_{market_type}_stock_input"
    ).strip().upper() if market_type != 'Aè‚¡' else st.text_input(
        "è‚¡ç¥¨ä»£ç  ğŸ“ˆ",
        value=default_value,
        placeholder=placeholder,
        help=help_text,
        key=f"enhanced_{market_type}_stock_input"
    ).strip()
    
    # å®æ—¶éªŒè¯
    if stock_symbol:
        import re
        if not re.match(validation_pattern, stock_symbol):
            st.error(f"âš ï¸ è‚¡ç¥¨ä»£ç æ ¼å¼ä¸æ­£ç¡®ï¼Œè¯·æ£€æŸ¥åé‡æ–°è¾“å…¥")
            st.info(f"ğŸ’¡ {market_type}æ­£ç¡®æ ¼å¼ç¤ºä¾‹: {placeholder.split('ï¼Œ')[1] if 'ï¼Œ' in placeholder else placeholder}")
        else:
            st.success(f"âœ… è‚¡ç¥¨ä»£ç æ ¼å¼æ­£ç¡®")
    
    return stock_symbol


def render_ai_collaboration_config(cached_config: Dict[str, Any]) -> Dict[str, Any]:
    """æ¸²æŸ“AIåä½œé…ç½®éƒ¨åˆ†"""
    col1, col2 = st.columns(2)
    
    with col1:
        # åä½œæ¨¡å¼é€‰æ‹©
        collaboration_mode = st.selectbox(
            "åä½œæ¨¡å¼ ğŸ”„",
            options=["sequential", "parallel", "debate"],
            format_func=lambda x: {
                "sequential": "ğŸ“‹ ä¸²è¡Œåä½œ - æ™ºèƒ½ä½“ä¾æ¬¡åˆ†æ",
                "parallel": "âš¡ å¹¶è¡Œåä½œ - æ™ºèƒ½ä½“åŒæ—¶åˆ†æ", 
                "debate": "ğŸ’¬ è¾©è®ºåä½œ - æ™ºèƒ½ä½“äº’ç›¸è¾©è®º"
            }[x],
            index=0,
            help="é€‰æ‹©æ™ºèƒ½ä½“åä½œæ¨¡å¼ï¼šä¸²è¡Œæ›´ç¨³å®šï¼Œå¹¶è¡Œæ›´å¿«é€Ÿï¼Œè¾©è®ºæ›´å…¨é¢"
        )
        
        # åˆ†ææ·±åº¦
        research_depth = st.select_slider(
            "ç ”ç©¶æ·±åº¦ ğŸ”",
            options=[1, 2, 3, 4, 5],
            value=3,
            format_func=lambda x: {
                1: "1çº§ - å¿«é€Ÿåˆ†æ (~2åˆ†é’Ÿ)",
                2: "2çº§ - åŸºç¡€åˆ†æ (~5åˆ†é’Ÿ)", 
                3: "3çº§ - æ ‡å‡†åˆ†æ (~8åˆ†é’Ÿ)",
                4: "4çº§ - æ·±åº¦åˆ†æ (~12åˆ†é’Ÿ)",
                5: "5çº§ - å…¨é¢åˆ†æ (~20åˆ†é’Ÿ)"
            }[x],
            help="é€‰æ‹©åˆ†æçš„æ·±åº¦çº§åˆ«ï¼Œçº§åˆ«è¶Šé«˜ç»“æœè¶Šè¯¦ç»†ä½†è€—æ—¶è¶Šé•¿"
        )
    
    with col2:
        # æ™ºèƒ½è·¯ç”±é€‰æ‹©
        use_smart_routing = st.checkbox(
            "ğŸ§  å¯ç”¨æ™ºèƒ½è·¯ç”±",
            value=True,
            help="è®©AIè‡ªåŠ¨ä¸ºæ¯ä¸ªä»»åŠ¡é€‰æ‹©æœ€é€‚åˆçš„æ¨¡å‹ç»„åˆï¼Œæé«˜åˆ†æè´¨é‡"
        )
        
        # æˆæœ¬æ§åˆ¶
        cost_optimization = st.selectbox(
            "æˆæœ¬æ§åˆ¶ ğŸ’°",
            options=["balanced", "cost_first", "quality_first"],
            format_func=lambda x: {
                "balanced": "âš–ï¸ å¹³è¡¡æ¨¡å¼ - æˆæœ¬ä¸è´¨é‡å¹¶é‡",
                "cost_first": "ğŸ’¸ æˆæœ¬ä¼˜å…ˆ - ä¼˜å…ˆä½¿ç”¨ç»æµå‹æ¨¡å‹",
                "quality_first": "â­ è´¨é‡ä¼˜å…ˆ - ä¼˜å…ˆä½¿ç”¨é«˜æ€§èƒ½æ¨¡å‹"
            }[x],
            index=0,
            help="é€‰æ‹©æˆæœ¬ä¼˜åŒ–ç­–ç•¥ï¼šå¹³è¡¡æ¨¡å¼æ¨èæ—¥å¸¸ä½¿ç”¨"
        )
    
    # ä¸“ä¸šæ™ºèƒ½ä½“é€‰æ‹©
    st.markdown("#### ğŸ‘¥ ä¸“ä¸šæ™ºèƒ½ä½“å›¢é˜Ÿ")
    st.markdown("*é€‰æ‹©å‚ä¸åˆ†æçš„ä¸“ä¸šæ™ºèƒ½ä½“è§’è‰²*")
    
    # åˆ›å»º3åˆ—å¸ƒå±€æ˜¾ç¤º9ä¸ªæ™ºèƒ½ä½“
    col1, col2, col3 = st.columns(3)
    
    # è·å–ç¼“å­˜çš„æ™ºèƒ½ä½“é€‰æ‹©
    cached_agents = cached_config.get('selected_agents', [
        'news_hunter', 'fundamental_expert', 'risk_manager'
    ]) if cached_config else ['news_hunter', 'fundamental_expert', 'risk_manager']
    
    selected_agents = []
    
    with col1:
        if st.checkbox(
            "ğŸ“° å¿«è®¯çŒæ‰‹",
            value='news_hunter' in cached_agents,
            help="å®æ—¶æ–°é—»æ”¶é›†ä¸åˆ†æ"
        ):
            selected_agents.append('news_hunter')
        
        if st.checkbox(
            "ğŸ“ˆ æŠ€æœ¯åˆ†æå¸ˆ", 
            value='technical_analyst' in cached_agents,
            help="æŠ€æœ¯æŒ‡æ ‡ä¸å›¾è¡¨åˆ†æï¼Œæ¨èä½¿ç”¨DeepSeek-V3æ¨¡å‹"
        ):
            selected_agents.append('technical_analyst')
        
        if st.checkbox(
            "ğŸ“‹ æ”¿ç­–ç ”ç©¶å‘˜",
            value='policy_researcher' in cached_agents,
            help="æ”¿ç­–æ³•è§„è§£è¯»åˆ†æ"
        ):
            selected_agents.append('policy_researcher')
    
    with col2:
        if st.checkbox(
            "ğŸ’° åŸºæœ¬é¢ä¸“å®¶",
            value='fundamental_expert' in cached_agents,
            help="è´¢åŠ¡æ•°æ®ä¸ä¼°å€¼åˆ†æï¼Œæ¨èä½¿ç”¨DeepSeek-R1æ¨¡å‹"
        ):
            selected_agents.append('fundamental_expert')
        
        if st.checkbox(
            "ğŸ’­ æƒ…ç»ªåˆ†æå¸ˆ",
            value='sentiment_analyst' in cached_agents,
            help="å¸‚åœºæƒ…ç»ªä¸ç¤¾åª’åˆ†æï¼Œæ¨èä½¿ç”¨Step-3æ¨¡å‹"
        ):
            selected_agents.append('sentiment_analyst')
        
        if st.checkbox(
            "ğŸ”§ å·¥å…·å·¥ç¨‹å¸ˆ",
            value='tool_engineer' in cached_agents,
            help="é‡åŒ–å·¥å…·ä¸å›æµ‹åˆ†æï¼Œæ¨èä½¿ç”¨Kimi-K2æ¨¡å‹"
        ):
            selected_agents.append('tool_engineer')
    
    with col3:
        if st.checkbox(
            "âš ï¸ é£é™©ç®¡ç†å‘˜",
            value='risk_manager' in cached_agents,
            help="æŠ•èµ„é£é™©è¯„ä¼°ä¸æ§åˆ¶ï¼Œæ¨èä½¿ç”¨GLM-4.5æ¨¡å‹"
        ):
            selected_agents.append('risk_manager')
        
        if st.checkbox(
            "ğŸ›¡ï¸ åˆè§„å®˜",
            value='compliance_officer' in cached_agents,
            help="æ³•å¾‹åˆè§„æ€§æ£€æŸ¥ï¼Œæ¨èä½¿ç”¨ERNIE-4.5æ¨¡å‹"
        ):
            selected_agents.append('compliance_officer')
        
        if st.checkbox(
            "ğŸ† é¦–å¸­å†³ç­–å®˜",
            value='chief_decision_officer' in cached_agents,
            help="ç»¼åˆå†³ç­–ä¸æœ€ç»ˆå»ºè®®ï¼Œæ¨èä½¿ç”¨æœ€å¼ºæ¨¡å‹"
        ):
            selected_agents.append('chief_decision_officer')
    
    # æ£€æŸ¥æ˜¯å¦é€‰æ‹©äº†æ™ºèƒ½ä½“
    if not selected_agents:
        st.warning("âš ï¸ è¯·è‡³å°‘é€‰æ‹©ä¸€ä¸ªä¸“ä¸šæ™ºèƒ½ä½“è¿›è¡Œåˆ†æ")
    else:
        st.success(f"âœ… å·²é€‰æ‹© {len(selected_agents)} ä¸ªä¸“ä¸šæ™ºèƒ½ä½“")
    
    return {
        'collaboration_mode': collaboration_mode,
        'research_depth': research_depth,
        'use_smart_routing': use_smart_routing,
        'cost_optimization': cost_optimization,
        'selected_agents': selected_agents
    }


def render_advanced_settings(cached_config: Dict[str, Any]) -> Dict[str, Any]:
    """æ¸²æŸ“é«˜çº§è®¾ç½®éƒ¨åˆ†"""
    col1, col2 = st.columns(2)
    
    with col1:
        # è¶…æ—¶è®¾ç½®
        analysis_timeout = st.number_input(
            "åˆ†æè¶…æ—¶æ—¶é—´ï¼ˆåˆ†é’Ÿï¼‰",
            min_value=5,
            max_value=60,
            value=20,
            help="è®¾ç½®å•æ¬¡åˆ†æçš„æœ€å¤§æ—¶é—´é™åˆ¶ï¼Œè¶…æ—¶å°†è‡ªåŠ¨åœæ­¢"
        )
        
        # é‡è¯•è®¾ç½®
        max_retries = st.number_input(
            "æœ€å¤§é‡è¯•æ¬¡æ•°",
            min_value=0,
            max_value=5,
            value=2,
            help="å½“åˆ†æå¤±è´¥æ—¶çš„æœ€å¤§è‡ªåŠ¨é‡è¯•æ¬¡æ•°"
        )
    
    with col2:
        # ç¼“å­˜è®¾ç½®
        use_cache = st.checkbox(
            "å¯ç”¨ç»“æœç¼“å­˜",
            value=True,
            help="å¯ç”¨åä¼šç¼“å­˜åˆ†æç»“æœï¼Œç›¸åŒé…ç½®çš„åˆ†æä¼šç›´æ¥ä½¿ç”¨ç¼“å­˜ç»“æœ"
        )
        
        # è¿›åº¦æŠ¥å‘Š
        enable_progress_updates = st.checkbox(
            "å®æ—¶è¿›åº¦æ›´æ–°",
            value=True,
            help="å®æ—¶æ˜¾ç¤ºåˆ†æè¿›åº¦å’Œå„ä¸ªé˜¶æ®µçš„çŠ¶æ€"
        )
    
    return {
        'analysis_timeout': analysis_timeout,
        'max_retries': max_retries,
        'use_cache': use_cache,
        'enable_progress_updates': enable_progress_updates
    }


def handle_analysis_submission(config: Dict[str, Any]):
    """å¤„ç†åˆ†ææäº¤è¯·æ±‚"""
    try:
        # ç¼“å­˜é…ç½®
        st.session_state['enhanced_multi_model_config'] = config
        
        # éªŒè¯é…ç½®
        validation_error = validate_analysis_config(config)
        if validation_error:
            st.error(f"âš ï¸ é…ç½®éªŒè¯å¤±è´¥: {validation_error}")
            return
        
        # æ˜¾ç¤ºé…ç½®æ€»è§ˆ
        display_analysis_overview(config)
        
        # å¼€å§‹åˆ†æ
        if config.get('enable_progress_updates', True):
            # å¸¦è¿›åº¦åé¦ˆçš„åˆ†æ
            run_analysis_with_progress(config)
        else:
            # ç®€å•æ¨¡å¼åˆ†æ
            run_simple_analysis(config)
            
    except Exception as e:
        # ä½¿ç”¨ç”¨æˆ·å‹å¥½çš„é”™è¯¯å¤„ç†
        user_error = handle_user_friendly_error(e, {
            'action': 'analysis_submission',
            'config': config
        })
        
        display_user_friendly_error(user_error)
        logger.error(f"åˆ†ææäº¤å¤„ç†å¤±è´¥: {e}", exc_info=True)


def validate_analysis_config(config: Dict[str, Any]) -> Optional[str]:
    """éªŒè¯åˆ†æé…ç½®"""
    # æ£€æŸ¥å¿…éœ€å­—æ®µ
    required_fields = ['market_type', 'stock_symbol', 'analysis_date', 'analysis_mode']
    for field in required_fields:
        if not config.get(field):
            return f"ç¼ºå°‘å¿…éœ€é…ç½®é¡¹: {field}"
    
    # æ£€æŸ¥è‚¡ç¥¨ä»£ç æ ¼å¼
    stock_symbol = config['stock_symbol']
    market_type = config['market_type']
    
    import re
    validation_patterns = {
        "ç¾è‚¡": r'^[A-Z]{1,5}$',
        "æ¸¯è‚¡": r'^\d{4,5}\.HK$',
        "Aè‚¡": r'^\d{6}$'
    }
    
    pattern = validation_patterns.get(market_type)
    if pattern and not re.match(pattern, stock_symbol):
        return f"è‚¡ç¥¨ä»£ç æ ¼å¼ä¸æ­£ç¡®: {stock_symbol}"
    
    # æ£€æŸ¥æ™ºèƒ½ä½“é€‰æ‹©
    if config.get('analysis_mode') == 'multi_model':
        selected_agents = config.get('selected_agents', [])
        if not selected_agents:
            return "å¤šæ¨¡å‹æ¨¡å¼ä¸‹å¿…é¡»é€‰æ‹©è‡³å°‘ä¸€ä¸ªæ™ºèƒ½ä½“"
    
    return None


def display_analysis_overview(config: Dict[str, Any]):
    """æ˜¾ç¤ºåˆ†æé…ç½®æ€»è§ˆ"""
    with st.expander("ğŸ“‹ åˆ†æé…ç½®æ€»è§ˆ", expanded=True):
        col1, col2 = st.columns(2)
        
        with col1:
            st.markdown(f"**ç›®æ ‡è‚¡ç¥¨**: {config['stock_symbol']} ({config['market_type']})")
            st.markdown(f"**åˆ†ææ—¥æœŸ**: {config['analysis_date']}")
            st.markdown(f"**åˆ†ææ¨¡å¼**: {config['analysis_mode']}")
        
        with col2:
            if config.get('analysis_mode') == 'multi_model':
                agents_count = len(config.get('selected_agents', []))
                st.markdown(f"**æ™ºèƒ½ä½“æ•°é‡**: {agents_count} ä¸ª")
                st.markdown(f"**åä½œæ¨¡å¼**: {config.get('collaboration_mode', 'sequential')}")
                st.markdown(f"**ç ”ç©¶æ·±åº¦**: {config.get('research_depth', 3)} çº§")
        
        # æ˜¾ç¤ºæ™ºèƒ½ä½“åˆ—è¡¨
        if config.get('selected_agents'):
            try:
                from web.utils.ui_utils import get_role_display_name
                agent_list = [get_role_display_name(agent) for agent in config['selected_agents']]
            except Exception:
                agent_list = config['selected_agents']
            st.markdown(f"**å‚ä¸æ™ºèƒ½ä½“**: {', '.join(agent_list)}")


def run_analysis_with_progress(config: Dict[str, Any]):
    """è¿è¡Œå¸¦è¿›åº¦åé¦ˆçš„åˆ†æ"""
    progress_tracker = AnalysisProgressTracker()
    progress_tracker.start_analysis()
    
    # åˆ›å»ºè¿›åº¦æ˜¾ç¤ºåŒºåŸŸ
    progress_container = st.empty()
    cancel_container = st.empty()
    
    try:
        # æ˜¾ç¤ºåˆå§‹è¿›åº¦
        display_progress_info(progress_tracker, progress_container, cancel_container)
        
        # å®é™…åˆ†æé€»è¾‘ï¼ˆè¿™é‡Œéœ€è¦é›†æˆåˆ°çœŸå®çš„åˆ†æç³»ç»Ÿï¼‰
        result = simulate_analysis_with_progress(config, progress_tracker, progress_container, cancel_container)
        
        if result:
            st.success("ğŸ‰ åˆ†æå®Œæˆï¼")
            display_analysis_results(result)
        else:
            st.error("âŒ åˆ†æè¢«å–æ¶ˆæˆ–å¤±è´¥")
            
    except Exception as e:
        user_error = handle_user_friendly_error(e, {
            'action': 'analysis_execution',
            'config': config
        })
        display_user_friendly_error(user_error)


def simulate_analysis_with_progress(config: Dict[str, Any], 
                                  progress_tracker: AnalysisProgressTracker,
                                  progress_container,
                                  cancel_container) -> Optional[Dict[str, Any]]:
    """æ¨¡æ‹Ÿå¸¦è¿›åº¦çš„åˆ†æè¿‡ç¨‹ï¼ˆå®é™…å®ç°éœ€è¦é›†æˆçœŸå®åˆ†æç³»ç»Ÿï¼‰"""
    stages = ["preparation", "data_collection", "model_initialization", "agent_analysis", "result_synthesis", "completion"]
    
    for i, stage in enumerate(stages):
        if progress_tracker.is_cancelled():
            return None
        
        progress_tracker.update_stage(stage, f"æ­£åœ¨æ‰§è¡Œé˜¶æ®µ {i+1}/6")
        display_progress_info(progress_tracker, progress_container, cancel_container)
        
        # æ¨¡æ‹Ÿå¤„ç†æ—¶é—´
        stage_info = progress_tracker.stages[stage]
        simulation_time = min(stage_info["estimated_seconds"], 3)  # æœ€å¤š3ç§’ç”¨äºæ¼”ç¤º
        
        for j in range(int(simulation_time * 10)):
            if progress_tracker.is_cancelled():
                return None
            
            # æ›´æ–°è¿›åº¦ç™¾åˆ†æ¯”
            stage_progress = (j / (simulation_time * 10)) * (stage_info["progress_range"][1] - stage_info["progress_range"][0])
            progress_tracker.update_progress(stage_info["progress_range"][0] + stage_progress)
            display_progress_info(progress_tracker, progress_container, cancel_container)
            
            time.sleep(0.1)  # æ¨¡æ‹Ÿå¤„ç†å»¶è¿Ÿ
    
    # è¿”å›æ¨¡æ‹Ÿç»“æœ
    return {
        "status": "success",
        "config": config,
        "result": "åˆ†æå®Œæˆï¼Œè¿™æ˜¯æ¨¡æ‹Ÿç»“æœã€‚å®é™…å®ç°éœ€è¦é›†æˆçœŸå®åˆ†æç³»ç»Ÿã€‚"
    }


def display_progress_info(progress_tracker: AnalysisProgressTracker, 
                         progress_container,
                         cancel_container):
    """æ˜¾ç¤ºè¿›åº¦ä¿¡æ¯"""
    display_info = progress_tracker.get_display_info()
    
    with progress_container.container():
        # è¿›åº¦æ¡
        st.progress(display_info["progress_percentage"] / 100)
        
        # å½“å‰é˜¶æ®µ
        st.markdown(f"**å½“å‰é˜¶æ®µ**: {display_info['current_stage']}")
        
        if display_info["details"]:
            st.markdown(f"**è¯¦æƒ…**: {display_info['details']}")
        
        # æ—¶é—´ä¿¡æ¯
        col1, col2 = st.columns(2)
        with col1:
            elapsed_mins = int(display_info["elapsed_time"] // 60)
            elapsed_secs = int(display_info["elapsed_time"] % 60)
            st.markdown(f"**å·²ç”¨æ—¶é—´**: {elapsed_mins}åˆ†{elapsed_secs}ç§’")
        
        with col2:
            if display_info["estimated_time_remaining"]:
                remaining_mins = int(display_info["estimated_time_remaining"] // 60)
                remaining_secs = int(display_info["estimated_time_remaining"] % 60)
                st.markdown(f"**é¢„è®¡å‰©ä½™**: {remaining_mins}åˆ†{remaining_secs}ç§’")
    
    # å–æ¶ˆæŒ‰é’®
    if display_info["is_cancellable"]:
        with cancel_container.container():
            if st.button("âŒ å–æ¶ˆåˆ†æ", type="secondary"):
                progress_tracker.request_cancel()
                st.warning("âš ï¸ æ­£åœ¨å–æ¶ˆåˆ†æ...")


def run_simple_analysis(config: Dict[str, Any]):
    """è¿è¡Œç®€å•æ¨¡å¼åˆ†æ"""
    with st.spinner("ğŸ¤– æ­£åœ¨è¿›è¡Œæ™ºèƒ½åˆ†æï¼Œè¯·ç¨å€™..."):
        try:
            # è¿™é‡Œåº”è¯¥é›†æˆçœŸå®çš„åˆ†æç³»ç»Ÿ
            time.sleep(3)  # æ¨¡æ‹Ÿå¤„ç†æ—¶é—´
            
            result = {
                "status": "success",
                "config": config,
                "result": "ç®€å•æ¨¡å¼åˆ†æå®Œæˆï¼Œè¿™æ˜¯æ¨¡æ‹Ÿç»“æœã€‚"
            }
            
            st.success("ğŸ‰ åˆ†æå®Œæˆï¼")
            display_analysis_results(result)
            
        except Exception as e:
            user_error = handle_user_friendly_error(e, {
                'action': 'simple_analysis',
                'config': config
            })
            display_user_friendly_error(user_error)


def display_analysis_results(result: Dict[str, Any]):
    """æ˜¾ç¤ºåˆ†æç»“æœ"""
    st.markdown("### ğŸ“Š åˆ†æç»“æœ")
    
    # ç»“æœæ€»è§ˆ
    with st.expander("ğŸ“‹ ç»“æœæ€»è§ˆ", expanded=True):
        st.json(result)
    
    # è¿™é‡Œå¯ä»¥æ·»åŠ æ›´è¯¦ç»†çš„ç»“æœæ˜¾ç¤ºé€»è¾‘


def display_user_friendly_error(user_error: Dict[str, Any]):
    """æ˜¾ç¤ºç”¨æˆ·å‹å¥½çš„é”™è¯¯ä¿¡æ¯"""
    st.error(f"{user_error['title']}")
    
    with st.expander("ğŸ’¡ è§£å†³å»ºè®®", expanded=True):
        st.markdown(user_error['message'])
        st.markdown("**å»ºè®®è§£å†³æ–¹æ¡ˆ:**")
        st.markdown(user_error['suggestion'])
        
        if user_error.get('estimated_fix_time'):
            st.info(f"â±ï¸ é¢„è®¡ä¿®å¤æ—¶é—´: {user_error['estimated_fix_time']}")
        
        if user_error.get('retry_possible', False):
            st.button("ğŸ”„ é‡è¯•åˆ†æ", type="secondary")


# ä¸»æ¸²æŸ“å‡½æ•°ï¼ˆå…¼å®¹åŸæœ‰è°ƒç”¨ï¼‰
def render_multi_model_analysis_form():
    """å…¼å®¹åŸæœ‰è°ƒç”¨çš„ä¸»æ¸²æŸ“å‡½æ•°"""
    render_enhanced_multi_model_analysis_form()
