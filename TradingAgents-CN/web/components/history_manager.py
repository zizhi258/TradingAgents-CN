"""
å†å²è®°å½•é¡µé¢ç»„ä»¶
æä¾›åˆ†æå†å²è®°å½•çš„æŸ¥çœ‹ã€æœç´¢ã€å¯¼å‡ºåŠŸèƒ½
åŒ…å«Tokenä½¿ç”¨ç»Ÿè®¡å’Œæˆæœ¬åˆ†æ
"""

import streamlit as st
import pandas as pd
import json
import plotly.express as px
import plotly.graph_objects as go
from plotly.subplots import make_subplots
from datetime import datetime, timedelta
from typing import List, Dict, Optional

from web.modules.history_service import HistoryService
from tradingagents.utils.logging_manager import get_logger
from tradingagents.config.config_manager import config_manager, UsageRecord

logger = get_logger('web.history')


def render_history_page():
    """æ¸²æŸ“å†å²è®°å½•é¡µé¢"""
    
    st.markdown("## ğŸ“ˆ å†å²è®°å½•")
    st.markdown("æŸ¥çœ‹å’Œç®¡ç†ä¸ªè‚¡åˆ†æå†å²è®°å½•")
    
    # åˆå§‹åŒ–å†å²è®°å½•æœåŠ¡
    try:
        history_service = HistoryService()
    except Exception as e:
        st.error(f"âŒ åˆå§‹åŒ–å†å²è®°å½•æœåŠ¡å¤±è´¥: {e}")
        return
    
    # é¡µé¢æ ‡ç­¾
    tab1, tab2, tab3 = st.tabs([
        "ğŸ“‹ è®°å½•åˆ—è¡¨",
        "ğŸ” æœç´¢è¿‡æ»¤", 
        "ğŸ“Š ç»Ÿè®¡åˆ†æ"
    ])
    
    # è®°å½•åˆ—è¡¨æ ‡ç­¾é¡µ
    with tab1:
        render_history_list(history_service)
        
    # æœç´¢è¿‡æ»¤æ ‡ç­¾é¡µ
    with tab2:
        render_history_search(history_service)
        
    # ç»Ÿè®¡åˆ†ææ ‡ç­¾é¡µ
    with tab3:
        render_history_statistics(history_service)


def render_history_list(history_service: HistoryService):
    """æ¸²æŸ“å†å²è®°å½•åˆ—è¡¨"""
    
    st.markdown("### åˆ†æè®°å½•åˆ—è¡¨")
    
    # åˆ†é¡µè®¾ç½®
    col1, col2, col3 = st.columns(3)
    
    with col1:
        items_per_page = st.selectbox(
            "æ¯é¡µæ˜¾ç¤º",
            [10, 20, 50, 100],
            index=1,
            key="history_items_per_page"
        )
    
    with col2:
        # è·å–æ€»è®°å½•æ•°ç”¨äºè®¡ç®—é¡µæ•°
        all_records = history_service.get_analysis_history(limit=10000)
        total_records = len(all_records)
        total_pages = (total_records + items_per_page - 1) // items_per_page
        
        if total_pages > 1:
            current_page = st.selectbox(
                f"é¡µé¢ (å…±{total_pages}é¡µ)",
                range(1, total_pages + 1),
                key="history_current_page"
            )
        else:
            current_page = 1
    
    with col3:
        if st.button("ğŸ”„ åˆ·æ–°æ•°æ®"):
            st.rerun()
    
    # è·å–å½“å‰é¡µæ•°æ®
    offset = (current_page - 1) * items_per_page
    records = history_service.get_analysis_history(limit=items_per_page, offset=offset)
    
    if not records:
        st.info("ğŸ“­ æš‚æ— å†å²è®°å½•")
        return
    
    st.markdown(f"**æ‰¾åˆ° {total_records} æ¡è®°å½•ï¼Œæ˜¾ç¤ºç¬¬ {current_page} é¡µ**")
    
    # è½¬æ¢ä¸ºè¡¨æ ¼æ•°æ®
    table_data = []
    for record in records:
        # æ ¼å¼åŒ–æ—¶é—´
        try:
            timestamp = datetime.fromisoformat(record.get('timestamp', '').replace('Z', ''))
            formatted_time = timestamp.strftime("%Y-%m-%d %H:%M")
        except:
            formatted_time = record.get('timestamp', 'æœªçŸ¥')
        
        # æ ¼å¼åŒ–æ™ºèƒ½ä½“åˆ—è¡¨
        agents = record.get('agents_used', [])
        agents_str = ', '.join(agents[:3])  # åªæ˜¾ç¤ºå‰3ä¸ª
        if len(agents) > 3:
            agents_str += f" (+{len(agents)-3})"
        
        table_data.append({
            "åˆ†æID": record['analysis_id'][:16] + "..." if len(record['analysis_id']) > 16 else record['analysis_id'],
            "æ—¶é—´": formatted_time,
            "è‚¡ç¥¨ä»£ç ": record.get('stock_symbol', 'æœªçŸ¥'),
            "å¸‚åœº": record.get('market_type', 'æœªçŸ¥'),
            "æ¨¡å¼": record.get('analysis_mode', 'æœªçŸ¥'),
            "æ·±åº¦": f"L{record.get('research_depth', 0)}",
            "æ¨¡å‹": record.get('model_provider', 'æœªçŸ¥'),
            "çŠ¶æ€": "âœ… å®Œæˆ" if record.get('status') == 'completed' else "âŒ å¤±è´¥",
            "å»ºè®®": record.get('action', '-'),
            "ç½®ä¿¡åº¦": f"{record.get('confidence', 0):.0%}" if record.get('confidence') else '-',
            "æ™ºèƒ½ä½“": agents_str
        })
    
    df = pd.DataFrame(table_data)
    
    # æ˜¾ç¤ºè¡¨æ ¼ï¼ˆæ”¯æŒé€‰æ‹©ï¼‰
    event = st.dataframe(
        df,
        use_container_width=True,
        hide_index=True,
        on_select="rerun",
        selection_mode="multi-row"
    )
    
    # æ“ä½œæŒ‰é’®
    st.markdown("#### æ‰¹é‡æ“ä½œ")
    col4, col5, col6, col7 = st.columns(4)
    
    with col4:
        if st.button("ğŸ‘ï¸ æŸ¥çœ‹è¯¦æƒ…"):
            selected_rows = event.selection.get('rows', []) if hasattr(event, 'selection') else []
            if len(selected_rows) == 1:
                selected_record = records[selected_rows[0]]
                _show_analysis_detail(history_service, selected_record['analysis_id'])
            elif len(selected_rows) > 1:
                st.warning("è¯·é€‰æ‹©å•æ¡è®°å½•æŸ¥çœ‹è¯¦æƒ…")
            else:
                st.warning("è¯·å…ˆé€‰æ‹©è®°å½•")
    
    with col5:
        if st.button("ğŸ“„ å¯¼å‡ºJSON"):
            selected_rows = event.selection.get('rows', []) if hasattr(event, 'selection') else []
            if selected_rows:
                selected_records = [records[i] for i in selected_rows]
                _export_records_json(selected_records)
            else:
                st.warning("è¯·å…ˆé€‰æ‹©è¦å¯¼å‡ºçš„è®°å½•")
    
    with col6:
        if st.button("ğŸ“ å¯¼å‡ºMarkdown"):
            selected_rows = event.selection.get('rows', []) if hasattr(event, 'selection') else []
            if selected_rows:
                selected_records = [records[i] for i in selected_rows]
                _export_records_markdown(selected_records)
            else:
                st.warning("è¯·å…ˆé€‰æ‹©è¦å¯¼å‡ºçš„è®°å½•")
    
    with col7:
        if st.button("ğŸ—‘ï¸ åˆ é™¤è®°å½•"):
            selected_rows = event.selection.get('rows', []) if hasattr(event, 'selection') else []
            if selected_rows:
                _confirm_delete_records(history_service, [records[i] for i in selected_rows])
            else:
                st.warning("è¯·å…ˆé€‰æ‹©è¦åˆ é™¤çš„è®°å½•")


def render_history_search(history_service: HistoryService):
    """æ¸²æŸ“æœç´¢è¿‡æ»¤é¡µé¢"""
    
    st.markdown("### æœç´¢ä¸è¿‡æ»¤")
    
    # æœç´¢è¡¨å•
    with st.form("search_form"):
        col1, col2 = st.columns(2)
        
        with col1:
            stock_symbol = st.text_input(
                "è‚¡ç¥¨ä»£ç ",
                placeholder="å¦‚ï¼š000001, AAPL, 0700.HK",
                help="è¾“å…¥å®Œæ•´è‚¡ç¥¨ä»£ç è¿›è¡Œç²¾ç¡®æœç´¢"
            )
            
            analysis_mode = st.selectbox(
                "åˆ†ææ¨¡å¼",
                ["å…¨éƒ¨", "å•æ¨¡å‹åˆ†æ", "å¤šæ¨¡å‹åä½œ"],
                help="é€‰æ‹©åˆ†ææ¨¡å¼ç±»å‹"
            )
        
        with col2:
            market_type = st.selectbox(
                "å¸‚åœºç±»å‹", 
                ["å…¨éƒ¨", "Aè‚¡", "æ¸¯è‚¡", "ç¾è‚¡"],
                help="é€‰æ‹©è‚¡ç¥¨å¸‚åœº"
            )
            
            model_provider = st.text_input(
                "æ¨¡å‹æä¾›å•†",
                placeholder="å¦‚ï¼šDeepSeek, Google, Mixed",
                help="æ¨¡å‹æä¾›å•†åç§°ï¼ˆæ”¯æŒæ¨¡ç³ŠåŒ¹é…ï¼‰"
            )
        
        # æ—¶é—´èŒƒå›´
        st.markdown("#### æ—¶é—´èŒƒå›´")
        col3, col4 = st.columns(2)
        
        with col3:
            start_date = st.date_input(
                "å¼€å§‹æ—¥æœŸ",
                value=datetime.now().date() - timedelta(days=30),
                help="é€‰æ‹©æœç´¢çš„å¼€å§‹æ—¥æœŸ"
            )
        
        with col4:
            end_date = st.date_input(
                "ç»“æŸæ—¥æœŸ",
                value=datetime.now().date(),
                help="é€‰æ‹©æœç´¢çš„ç»“æŸæ—¥æœŸ"
            )
        
        # æœç´¢æŒ‰é’®
        submitted = st.form_submit_button("ğŸ” æœç´¢", type="primary")
    
    if submitted:
        # æ„å»ºæœç´¢è¿‡æ»¤æ¡ä»¶
        filters = {}
        
        if stock_symbol:
            filters['stock_symbol'] = stock_symbol.strip()
        
        if analysis_mode != "å…¨éƒ¨":
            filters['analysis_mode'] = analysis_mode
        
        if market_type != "å…¨éƒ¨":
            filters['market_type'] = market_type
        
        if start_date:
            filters['start_date'] = start_date.strftime('%Y-%m-%d')
        
        if end_date:
            filters['end_date'] = end_date.strftime('%Y-%m-%d')
        
        # æ‰§è¡Œæœç´¢
        try:
            search_results = history_service.search_analyses(**filters)
            
            st.markdown(f"### æœç´¢ç»“æœ ({len(search_results)} æ¡)")
            
            if search_results:
                # æ˜¾ç¤ºæœç´¢ç»“æœè¡¨æ ¼
                _display_search_results(search_results)
            else:
                st.info("ğŸ” æœªæ‰¾åˆ°åŒ¹é…çš„è®°å½•")
                
        except Exception as e:
            st.error(f"âŒ æœç´¢å¤±è´¥: {e}")


def render_history_statistics(history_service: HistoryService):
    """æ¸²æŸ“ç»Ÿè®¡åˆ†æé¡µé¢ï¼ˆæ•´åˆTokenç»Ÿè®¡åŠŸèƒ½ï¼‰"""
    
    st.markdown("### ğŸ“Š ç»Ÿè®¡åˆ†æ")
    
    # åˆ›å»ºä¸¤ä¸ªä¸»è¦éƒ¨åˆ†çš„æ ‡ç­¾é¡µ
    sub_tab1, sub_tab2 = st.tabs([
        "ğŸ“ˆ åˆ†æè®°å½•ç»Ÿè®¡",
        "ğŸ’° Tokenä½¿ç”¨ç»Ÿè®¡"
    ])
    
    # åˆ†æè®°å½•ç»Ÿè®¡
    with sub_tab1:
        _render_analysis_statistics(history_service)
    
    # Tokenä½¿ç”¨ç»Ÿè®¡
    with sub_tab2:
        _render_token_statistics()


def _render_analysis_statistics(history_service: HistoryService):
    """æ¸²æŸ“åˆ†æè®°å½•ç»Ÿè®¡"""
    
    try:
        stats = history_service.get_statistics()
        
        # æ€»ä½“ç»Ÿè®¡
        col1, col2, col3, col4 = st.columns(4)
        
        with col1:
            st.metric("ğŸ“Š æ€»åˆ†ææ¬¡æ•°", stats['total_analyses'])
        
        with col2:
            st.metric("ğŸ“… è¿‘7å¤©", stats['recent_7_days'])
        
        with col3:
            st.metric("ğŸ“† è¿‘30å¤©", stats['recent_30_days'])
        
        with col4:
            if stats['total_analyses'] > 0:
                avg_per_day = stats['recent_30_days'] / 30
                st.metric("ğŸ“ˆ æ—¥å‡åˆ†æ", f"{avg_per_day:.1f}")
            else:
                st.metric("ğŸ“ˆ æ—¥å‡åˆ†æ", "0")
        
        # åˆ†å¸ƒç»Ÿè®¡å›¾è¡¨
        col5, col6 = st.columns(2)
        
        with col5:
            st.markdown("#### å¸‚åœºåˆ†å¸ƒ")
            if stats['market_distribution']:
                market_df = pd.DataFrame(
                    list(stats['market_distribution'].items()),
                    columns=['å¸‚åœº', 'æ•°é‡']
                )
                st.bar_chart(market_df.set_index('å¸‚åœº'))
            else:
                st.info("æš‚æ— æ•°æ®")
        
        with col6:
            st.markdown("#### æ¨¡å¼åˆ†å¸ƒ")
            if stats['mode_distribution']:
                mode_df = pd.DataFrame(
                    list(stats['mode_distribution'].items()),
                    columns=['æ¨¡å¼', 'æ•°é‡']
                )
                st.bar_chart(mode_df.set_index('æ¨¡å¼'))
            else:
                st.info("æš‚æ— æ•°æ®")
        
        # æ¨¡å‹ä½¿ç”¨ç»Ÿè®¡
        st.markdown("#### æ¨¡å‹æä¾›å•†ä½¿ç”¨ç»Ÿè®¡")
        if stats['model_distribution']:
            model_data = []
            for provider, count in stats['model_distribution'].items():
                percentage = (count / stats['total_analyses']) * 100
                model_data.append({
                    "æä¾›å•†": provider,
                    "ä½¿ç”¨æ¬¡æ•°": count,
                    "ä½¿ç”¨æ¯”ä¾‹": f"{percentage:.1f}%"
                })
            
            model_df = pd.DataFrame(model_data)
            st.dataframe(model_df, use_container_width=True, hide_index=True)
        else:
            st.info("æš‚æ— æ¨¡å‹ä½¿ç”¨æ•°æ®")
            
    except Exception as e:
        st.error(f"âŒ è·å–ç»Ÿè®¡ä¿¡æ¯å¤±è´¥: {e}")


def _render_token_statistics():
    """æ¸²æŸ“Tokenä½¿ç”¨ç»Ÿè®¡ï¼ˆä»token_statistics.pyè¿ç§»ï¼‰"""
    
    # ä¾§è¾¹æ æ§åˆ¶
    with st.sidebar:
        st.subheader("ğŸ“Š Tokenç»Ÿè®¡è®¾ç½®")
        
        # æ—¶é—´èŒƒå›´é€‰æ‹©
        time_range = st.selectbox(
            "ç»Ÿè®¡æ—¶é—´èŒƒå›´",
            ["ä»Šå¤©", "æœ€è¿‘7å¤©", "æœ€è¿‘30å¤©", "æœ€è¿‘90å¤©", "å…¨éƒ¨"],
            index=2,
            key="token_time_range"
        )
        
        # è½¬æ¢ä¸ºå¤©æ•°
        days_map = {
            "ä»Šå¤©": 1,
            "æœ€è¿‘7å¤©": 7,
            "æœ€è¿‘30å¤©": 30,
            "æœ€è¿‘90å¤©": 90,
            "å…¨éƒ¨": 365  # ä½¿ç”¨ä¸€å¹´ä½œä¸º"å…¨éƒ¨"
        }
        days = days_map[time_range]
        
        # åˆ·æ–°æŒ‰é’®
        if st.button("ğŸ”„ åˆ·æ–°Tokenæ•°æ®", use_container_width=True, key="token_refresh"):
            st.rerun()
        
        # å¯¼å‡ºæ•°æ®æŒ‰é’®
        if st.button("ğŸ“¥ å¯¼å‡ºTokenç»Ÿè®¡", use_container_width=True, key="token_export"):
            _export_token_statistics_data(days)
    
    # è·å–Tokenç»Ÿè®¡æ•°æ®
    try:
        stats = config_manager.get_usage_statistics(days)
        records = _load_usage_records_filtered(days)
        
        if not stats or stats.get('total_requests', 0) == 0:
            st.info(f"ğŸ“Š {time_range}å†…æš‚æ— Tokenä½¿ç”¨è®°å½•")
            st.markdown("""
            ### ğŸ’¡ å¦‚ä½•å¼€å§‹è®°å½•Tokenä½¿ç”¨ï¼Ÿ
            
            1. **è¿›è¡Œä¸ªè‚¡åˆ†æ**: ä½¿ç”¨ä¸»é¡µé¢çš„ä¸ªè‚¡åˆ†æåŠŸèƒ½
            2. **ç¡®ä¿APIé…ç½®**: æ£€æŸ¥Google/DeepSeekç­‰APIå¯†é’¥æ˜¯å¦æ­£ç¡®é…ç½®
            3. **å¯ç”¨æˆæœ¬è·Ÿè¸ª**: åœ¨é…ç½®ç®¡ç†ä¸­å¯ç”¨Tokenæˆæœ¬è·Ÿè¸ª
            
            ç³»ç»Ÿä¼šè‡ªåŠ¨è®°å½•æ‰€æœ‰LLMè°ƒç”¨çš„Tokenä½¿ç”¨æƒ…å†µã€‚
            """)
            return
        
        # 1) æ¦‚è§ˆæŒ‡æ ‡
        col1, col2, col3, col4 = st.columns(4)
        with col1:
            st.metric("ğŸ’° æ€»æˆæœ¬", f"Â¥{stats['total_cost']:.4f}")
        with col2:
            st.metric("ğŸ”¢ æ€»è°ƒç”¨æ¬¡æ•°", f"{stats['total_requests']:,}")
        with col3:
            total_tokens = stats['total_input_tokens'] + stats['total_output_tokens']
            st.metric("ğŸ“Š æ€»Tokenæ•°", f"{total_tokens:,}")
        with col4:
            avg_cost = stats['total_cost']/stats['total_requests'] if stats['total_requests'] else 0
            st.metric("âš–ï¸ å¹³å‡æ¯æ¬¡æˆæœ¬", f"Â¥{avg_cost:.4f}")
        
        # 2) Tokenåˆ†å¸ƒé¥¼å›¾ä¸ä¾›åº”å•†å¯¹æ¯”
        col1, col2 = st.columns(2)
        with col1:
            if stats['total_input_tokens'] > 0 or stats['total_output_tokens'] > 0:
                fig_pie = px.pie(
                    values=[stats['total_input_tokens'], stats['total_output_tokens']],
                    names=['è¾“å…¥Token', 'è¾“å‡ºToken'], 
                    title="Tokenä½¿ç”¨åˆ†å¸ƒ",
                    color_discrete_sequence=['#FF6B6B', '#4ECDC4']
                )
                fig_pie.update_traces(textposition='inside', textinfo='percent+label')
                st.plotly_chart(fig_pie, use_container_width=True)
            else:
                st.info("æš‚æ— Tokenåˆ†å¸ƒæ•°æ®")
        
        # 3) ä¾›åº”å•†å¯¹æ¯”
        with col2:
            provider_stats = stats.get('provider_stats', {})
            if provider_stats:
                providers = list(provider_stats.keys())
                costs = [provider_stats[p]['cost'] for p in providers]
                
                fig_cost = px.bar(
                    x=providers, 
                    y=costs,
                    title="å„ä¾›åº”å•†æˆæœ¬å¯¹æ¯”", 
                    labels={'x':'ä¾›åº”å•†','y':'æˆæœ¬(Â¥)'},
                    color_discrete_sequence=['#36A2EB', '#FF6384', '#FFCE56', '#4BC0C0']
                )
                st.plotly_chart(fig_cost, use_container_width=True)
            else:
                st.info("æš‚æ— ä¾›åº”å•†å¯¹æ¯”æ•°æ®")
        
        # 4) æˆæœ¬/Token è¶‹åŠ¿ï¼ˆåŒè½´ï¼‰
        if records:
            st.markdown("#### ğŸ“ˆ æˆæœ¬ä¸Tokenä½¿ç”¨è¶‹åŠ¿")
            df = pd.DataFrame([
                {
                    'date': datetime.fromisoformat(r.timestamp).date(),
                    'cost': r.cost,
                    'tokens': r.input_tokens + r.output_tokens,
                } for r in records if hasattr(r, 'timestamp') and hasattr(r, 'cost')
            ])
            
            if not df.empty:
                daily = df.groupby('date').agg({'cost':'sum','tokens':'sum'}).reset_index()
                
                fig = make_subplots(specs=[[{"secondary_y": True}]])
                fig.add_trace(
                    go.Scatter(
                        x=daily['date'], 
                        y=daily['cost'], 
                        name='æ¯æ—¥æˆæœ¬(Â¥)', 
                        line=dict(color='#FF6B6B', width=3)
                    ), 
                    secondary_y=False
                )
                fig.add_trace(
                    go.Scatter(
                        x=daily['date'], 
                        y=daily['tokens'], 
                        name='æ¯æ—¥Tokenæ•°', 
                        line=dict(color='#4ECDC4', width=3)
                    ), 
                    secondary_y=True
                )
                
                fig.update_xaxes(title_text="æ—¥æœŸ")
                fig.update_yaxes(title_text="æˆæœ¬(Â¥)", secondary_y=False)
                fig.update_yaxes(title_text="Tokenæ•°é‡", secondary_y=True)
                fig.update_layout(title_text="æˆæœ¬ä¸Tokenä½¿ç”¨è¶‹åŠ¿")
                
                st.plotly_chart(fig, use_container_width=True)
            else:
                st.info("æš‚æ— è¶‹åŠ¿æ•°æ®")
        
        # 5) æ˜ç»†è¡¨ + åˆ†é¡µ
        if records:
            _render_token_usage_table(records)
        
        # 6) ä¾›åº”å•†è¯¦ç»†ç»Ÿè®¡
        if provider_stats:
            _render_provider_detailed_stats(provider_stats)
        
    except Exception as e:
        st.error(f"âŒ è·å–Tokenç»Ÿè®¡å¤±è´¥: {e}")
        logger.error(f"Tokenç»Ÿè®¡è·å–å¤±è´¥: {e}", exc_info=True)


def _load_usage_records_filtered(days: int) -> List[UsageRecord]:
    """åŠ è½½è¿‡æ»¤åçš„ä½¿ç”¨è®°å½•"""
    try:
        all_records = config_manager.load_usage_records()
        cutoff = datetime.now() - timedelta(days=days)
        filtered_records = []
        
        for record in all_records:
            try:
                if hasattr(record, 'timestamp'):
                    record_time = datetime.fromisoformat(record.timestamp)
                    if record_time >= cutoff:
                        filtered_records.append(record)
            except Exception:
                # å¿½ç•¥æ—¶é—´è§£æå¤±è´¥çš„è®°å½•
                continue
        
        return filtered_records
        
    except Exception as e:
        st.error(f"åŠ è½½Tokenä½¿ç”¨è®°å½•å¤±è´¥: {e}")
        return []


def _render_token_usage_table(records: List[UsageRecord]):
    """æ¸²æŸ“Tokenä½¿ç”¨æ˜ç»†è¡¨"""
    
    st.markdown("#### ğŸ“‹ è¯¦ç»†ä½¿ç”¨è®°å½•")
    
    # åˆ†é¡µè®¾ç½®
    items_per_page = st.selectbox(
        "æ¯é¡µæ˜¾ç¤ºè®°å½•æ•°",
        [10, 20, 50, 100],
        index=1,
        key="token_table_items_per_page"
    )
    
    total_records = len(records)
    total_pages = (total_records + items_per_page - 1) // items_per_page
    
    if total_pages > 1:
        current_page = st.selectbox(
            f"é¡µé¢ (å…±{total_pages}é¡µ)",
            range(1, total_pages + 1),
            key="token_table_current_page"
        )
    else:
        current_page = 1
    
    # è·å–å½“å‰é¡µæ•°æ®
    start_idx = (current_page - 1) * items_per_page
    end_idx = start_idx + items_per_page
    page_records = records[start_idx:end_idx]
    
    if page_records:
        # è½¬æ¢ä¸ºè¡¨æ ¼æ•°æ®
        table_data = []
        for record in page_records:
            try:
                timestamp = datetime.fromisoformat(record.timestamp)
                formatted_time = timestamp.strftime("%Y-%m-%d %H:%M:%S")
            except:
                formatted_time = record.timestamp if hasattr(record, 'timestamp') else 'æœªçŸ¥'
            
            table_data.append({
                "æ—¶é—´": formatted_time,
                "æä¾›å•†": getattr(record, 'provider', 'æœªçŸ¥'),
                "æ¨¡å‹": getattr(record, 'model_name', 'æœªçŸ¥'),
                "è¾“å…¥Token": getattr(record, 'input_tokens', 0),
                "è¾“å‡ºToken": getattr(record, 'output_tokens', 0),
                "æ€»Token": getattr(record, 'input_tokens', 0) + getattr(record, 'output_tokens', 0),
                "æˆæœ¬(Â¥)": f"{getattr(record, 'cost', 0):.4f}",
                "åˆ†æç±»å‹": getattr(record, 'analysis_type', 'æœªçŸ¥'),
                "ä¼šè¯ID": getattr(record, 'session_id', 'æœªçŸ¥')[:16] + "..." if len(getattr(record, 'session_id', '')) > 16 else getattr(record, 'session_id', 'æœªçŸ¥')
            })
        
        df = pd.DataFrame(table_data)
        st.dataframe(df, use_container_width=True, hide_index=True)
        
        st.markdown(f"**æ˜¾ç¤º {start_idx + 1}-{min(end_idx, total_records)} æ¡ï¼Œå…± {total_records} æ¡è®°å½•**")
    else:
        st.info("å½“å‰é¡µé¢æš‚æ— è®°å½•")


def _render_provider_detailed_stats(provider_stats: Dict):
    """æ¸²æŸ“ä¾›åº”å•†è¯¦ç»†ç»Ÿè®¡"""
    
    st.markdown("#### ğŸ¢ ä¾›åº”å•†è¯¦ç»†ç»Ÿè®¡")
    
    for provider, stats in provider_stats.items():
        with st.expander(f"ğŸ“Š {provider} è¯¦ç»†ç»Ÿè®¡", expanded=False):
            col1, col2, col3, col4 = st.columns(4)
            
            with col1:
                st.metric("æ€»æˆæœ¬", f"Â¥{stats.get('cost', 0):.4f}")
            
            with col2:
                st.metric("è°ƒç”¨æ¬¡æ•°", f"{stats.get('requests', 0):,}")
            
            with col3:
                total_tokens = stats.get('input_tokens', 0) + stats.get('output_tokens', 0)
                st.metric("æ€»Token", f"{total_tokens:,}")
            
            with col4:
                avg_cost = stats.get('cost', 0) / stats.get('requests', 1)
                st.metric("å¹³å‡æˆæœ¬", f"Â¥{avg_cost:.4f}")
            
            # æ¨¡å‹åˆ†å¸ƒ
            models = stats.get('models', {})
            if models:
                st.markdown("**æ¨¡å‹ä½¿ç”¨åˆ†å¸ƒ**")
                model_data = []
                for model, count in models.items():
                    model_data.append({"æ¨¡å‹": model, "ä½¿ç”¨æ¬¡æ•°": count})
                
                model_df = pd.DataFrame(model_data)
                st.dataframe(model_df, use_container_width=True, hide_index=True)


def _export_token_statistics_data(days: int):
    """å¯¼å‡ºTokenç»Ÿè®¡æ•°æ®"""
    try:
        stats = config_manager.get_usage_statistics(days)
        records = _load_usage_records_filtered(days)
        
        export_data = {
            "export_info": {
                "export_time": datetime.now().isoformat(),
                "time_range_days": days,
                "total_records": len(records)
            },
            "summary_statistics": stats,
            "detailed_records": [
                {
                    "timestamp": getattr(r, 'timestamp', ''),
                    "provider": getattr(r, 'provider', ''),
                    "model_name": getattr(r, 'model_name', ''),
                    "input_tokens": getattr(r, 'input_tokens', 0),
                    "output_tokens": getattr(r, 'output_tokens', 0),
                    "cost": getattr(r, 'cost', 0),
                    "analysis_type": getattr(r, 'analysis_type', ''),
                    "session_id": getattr(r, 'session_id', '')
                } for r in records
            ]
        }
        
        json_str = json.dumps(export_data, ensure_ascii=False, indent=2)
        
        st.download_button(
            label="ğŸ“¥ ä¸‹è½½Tokenç»Ÿè®¡æ•°æ® (JSON)",
            data=json_str,
            file_name=f"token_statistics_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json",
            mime="application/json",
            key="download_token_stats"
        )
        
        st.success(f"âœ… å‡†å¤‡å¯¼å‡º {len(records)} æ¡Tokenä½¿ç”¨è®°å½•")
        
    except Exception as e:
        st.error(f"âŒ å¯¼å‡ºTokenç»Ÿè®¡æ•°æ®å¤±è´¥: {e}")


# ä¿æŒåŸæœ‰çš„å…¶ä»–å‡½æ•°ä¸å˜...


def _show_analysis_detail(history_service: HistoryService, analysis_id: str):
    """æ˜¾ç¤ºåˆ†æè¯¦æƒ…"""
    
    detail_data = history_service.get_analysis_detail(analysis_id)
    if not detail_data:
        st.error("âŒ æ— æ³•è·å–åˆ†æè¯¦æƒ…")
        return
    
    with st.expander(f"ğŸ“„ åˆ†æè¯¦æƒ…: {analysis_id}", expanded=True):
        # åŸºç¡€ä¿¡æ¯
        col1, col2 = st.columns(2)
        
        with col1:
            st.write(f"**åˆ†æID**: `{analysis_id}`")
            st.write(f"**çŠ¶æ€**: {detail_data.get('status', 'æœªçŸ¥')}")
            st.write(f"**è‚¡ç¥¨ä»£ç **: {detail_data.get('results', {}).get('analysis_data', {}).get('stock_symbol', 'æœªçŸ¥')}")
            st.write(f"**å¸‚åœºç±»å‹**: {detail_data.get('results', {}).get('analysis_data', {}).get('market_type', 'æœªçŸ¥')}")
        
        with col2:
            st.write(f"**ç ”ç©¶æ·±åº¦**: {detail_data.get('results', {}).get('analysis_data', {}).get('research_depth', 'æœªçŸ¥')}")
            st.write(f"**åä½œæ¨¡å¼**: {detail_data.get('results', {}).get('collaboration_mode', 'æœªçŸ¥')}")
            st.write(f"**ä½¿ç”¨çš„æ™ºèƒ½ä½“**: {', '.join(detail_data.get('results', {}).get('agents_used', []))}")
        
        # åˆ†æç»“æœæ‘˜è¦
        results = detail_data.get('results', {}).get('results', {})
        if results:
            st.markdown("#### åˆ†æç»“æœæ‘˜è¦")
            for agent_name, agent_result in results.items():
                if isinstance(agent_result, dict):
                    with st.expander(f"ğŸ¤– {agent_name.replace('_', ' ').title()}", expanded=False):
                        
                        # æ˜¾ç¤ºåŸºæœ¬ä¿¡æ¯
                        if 'confidence' in agent_result:
                            st.write(f"**ç½®ä¿¡åº¦**: {agent_result['confidence']:.0%}")
                        
                        if 'execution_time' in agent_result:
                            exec_time = agent_result['execution_time'] / 1000  # è½¬æ¢ä¸ºç§’
                            st.write(f"**æ‰§è¡Œæ—¶é—´**: {exec_time:.1f}ç§’")
                        
                        if 'model_used' in agent_result:
                            st.write(f"**ä½¿ç”¨æ¨¡å‹**: {agent_result['model_used']}")
                        
                        # æ˜¾ç¤ºåˆ†æå†…å®¹ï¼ˆæˆªæ–­æ˜¾ç¤ºï¼‰
                        analysis = agent_result.get('analysis', '')
                        if analysis:
                            if len(analysis) > 500:
                                st.markdown(f"**åˆ†æå†…å®¹**: {analysis[:500]}...")
                                if st.button(f"æ˜¾ç¤ºå®Œæ•´å†…å®¹ - {agent_name}", key=f"show_full_{agent_name}"):
                                    st.markdown(analysis)
                            else:
                                st.markdown(f"**åˆ†æå†…å®¹**: {analysis}")
        
        # åŸå§‹æ•°æ®ä¸‹è½½
        st.markdown("#### åŸå§‹æ•°æ®")
        json_str = json.dumps(detail_data, ensure_ascii=False, indent=2)
        st.download_button(
            label="ğŸ“¥ ä¸‹è½½å®Œæ•´æ•°æ® (JSON)",
            data=json_str,
            file_name=f"analysis_{analysis_id}.json",
            mime="application/json"
        )


def _display_search_results(results: List[Dict]):
    """æ˜¾ç¤ºæœç´¢ç»“æœ"""
    
    # è½¬æ¢ä¸ºè¡¨æ ¼æ ¼å¼
    table_data = []
    for record in results:
        try:
            timestamp = datetime.fromisoformat(record.get('timestamp', '').replace('Z', ''))
            formatted_time = timestamp.strftime("%Y-%m-%d %H:%M")
        except:
            formatted_time = record.get('timestamp', 'æœªçŸ¥')
        
        table_data.append({
            "æ—¶é—´": formatted_time,
            "è‚¡ç¥¨ä»£ç ": record.get('stock_symbol', 'æœªçŸ¥'),
            "å¸‚åœº": record.get('market_type', 'æœªçŸ¥'),
            "æ¨¡å¼": record.get('analysis_mode', 'æœªçŸ¥'),
            "å»ºè®®": record.get('action', '-'),
            "ç½®ä¿¡åº¦": f"{record.get('confidence', 0):.0%}" if record.get('confidence') else '-'
        })
    
    df = pd.DataFrame(table_data)
    st.dataframe(df, use_container_width=True, hide_index=True)


def _export_records_json(records: List[Dict]):
    """å¯¼å‡ºè®°å½•ä¸ºJSONæ ¼å¼"""
    try:
        json_data = json.dumps(records, ensure_ascii=False, indent=2)
        
        st.download_button(
            label="ğŸ“¥ ä¸‹è½½ JSON æ–‡ä»¶",
            data=json_data,
            file_name=f"analysis_history_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json",
            mime="application/json"
        )
        
        st.success(f"âœ… å‡†å¤‡å¯¼å‡º {len(records)} æ¡è®°å½•")
        
    except Exception as e:
        st.error(f"âŒ å¯¼å‡ºJSONå¤±è´¥: {e}")


def _export_records_markdown(records: List[Dict]):
    """å¯¼å‡ºè®°å½•ä¸ºMarkdownæ ¼å¼"""
    try:
        md_content = "# ä¸ªè‚¡åˆ†æå†å²è®°å½•\n\n"
        md_content += f"å¯¼å‡ºæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n"
        md_content += f"è®°å½•æ•°é‡: {len(records)}\n\n"
        
        for i, record in enumerate(records, 1):
            md_content += f"## {i}. {record.get('stock_symbol', 'æœªçŸ¥')} - {record.get('analysis_id', '')}\n\n"
            
            try:
                timestamp = datetime.fromisoformat(record.get('timestamp', '').replace('Z', ''))
                formatted_time = timestamp.strftime("%Y-%m-%d %H:%M:%S")
            except:
                formatted_time = record.get('timestamp', 'æœªçŸ¥')
            
            md_content += f"- **åˆ†ææ—¶é—´**: {formatted_time}\n"
            md_content += f"- **è‚¡ç¥¨ä»£ç **: {record.get('stock_symbol', 'æœªçŸ¥')}\n"
            md_content += f"- **å¸‚åœºç±»å‹**: {record.get('market_type', 'æœªçŸ¥')}\n"
            md_content += f"- **åˆ†ææ¨¡å¼**: {record.get('analysis_mode', 'æœªçŸ¥')}\n"
            md_content += f"- **ç ”ç©¶æ·±åº¦**: L{record.get('research_depth', 0)}\n"
            md_content += f"- **æŠ•èµ„å»ºè®®**: {record.get('action', 'æœªçŸ¥')}\n"
            md_content += f"- **ç½®ä¿¡åº¦**: {record.get('confidence', 0):.0%}\n" if record.get('confidence') else "- **ç½®ä¿¡åº¦**: æœªçŸ¥\n"
            md_content += f"- **çŠ¶æ€**: {record.get('status', 'æœªçŸ¥')}\n\n"
        
        st.download_button(
            label="ğŸ“¥ ä¸‹è½½ Markdown æ–‡ä»¶",
            data=md_content,
            file_name=f"analysis_history_{datetime.now().strftime('%Y%m%d_%H%M%S')}.md",
            mime="text/markdown"
        )
        
        st.success(f"âœ… å‡†å¤‡å¯¼å‡º {len(records)} æ¡è®°å½•")
        
    except Exception as e:
        st.error(f"âŒ å¯¼å‡ºMarkdownå¤±è´¥: {e}")


def _confirm_delete_records(history_service: HistoryService, records: List[Dict]):
    """ç¡®è®¤åˆ é™¤è®°å½•"""
    
    with st.expander(f"âš ï¸ ç¡®è®¤åˆ é™¤ {len(records)} æ¡è®°å½•ï¼Ÿ", expanded=True):
        st.warning("æ­¤æ“ä½œå°†æ°¸ä¹…åˆ é™¤é€‰ä¸­çš„åˆ†æè®°å½•ï¼Œæ— æ³•æ¢å¤ï¼")
        
        # æ˜¾ç¤ºè¦åˆ é™¤çš„è®°å½•
        for record in records:
            st.write(f"â€¢ {record.get('stock_symbol', 'æœªçŸ¥')} - {record['analysis_id']}")
        
        col1, col2 = st.columns(2)
        
        with col1:
            if st.button("âœ… ç¡®è®¤åˆ é™¤", type="primary", key="confirm_delete"):
                deleted_count = 0
                for record in records:
                    if history_service.delete_analysis(record['analysis_id']):
                        deleted_count += 1
                
                if deleted_count > 0:
                    st.success(f"âœ… æˆåŠŸåˆ é™¤ {deleted_count} æ¡è®°å½•")
                    st.rerun()
                else:
                    st.error("âŒ åˆ é™¤å¤±è´¥")
        
        with col2:
            if st.button("âŒ å–æ¶ˆ", key="cancel_delete"):
                st.info("å·²å–æ¶ˆåˆ é™¤æ“ä½œ")
