#!/usr/bin/env python3
"""
å¼‚æ­¥è¿›åº¦è·Ÿè¸ªå™¨
æ”¯æŒRediså’Œæ–‡ä»¶ä¸¤ç§å­˜å‚¨æ–¹å¼ï¼Œå‰ç«¯å®šæ—¶è½®è¯¢è·å–è¿›åº¦
"""

import json
import time
import os
from typing import Dict, Any, Optional, List
from datetime import datetime
import threading
from pathlib import Path

# å¯¼å…¥æ—¥å¿—æ¨¡å—
from tradingagents.utils.logging_manager import get_logger
logger = get_logger('async_progress')

def safe_serialize(obj):
    """å®‰å…¨åºåˆ—åŒ–å¯¹è±¡ï¼Œå¤„ç†ä¸å¯åºåˆ—åŒ–çš„ç±»å‹"""
    if hasattr(obj, 'dict'):
        # Pydanticå¯¹è±¡
        return obj.dict()
    elif hasattr(obj, '__dict__'):
        # æ™®é€šå¯¹è±¡ï¼Œè½¬æ¢ä¸ºå­—å…¸
        result = {}
        for key, value in obj.__dict__.items():
            if not key.startswith('_'):  # è·³è¿‡ç§æœ‰å±æ€§
                try:
                    json.dumps(value)  # æµ‹è¯•æ˜¯å¦å¯åºåˆ—åŒ–
                    result[key] = value
                except (TypeError, ValueError):
                    result[key] = str(value)  # è½¬æ¢ä¸ºå­—ç¬¦ä¸²
        return result
    elif isinstance(obj, (list, tuple)):
        return [safe_serialize(item) for item in obj]
    elif isinstance(obj, dict):
        return {key: safe_serialize(value) for key, value in obj.items()}
    else:
        try:
            json.dumps(obj)  # æµ‹è¯•æ˜¯å¦å¯åºåˆ—åŒ–
            return obj
        except (TypeError, ValueError):
            return str(obj)  # è½¬æ¢ä¸ºå­—ç¬¦ä¸²

class AsyncProgressTracker:
    """å¼‚æ­¥è¿›åº¦è·Ÿè¸ªå™¨"""
    
    def __init__(self, analysis_id: str, analysts: List[str], research_depth: int, llm_provider: str):
        self.analysis_id = analysis_id
        self.analysts = analysts
        self.research_depth = research_depth
        self.llm_provider = llm_provider
        self.start_time = time.time()
        # æµå¼å†™å…¥èŠ‚æµä¸å®ŒæˆçŠ¶æ€æ ‡è®°
        self._last_stream_update_ts: float = 0.0
        self._stream_update_interval_sec: float = 0.5  # è‡³å¤šæ¯500msè½ä¸€æ¬¡ç›˜
        self._explicitly_completed: bool = False
        
        # ç”Ÿæˆåˆ†ææ­¥éª¤
        self.analysis_steps = self._generate_dynamic_steps()
        self.estimated_duration = self._estimate_total_duration()
        
        # åˆå§‹åŒ–çŠ¶æ€
        self.current_step = 0
        self.progress_data = {
            'analysis_id': analysis_id,
            'status': 'running',
            'current_step': 0,
            'total_steps': len(self.analysis_steps),
            'progress_percentage': 0.0,
            'current_step_name': self.analysis_steps[0]['name'],
            'current_step_description': self.analysis_steps[0]['description'],
            'elapsed_time': 0.0,
            'estimated_total_time': self.estimated_duration,
            'remaining_time': self.estimated_duration,
            'last_message': 'å‡†å¤‡å¼€å§‹åˆ†æ...',
            'last_update': time.time(),
            'start_time': self.start_time,
            'steps': self.analysis_steps
        }
        
        # å°è¯•åˆå§‹åŒ–Redisï¼Œå¤±è´¥åˆ™ä½¿ç”¨æ–‡ä»¶
        self.redis_client = None
        self.use_redis = self._init_redis()
        
        if not self.use_redis:
            # ä½¿ç”¨æ–‡ä»¶å­˜å‚¨
            self.progress_file = f"./data/progress_{analysis_id}.json"
            os.makedirs(os.path.dirname(self.progress_file), exist_ok=True)
        
        # ä¿å­˜åˆå§‹çŠ¶æ€
        self._save_progress()
        
        logger.info(f"ğŸ“Š [å¼‚æ­¥è¿›åº¦] åˆå§‹åŒ–å®Œæˆ: {analysis_id}, å­˜å‚¨æ–¹å¼: {'Redis' if self.use_redis else 'æ–‡ä»¶'}")

        # æ³¨å†Œåˆ°æ—¥å¿—ç³»ç»Ÿè¿›è¡Œè‡ªåŠ¨è¿›åº¦æ›´æ–°
        try:
            from .progress_log_handler import register_analysis_tracker
            import threading

            # ä½¿ç”¨è¶…æ—¶æœºåˆ¶é¿å…æ­»é”
            def register_with_timeout():
                try:
                    register_analysis_tracker(self.analysis_id, self)
                    print(f"âœ… [è¿›åº¦é›†æˆ] è·Ÿè¸ªå™¨æ³¨å†ŒæˆåŠŸ: {self.analysis_id}")
                except Exception as e:
                    print(f"âŒ [è¿›åº¦é›†æˆ] è·Ÿè¸ªå™¨æ³¨å†Œå¤±è´¥: {e}")

            # åœ¨å•ç‹¬çº¿ç¨‹ä¸­æ³¨å†Œï¼Œé¿å…é˜»å¡ä¸»çº¿ç¨‹
            register_thread = threading.Thread(target=register_with_timeout, daemon=True)
            register_thread.start()
            register_thread.join(timeout=2.0)  # 2ç§’è¶…æ—¶

            if register_thread.is_alive():
                print(f"âš ï¸ [è¿›åº¦é›†æˆ] è·Ÿè¸ªå™¨æ³¨å†Œè¶…æ—¶ï¼Œç»§ç»­æ‰§è¡Œ: {self.analysis_id}")

        except ImportError:
            logger.debug("ğŸ“Š [å¼‚æ­¥è¿›åº¦] æ—¥å¿—é›†æˆä¸å¯ç”¨")
        except Exception as e:
            print(f"âŒ [è¿›åº¦é›†æˆ] è·Ÿè¸ªå™¨æ³¨å†Œå¼‚å¸¸: {e}")
    
    def _init_redis(self) -> bool:
        """åˆå§‹åŒ–Redisè¿æ¥"""
        try:
            # é¦–å…ˆæ£€æŸ¥REDIS_ENABLEDç¯å¢ƒå˜é‡
            redis_enabled_raw = os.getenv('REDIS_ENABLED', 'false')
            redis_enabled = redis_enabled_raw.lower()
            logger.info(f"ğŸ” [Redisæ£€æŸ¥] REDIS_ENABLEDåŸå€¼='{redis_enabled_raw}' -> å¤„ç†å='{redis_enabled}'")

            if redis_enabled != 'true':
                logger.info(f"ğŸ“Š [å¼‚æ­¥è¿›åº¦] Rediså·²ç¦ç”¨ï¼Œä½¿ç”¨æ–‡ä»¶å­˜å‚¨")
                return False

            import redis

            # ä»ç¯å¢ƒå˜é‡è·å–Redisé…ç½®
            redis_host = os.getenv('REDIS_HOST', 'localhost')
            redis_port = int(os.getenv('REDIS_PORT', 6379))
            redis_password = os.getenv('REDIS_PASSWORD', None)
            redis_db = int(os.getenv('REDIS_DB', 0))

            # åˆ›å»ºRedisè¿æ¥
            if redis_password:
                self.redis_client = redis.Redis(
                    host=redis_host,
                    port=redis_port,
                    password=redis_password,
                    db=redis_db,
                    decode_responses=True
                )
            else:
                self.redis_client = redis.Redis(
                    host=redis_host,
                    port=redis_port,
                    db=redis_db,
                    decode_responses=True
                )

            # æµ‹è¯•è¿æ¥
            self.redis_client.ping()
            logger.info(f"ğŸ“Š [å¼‚æ­¥è¿›åº¦] Redisè¿æ¥æˆåŠŸ: {redis_host}:{redis_port}")
            return True
        except Exception as e:
            logger.warning(f"ğŸ“Š [å¼‚æ­¥è¿›åº¦] Redisè¿æ¥å¤±è´¥ï¼Œä½¿ç”¨æ–‡ä»¶å­˜å‚¨: {e}")
            return False
    
    def _generate_dynamic_steps(self) -> List[Dict]:
        """æ ¹æ®åˆ†æå¸ˆæ•°é‡å’Œç ”ç©¶æ·±åº¦åŠ¨æ€ç”Ÿæˆåˆ†ææ­¥éª¤"""
        steps = [
            {"name": "ğŸ“‹ å‡†å¤‡é˜¶æ®µ", "description": "éªŒè¯è‚¡ç¥¨ä»£ç ï¼Œæ£€æŸ¥æ•°æ®æºå¯ç”¨æ€§", "weight": 0.05},
            {"name": "ğŸ”§ ç¯å¢ƒæ£€æŸ¥", "description": "æ£€æŸ¥APIå¯†é’¥é…ç½®ï¼Œç¡®ä¿æ•°æ®è·å–æ­£å¸¸", "weight": 0.02},
            {"name": "ğŸ’° æˆæœ¬ä¼°ç®—", "description": "æ ¹æ®åˆ†ææ·±åº¦é¢„ä¼°APIè°ƒç”¨æˆæœ¬", "weight": 0.01},
            {"name": "âš™ï¸ å‚æ•°è®¾ç½®", "description": "é…ç½®åˆ†æå‚æ•°å’ŒAIæ¨¡å‹é€‰æ‹©", "weight": 0.02},
            {"name": "ğŸš€ å¯åŠ¨å¼•æ“", "description": "åˆå§‹åŒ–AIåˆ†æå¼•æ“ï¼Œå‡†å¤‡å¼€å§‹åˆ†æ", "weight": 0.05},
        ]

        # ä¸ºæ¯ä¸ªåˆ†æå¸ˆæ·»åŠ ä¸“é—¨çš„æ­¥éª¤
        analyst_base_weight = 0.6 / len(self.analysts)  # 60%çš„æ—¶é—´ç”¨äºåˆ†æå¸ˆå·¥ä½œ
        for analyst in self.analysts:
            analyst_info = self._get_analyst_step_info(analyst)
            steps.append({
                "name": analyst_info["name"],
                "description": analyst_info["description"],
                "weight": analyst_base_weight
            })

        # æ ¹æ®ç ”ç©¶æ·±åº¦æ·»åŠ åç»­æ­¥éª¤
        if self.research_depth >= 2:
            # æ ‡å‡†å’Œæ·±åº¦åˆ†æåŒ…å«ç ”ç©¶å‘˜è¾©è®º
            steps.extend([
                {"name": "ğŸ“ˆ å¤šå¤´è§‚ç‚¹", "description": "ä»ä¹è§‚è§’åº¦åˆ†ææŠ•èµ„æœºä¼šå’Œä¸Šæ¶¨æ½œåŠ›", "weight": 0.06},
                {"name": "ğŸ“‰ ç©ºå¤´è§‚ç‚¹", "description": "ä»è°¨æ…è§’åº¦åˆ†ææŠ•èµ„é£é™©å’Œä¸‹è·Œå¯èƒ½", "weight": 0.06},
                {"name": "ğŸ¤ è§‚ç‚¹æ•´åˆ", "description": "ç»¼åˆå¤šç©ºè§‚ç‚¹ï¼Œå½¢æˆå¹³è¡¡çš„æŠ•èµ„å»ºè®®", "weight": 0.05},
            ])

        # æ‰€æœ‰æ·±åº¦éƒ½åŒ…å«äº¤æ˜“å†³ç­–
        steps.append({"name": "ğŸ’¡ æŠ•èµ„å»ºè®®", "description": "åŸºäºåˆ†æç»“æœåˆ¶å®šå…·ä½“çš„ä¹°å–å»ºè®®", "weight": 0.06})

        if self.research_depth >= 3:
            # æ·±åº¦åˆ†æåŒ…å«è¯¦ç»†é£é™©è¯„ä¼°
            steps.extend([
                {"name": "ğŸ”¥ æ¿€è¿›ç­–ç•¥", "description": "è¯„ä¼°é«˜é£é™©é«˜æ”¶ç›Šçš„æŠ•èµ„ç­–ç•¥", "weight": 0.03},
                {"name": "ğŸ›¡ï¸ ä¿å®ˆç­–ç•¥", "description": "è¯„ä¼°ä½é£é™©ç¨³å¥çš„æŠ•èµ„ç­–ç•¥", "weight": 0.03},
                {"name": "âš–ï¸ å¹³è¡¡ç­–ç•¥", "description": "è¯„ä¼°é£é™©æ”¶ç›Šå¹³è¡¡çš„æŠ•èµ„ç­–ç•¥", "weight": 0.03},
                {"name": "ğŸ¯ é£é™©æ§åˆ¶", "description": "åˆ¶å®šé£é™©æ§åˆ¶æªæ–½å’Œæ­¢æŸç­–ç•¥", "weight": 0.04},
            ])
        else:
            # å¿«é€Ÿå’Œæ ‡å‡†åˆ†æçš„ç®€åŒ–é£é™©è¯„ä¼°
            steps.append({"name": "âš ï¸ é£é™©æç¤º", "description": "è¯†åˆ«ä¸»è¦æŠ•èµ„é£é™©å¹¶æä¾›é£é™©æç¤º", "weight": 0.05})

        # æœ€åçš„æ•´ç†æ­¥éª¤
        steps.append({"name": "ğŸ“Š ç”ŸæˆæŠ¥å‘Š", "description": "æ•´ç†æ‰€æœ‰åˆ†æç»“æœï¼Œç”Ÿæˆæœ€ç»ˆæŠ•èµ„æŠ¥å‘Š", "weight": 0.04})

        # é‡æ–°å¹³è¡¡æƒé‡ï¼Œç¡®ä¿æ€»å’Œä¸º1.0
        total_weight = sum(step["weight"] for step in steps)
        for step in steps:
            step["weight"] = step["weight"] / total_weight

        return steps
    
    def _get_analyst_display_name(self, analyst: str) -> str:
        """è·å–åˆ†æå¸ˆæ˜¾ç¤ºåç§°ï¼ˆä¿ç•™å…¼å®¹æ€§ï¼‰"""
        name_map = {
            'market': 'å¸‚åœºåˆ†æå¸ˆ',
            'fundamentals': 'åŸºæœ¬é¢åˆ†æå¸ˆ',
            'technical': 'æŠ€æœ¯åˆ†æå¸ˆ',
            'sentiment': 'æƒ…ç»ªåˆ†æå¸ˆ',
            'risk': 'é£é™©åˆ†æå¸ˆ'
        }
        return name_map.get(analyst, f'{analyst}åˆ†æå¸ˆ')

    def _get_analyst_step_info(self, analyst: str) -> Dict[str, str]:
        """è·å–åˆ†æå¸ˆæ­¥éª¤ä¿¡æ¯ï¼ˆåç§°å’Œæè¿°ï¼‰"""
        analyst_info = {
            'market': {
                "name": "ğŸ“Š å¸‚åœºåˆ†æ",
                "description": "åˆ†æè‚¡ä»·èµ°åŠ¿ã€æˆäº¤é‡ã€å¸‚åœºçƒ­åº¦ç­‰å¸‚åœºè¡¨ç°"
            },
            'fundamentals': {
                "name": "ğŸ’¼ åŸºæœ¬é¢åˆ†æ",
                "description": "åˆ†æå…¬å¸è´¢åŠ¡çŠ¶å†µã€ç›ˆåˆ©èƒ½åŠ›ã€æˆé•¿æ€§ç­‰åŸºæœ¬é¢"
            },
            'technical': {
                "name": "ğŸ“ˆ æŠ€æœ¯åˆ†æ",
                "description": "åˆ†æKçº¿å›¾å½¢ã€æŠ€æœ¯æŒ‡æ ‡ã€æ”¯æ’‘é˜»åŠ›ç­‰æŠ€æœ¯é¢"
            },
            'sentiment': {
                "name": "ğŸ’­ æƒ…ç»ªåˆ†æ",
                "description": "åˆ†æå¸‚åœºæƒ…ç»ªã€æŠ•èµ„è€…å¿ƒç†ã€èˆ†è®ºå€¾å‘ç­‰"
            },
            'news': {
                "name": "ğŸ“° æ–°é—»åˆ†æ",
                "description": "åˆ†æç›¸å…³æ–°é—»ã€å…¬å‘Šã€è¡Œä¸šåŠ¨æ€å¯¹è‚¡ä»·çš„å½±å“"
            },
            'social_media': {
                "name": "ğŸŒ ç¤¾äº¤åª’ä½“",
                "description": "åˆ†æç¤¾äº¤åª’ä½“è®¨è®ºã€ç½‘ç»œçƒ­åº¦ã€æ•£æˆ·æƒ…ç»ªç­‰"
            },
            'risk': {
                "name": "âš ï¸ é£é™©åˆ†æ",
                "description": "è¯†åˆ«æŠ•èµ„é£é™©ã€è¯„ä¼°é£é™©ç­‰çº§ã€åˆ¶å®šé£æ§æªæ–½"
            }
        }

        return analyst_info.get(analyst, {
            "name": f"ğŸ” {analyst}åˆ†æ",
            "description": f"è¿›è¡Œ{analyst}ç›¸å…³çš„ä¸“ä¸šåˆ†æ"
        })
    
    def _estimate_total_duration(self) -> float:
        """æ ¹æ®åˆ†æå¸ˆæ•°é‡ã€ç ”ç©¶æ·±åº¦ã€æ¨¡å‹ç±»å‹é¢„ä¼°æ€»æ—¶é•¿ï¼ˆç§’ï¼‰"""
        # åŸºç¡€æ—¶é—´ï¼ˆç§’ï¼‰- ç¯å¢ƒå‡†å¤‡ã€é…ç½®ç­‰
        base_time = 60
        
        # æ¯ä¸ªåˆ†æå¸ˆçš„å®é™…è€—æ—¶ï¼ˆåŸºäºçœŸå®æµ‹è¯•æ•°æ®ï¼‰
        analyst_base_time = {
            1: 120,  # å¿«é€Ÿåˆ†æï¼šæ¯ä¸ªåˆ†æå¸ˆçº¦2åˆ†é’Ÿ
            2: 180,  # åŸºç¡€åˆ†æï¼šæ¯ä¸ªåˆ†æå¸ˆçº¦3åˆ†é’Ÿ  
            3: 240   # æ ‡å‡†åˆ†æï¼šæ¯ä¸ªåˆ†æå¸ˆçº¦4åˆ†é’Ÿ
        }.get(self.research_depth, 180)
        
        analyst_time = len(self.analysts) * analyst_base_time
        
        # æ¨¡å‹é€Ÿåº¦å½±å“ï¼ˆåŸºäºå®é™…æµ‹è¯•ï¼‰
        model_multiplier = {
            # dashscope å·²ç§»é™¤
            'deepseek': 0.7,   # DeepSeekè¾ƒå¿«
            'google': 1.3      # Googleè¾ƒæ…¢
        }.get(self.llm_provider, 1.0)
        
        # ç ”ç©¶æ·±åº¦é¢å¤–å½±å“ï¼ˆå·¥å…·è°ƒç”¨å¤æ‚åº¦ï¼‰
        depth_multiplier = {
            1: 0.8,  # å¿«é€Ÿåˆ†æï¼Œè¾ƒå°‘å·¥å…·è°ƒç”¨
            2: 1.0,  # åŸºç¡€åˆ†æï¼Œæ ‡å‡†å·¥å…·è°ƒç”¨
            3: 1.3   # æ ‡å‡†åˆ†æï¼Œæ›´å¤šå·¥å…·è°ƒç”¨å’Œæ¨ç†
        }.get(self.research_depth, 1.0)
        
        total_time = (base_time + analyst_time) * model_multiplier * depth_multiplier
        return total_time
    
    def update_progress(self, message: str, step: Optional[int] = None):
        """æ›´æ–°è¿›åº¦çŠ¶æ€"""
        current_time = time.time()
        elapsed_time = current_time - self.start_time

        # è‹¥å·²æ˜¾å¼å®Œæˆï¼Œå¿½ç•¥åç»­æµå¼ç‰‡æ®µä»¥é¿å…æ­»å¾ªç¯å¼åˆ·ç›˜
        if self.progress_data.get('status') == 'completed' or self._explicitly_completed:
            # ä»å…è®¸éæµå¼çš„é‡è¦äº‹ä»¶å†™å…¥ï¼ˆä¾‹å¦‚é”™è¯¯ï¼‰
            if isinstance(message, str) and message.startswith('[æµå¼]'):
                return

        # è‡ªåŠ¨æ£€æµ‹æ­¥éª¤
        if step is None:
            step = self._detect_step_from_message(message)

        # æ›´æ–°æ­¥éª¤ï¼ˆé˜²æ­¢å€’é€€ï¼‰
        if step is not None and step >= self.current_step:
            self.current_step = step
            logger.debug(f"ğŸ“Š [å¼‚æ­¥è¿›åº¦] æ­¥éª¤æ¨è¿›åˆ° {self.current_step + 1}/{len(self.analysis_steps)}")

        # å¦‚æœæ˜¯å®Œæˆæ¶ˆæ¯ï¼Œç¡®ä¿è¿›åº¦ä¸º100%å¹¶è®°å½•æ˜¾å¼å®Œæˆ
        if "åˆ†æå®Œæˆ" in message or "åˆ†ææˆåŠŸ" in message or "âœ… åˆ†æå®Œæˆ" in message:
            self.current_step = len(self.analysis_steps) - 1
            self._explicitly_completed = True
            logger.info(f"ğŸ“Š [å¼‚æ­¥è¿›åº¦] åˆ†æå®Œæˆï¼Œè®¾ç½®ä¸ºæœ€ç»ˆæ­¥éª¤")

        # è®¡ç®—è¿›åº¦
        progress_percentage = self._calculate_weighted_progress() * 100
        remaining_time = self._estimate_remaining_time(progress_percentage / 100, elapsed_time)

        # æ›´æ–°è¿›åº¦æ•°æ®
        current_step_info = self.analysis_steps[self.current_step] if self.current_step < len(self.analysis_steps) else self.analysis_steps[-1]

        # ç‰¹æ®Šå¤„ç†å·¥å…·è°ƒç”¨æ¶ˆæ¯ï¼Œæ›´æ–°æ­¥éª¤æè¿°ä½†ä¸æ”¹å˜æ­¥éª¤
        step_description = current_step_info['description']
        if "å·¥å…·è°ƒç”¨" in message:
            # æå–å·¥å…·åç§°å¹¶æ›´æ–°æè¿°
            if "get_stock_market_data_unified" in message:
                step_description = "æ­£åœ¨è·å–å¸‚åœºæ•°æ®å’ŒæŠ€æœ¯æŒ‡æ ‡..."
            elif "get_stock_fundamentals_unified" in message:
                step_description = "æ­£åœ¨è·å–åŸºæœ¬é¢æ•°æ®å’Œè´¢åŠ¡æŒ‡æ ‡..."
            elif "get_china_stock_data" in message:
                step_description = "æ­£åœ¨è·å–Aè‚¡å¸‚åœºæ•°æ®..."
            elif "get_china_fundamentals" in message:
                step_description = "æ­£åœ¨è·å–Aè‚¡åŸºæœ¬é¢æ•°æ®..."
            else:
                step_description = "æ­£åœ¨è°ƒç”¨åˆ†æå·¥å…·..."
        elif "æ¨¡å—å¼€å§‹" in message:
            step_description = f"å¼€å§‹{current_step_info['name']}..."
        elif "æ¨¡å—å®Œæˆ" in message:
            step_description = f"{current_step_info['name']}å·²å®Œæˆ"

        # ä»…å½“æ˜¾å¼å®Œæˆæ—¶æ‰æ ‡è®° completedï¼›å¦åˆ™å³ä¾¿100%ä¹Ÿä¿æŒ runningï¼Œç­‰å¾…æœ€ç»ˆæ”¶å°¾
        calculated_status = 'completed' if (self._explicitly_completed) else 'running'

        self.progress_data.update({
            'current_step': self.current_step,
            'progress_percentage': progress_percentage,
            'current_step_name': current_step_info['name'],
            'current_step_description': step_description,
            'elapsed_time': elapsed_time,
            'remaining_time': remaining_time,
            'last_message': message,
            'last_update': current_time,
            'status': calculated_status
        })

        # æµå¼ç‰‡æ®µè¿›è¡ŒèŠ‚æµï¼Œé¿å…é«˜é¢‘åˆ·ç›˜
        if isinstance(message, str) and message.startswith('[æµå¼]') and not self._explicitly_completed:
            if current_time - self._last_stream_update_ts < self._stream_update_interval_sec:
                return
            self._last_stream_update_ts = current_time

        # ä¿å­˜åˆ°å­˜å‚¨
        self._save_progress()

        # è¯¦ç»†çš„æ›´æ–°æ—¥å¿—
        step_name = current_step_info.get('name', 'æœªçŸ¥')
        logger.info(f"ğŸ“Š [è¿›åº¦æ›´æ–°] {self.analysis_id}: {message[:50]}...")
        logger.debug(f"ğŸ“Š [è¿›åº¦è¯¦æƒ…] æ­¥éª¤{self.current_step + 1}/{len(self.analysis_steps)} ({step_name}), è¿›åº¦{progress_percentage:.1f}%, è€—æ—¶{elapsed_time:.1f}s")
    
    def _detect_step_from_message(self, message: str) -> Optional[int]:
        """æ ¹æ®æ¶ˆæ¯å†…å®¹æ™ºèƒ½æ£€æµ‹å½“å‰æ­¥éª¤"""
        message_lower = message.lower()

        # å¼€å§‹åˆ†æé˜¶æ®µ - åªåŒ¹é…æœ€åˆçš„å¼€å§‹æ¶ˆæ¯
        if "ğŸš€ å¼€å§‹ä¸ªè‚¡åˆ†æ" in message:
            return 0
        # æ•°æ®éªŒè¯é˜¶æ®µ
        elif "éªŒè¯" in message or "é¢„è·å–" in message or "æ•°æ®å‡†å¤‡" in message:
            return 0
        # ç¯å¢ƒå‡†å¤‡é˜¶æ®µ
        elif "ç¯å¢ƒ" in message or "api" in message_lower or "å¯†é’¥" in message:
            return 1
        # æˆæœ¬é¢„ä¼°é˜¶æ®µ
        elif "æˆæœ¬" in message or "é¢„ä¼°" in message:
            return 2
        # å‚æ•°é…ç½®é˜¶æ®µ
        elif "é…ç½®" in message or "å‚æ•°" in message:
            return 3
        # å¼•æ“åˆå§‹åŒ–é˜¶æ®µ
        elif "åˆå§‹åŒ–" in message or "å¼•æ“" in message:
            return 4
        # æ¨¡å—å¼€å§‹æ—¥å¿— - åªåœ¨ç¬¬ä¸€æ¬¡å¼€å§‹æ—¶æ¨è¿›æ­¥éª¤
        elif "æ¨¡å—å¼€å§‹" in message:
            # ä»æ—¥å¿—ä¸­æå–åˆ†æå¸ˆç±»å‹ï¼ŒåŒ¹é…æ–°çš„æ­¥éª¤åç§°
            if "market_analyst" in message or "market" in message:
                return self._find_step_by_keyword(["å¸‚åœºåˆ†æ", "å¸‚åœº"])
            elif "fundamentals_analyst" in message or "fundamentals" in message:
                return self._find_step_by_keyword(["åŸºæœ¬é¢åˆ†æ", "åŸºæœ¬é¢"])
            elif "technical_analyst" in message or "technical" in message:
                return self._find_step_by_keyword(["æŠ€æœ¯åˆ†æ", "æŠ€æœ¯"])
            elif "sentiment_analyst" in message or "sentiment" in message:
                return self._find_step_by_keyword(["æƒ…ç»ªåˆ†æ", "æƒ…ç»ª"])
            elif "news_analyst" in message or "news" in message:
                return self._find_step_by_keyword(["æ–°é—»åˆ†æ", "æ–°é—»"])
            elif "social_media_analyst" in message or "social" in message:
                return self._find_step_by_keyword(["ç¤¾äº¤åª’ä½“", "ç¤¾äº¤"])
            elif "risk_analyst" in message or "risk" in message:
                return self._find_step_by_keyword(["é£é™©åˆ†æ", "é£é™©"])
            elif "bull_researcher" in message or "bull" in message:
                return self._find_step_by_keyword(["å¤šå¤´è§‚ç‚¹", "å¤šå¤´", "çœ‹æ¶¨"])
            elif "bear_researcher" in message or "bear" in message:
                return self._find_step_by_keyword(["ç©ºå¤´è§‚ç‚¹", "ç©ºå¤´", "çœ‹è·Œ"])
            elif "research_manager" in message:
                return self._find_step_by_keyword(["è§‚ç‚¹æ•´åˆ", "æ•´åˆ"])
            elif "trader" in message:
                return self._find_step_by_keyword(["æŠ•èµ„å»ºè®®", "å»ºè®®"])
            elif "risk_manager" in message:
                return self._find_step_by_keyword(["é£é™©æ§åˆ¶", "æ§åˆ¶"])
            elif "graph_signal_processing" in message or "signal" in message:
                return self._find_step_by_keyword(["ç”ŸæˆæŠ¥å‘Š", "æŠ¥å‘Š"])
        # å·¥å…·è°ƒç”¨æ—¥å¿— - ä¸æ¨è¿›æ­¥éª¤ï¼Œåªæ›´æ–°æè¿°
        elif "å·¥å…·è°ƒç”¨" in message:
            # ä¿æŒå½“å‰æ­¥éª¤ï¼Œä¸æ¨è¿›
            return None
        # æ¨¡å—å®Œæˆæ—¥å¿— - æ¨è¿›åˆ°ä¸‹ä¸€æ­¥
        elif "æ¨¡å—å®Œæˆ" in message:
            # æ¨¡å—å®Œæˆæ—¶ï¼Œä»å½“å‰æ­¥éª¤æ¨è¿›åˆ°ä¸‹ä¸€æ­¥
            # ä¸å†ä¾èµ–æ¨¡å—åç§°ï¼Œè€Œæ˜¯åŸºäºå½“å‰è¿›åº¦æ¨è¿›
            next_step = min(self.current_step + 1, len(self.analysis_steps) - 1)
            logger.debug(f"ğŸ“Š [æ­¥éª¤æ¨è¿›] æ¨¡å—å®Œæˆï¼Œä»æ­¥éª¤{self.current_step}æ¨è¿›åˆ°æ­¥éª¤{next_step}")
            return next_step

        return None

    def _find_step_by_keyword(self, keywords) -> Optional[int]:
        """æ ¹æ®å…³é”®è¯æŸ¥æ‰¾æ­¥éª¤ç´¢å¼•"""
        if isinstance(keywords, str):
            keywords = [keywords]

        for i, step in enumerate(self.analysis_steps):
            for keyword in keywords:
                if keyword in step["name"]:
                    return i
        return None

    def _get_next_step(self, keyword: str) -> Optional[int]:
        """è·å–æŒ‡å®šæ­¥éª¤çš„ä¸‹ä¸€æ­¥"""
        current_step_index = self._find_step_by_keyword(keyword)
        if current_step_index is not None:
            return min(current_step_index + 1, len(self.analysis_steps) - 1)
        return None

    def _calculate_weighted_progress(self) -> float:
        """æ ¹æ®æ­¥éª¤æƒé‡è®¡ç®—è¿›åº¦"""
        if self.current_step >= len(self.analysis_steps):
            return 1.0

        # å¦‚æœæ˜¯æœ€åä¸€æ­¥ï¼Œè¿”å›100%
        if self.current_step == len(self.analysis_steps) - 1:
            return 1.0

        completed_weight = sum(step["weight"] for step in self.analysis_steps[:self.current_step])
        total_weight = sum(step["weight"] for step in self.analysis_steps)

        return min(completed_weight / total_weight, 1.0)
    
    def _estimate_remaining_time(self, progress: float, elapsed_time: float) -> float:
        """åŸºäºæ€»é¢„ä¼°æ—¶é—´è®¡ç®—å‰©ä½™æ—¶é—´"""
        # å¦‚æœè¿›åº¦å·²å®Œæˆï¼Œå‰©ä½™æ—¶é—´ä¸º0
        if progress >= 1.0:
            return 0.0

        # ä½¿ç”¨ç®€å•è€Œå‡†ç¡®çš„æ–¹æ³•ï¼šæ€»é¢„ä¼°æ—¶é—´ - å·²èŠ±è´¹æ—¶é—´
        remaining = max(self.estimated_duration - elapsed_time, 0)

        # å¦‚æœå·²ç»è¶…è¿‡é¢„ä¼°æ—¶é—´ï¼Œæ ¹æ®å½“å‰è¿›åº¦åŠ¨æ€è°ƒæ•´
        if remaining <= 0 and progress > 0:
            # åŸºäºå½“å‰è¿›åº¦é‡æ–°ä¼°ç®—æ€»æ—¶é—´ï¼Œç„¶åè®¡ç®—å‰©ä½™
            estimated_total = elapsed_time / progress
            remaining = max(estimated_total - elapsed_time, 0)

        return remaining
    
    def _save_progress(self):
        """ä¿å­˜è¿›åº¦åˆ°å­˜å‚¨"""
        try:
            current_step_name = self.progress_data.get('current_step_name', 'æœªçŸ¥')
            progress_pct = self.progress_data.get('progress_percentage', 0)
            status = self.progress_data.get('status', 'running')

            if self.use_redis:
                # ä¿å­˜åˆ°Redisï¼ˆå®‰å…¨åºåˆ—åŒ–ï¼‰
                key = f"progress:{self.analysis_id}"
                safe_data = safe_serialize(self.progress_data)
                data_json = json.dumps(safe_data, ensure_ascii=False)
                self.redis_client.setex(key, 3600, data_json)  # 1å°æ—¶è¿‡æœŸ

                logger.info(f"ğŸ“Š [Rediså†™å…¥] {self.analysis_id} -> {status} | {current_step_name} | {progress_pct:.1f}%")
                logger.debug(f"ğŸ“Š [Redisè¯¦æƒ…] é”®: {key}, æ•°æ®å¤§å°: {len(data_json)} å­—èŠ‚")
            else:
                # ä¿å­˜åˆ°æ–‡ä»¶ï¼ˆå®‰å…¨åºåˆ—åŒ–ï¼‰
                safe_data = safe_serialize(self.progress_data)
                with open(self.progress_file, 'w', encoding='utf-8') as f:
                    json.dump(safe_data, f, ensure_ascii=False, indent=2)

                logger.info(f"ğŸ“Š [æ–‡ä»¶å†™å…¥] {self.analysis_id} -> {status} | {current_step_name} | {progress_pct:.1f}%")
                logger.debug(f"ğŸ“Š [æ–‡ä»¶è¯¦æƒ…] è·¯å¾„: {self.progress_file}")

        except Exception as e:
            logger.error(f"ğŸ“Š [å¼‚æ­¥è¿›åº¦] ä¿å­˜å¤±è´¥: {e}")
            # å°è¯•å¤‡ç”¨å­˜å‚¨æ–¹å¼
            try:
                if self.use_redis:
                    # Rediså¤±è´¥ï¼Œå°è¯•æ–‡ä»¶å­˜å‚¨
                    logger.warning(f"ğŸ“Š [å¼‚æ­¥è¿›åº¦] Redisä¿å­˜å¤±è´¥ï¼Œå°è¯•æ–‡ä»¶å­˜å‚¨")
                    backup_file = f"./data/progress_{self.analysis_id}.json"
                    os.makedirs(os.path.dirname(backup_file), exist_ok=True)
                    safe_data = safe_serialize(self.progress_data)
                    with open(backup_file, 'w', encoding='utf-8') as f:
                        json.dump(safe_data, f, ensure_ascii=False, indent=2)
                    logger.info(f"ğŸ“Š [å¤‡ç”¨å­˜å‚¨] æ–‡ä»¶ä¿å­˜æˆåŠŸ: {backup_file}")
                else:
                    # æ–‡ä»¶å­˜å‚¨å¤±è´¥ï¼Œå°è¯•ç®€åŒ–æ•°æ®
                    logger.warning(f"ğŸ“Š [å¼‚æ­¥è¿›åº¦] æ–‡ä»¶ä¿å­˜å¤±è´¥ï¼Œå°è¯•ç®€åŒ–æ•°æ®")
                    simplified_data = {
                        'analysis_id': self.analysis_id,
                        'status': self.progress_data.get('status', 'unknown'),
                        'progress_percentage': self.progress_data.get('progress_percentage', 0),
                        'last_message': str(self.progress_data.get('last_message', '')),
                        'last_update': self.progress_data.get('last_update', time.time())
                    }
                    backup_file = f"./data/progress_{self.analysis_id}.json"
                    with open(backup_file, 'w', encoding='utf-8') as f:
                        json.dump(simplified_data, f, ensure_ascii=False, indent=2)
                    logger.info(f"ğŸ“Š [å¤‡ç”¨å­˜å‚¨] ç®€åŒ–æ•°æ®ä¿å­˜æˆåŠŸ: {backup_file}")
            except Exception as backup_e:
                logger.error(f"ğŸ“Š [å¼‚æ­¥è¿›åº¦] å¤‡ç”¨å­˜å‚¨ä¹Ÿå¤±è´¥: {backup_e}")
    
    def get_progress(self) -> Dict[str, Any]:
        """è·å–å½“å‰è¿›åº¦"""
        return self.progress_data.copy()
    
    def mark_completed(self, message: str = "åˆ†æå®Œæˆ", results: Any = None):
        """æ ‡è®°åˆ†æå®Œæˆ"""
        self._explicitly_completed = True
        self.update_progress(message)
        self.progress_data['status'] = 'completed'
        self.progress_data['progress_percentage'] = 100.0
        self.progress_data['remaining_time'] = 0.0

        # ä¿å­˜åˆ†æç»“æœï¼ˆå®‰å…¨åºåˆ—åŒ–ï¼‰
        if results is not None:
            try:
                self.progress_data['raw_results'] = safe_serialize(results)
                logger.info(f"ğŸ“Š [å¼‚æ­¥è¿›åº¦] ä¿å­˜åˆ†æç»“æœ: {self.analysis_id}")
            except Exception as e:
                logger.warning(f"ğŸ“Š [å¼‚æ­¥è¿›åº¦] ç»“æœåºåˆ—åŒ–å¤±è´¥: {e}")
                self.progress_data['raw_results'] = str(results)  # æœ€åçš„fallback

        self._save_progress()
        logger.info(f"ğŸ“Š [å¼‚æ­¥è¿›åº¦] åˆ†æå®Œæˆ: {self.analysis_id}")

        # ä»æ—¥å¿—ç³»ç»Ÿæ³¨é”€
        try:
            from .progress_log_handler import unregister_analysis_tracker
            unregister_analysis_tracker(self.analysis_id)
        except ImportError:
            pass
    
    def mark_failed(self, error_message: str):
        """æ ‡è®°åˆ†æå¤±è´¥"""
        self.progress_data['status'] = 'failed'
        self.progress_data['last_message'] = f"åˆ†æå¤±è´¥: {error_message}"
        self.progress_data['last_update'] = time.time()
        self._save_progress()
        logger.error(f"ğŸ“Š [å¼‚æ­¥è¿›åº¦] åˆ†æå¤±è´¥: {self.analysis_id}, é”™è¯¯: {error_message}")

        # ä»æ—¥å¿—ç³»ç»Ÿæ³¨é”€
        try:
            from .progress_log_handler import unregister_analysis_tracker
            unregister_analysis_tracker(self.analysis_id)
        except ImportError:
            pass

def get_progress_by_id(analysis_id: str) -> Optional[Dict[str, Any]]:
    """æ ¹æ®åˆ†æIDè·å–è¿›åº¦"""
    try:
        # æ£€æŸ¥REDIS_ENABLEDç¯å¢ƒå˜é‡
        redis_enabled = os.getenv('REDIS_ENABLED', 'false').lower() == 'true'

        # å¦‚æœRediså¯ç”¨ï¼Œå…ˆå°è¯•Redis
        if redis_enabled:
            try:
                import redis

                # ä»ç¯å¢ƒå˜é‡è·å–Redisé…ç½®
                redis_host = os.getenv('REDIS_HOST', 'localhost')
                redis_port = int(os.getenv('REDIS_PORT', 6379))
                redis_password = os.getenv('REDIS_PASSWORD', None)
                redis_db = int(os.getenv('REDIS_DB', 0))

                # åˆ›å»ºRedisè¿æ¥
                if redis_password:
                    redis_client = redis.Redis(
                        host=redis_host,
                        port=redis_port,
                        password=redis_password,
                        db=redis_db,
                        decode_responses=True
                    )
                else:
                    redis_client = redis.Redis(
                        host=redis_host,
                        port=redis_port,
                        db=redis_db,
                        decode_responses=True
                    )

                key = f"progress:{analysis_id}"
                data = redis_client.get(key)
                if data:
                    return json.loads(data)
            except Exception as e:
                logger.debug(f"ğŸ“Š [å¼‚æ­¥è¿›åº¦] Redisè¯»å–å¤±è´¥: {e}")

        # å°è¯•æ–‡ä»¶
        progress_file = f"./data/progress_{analysis_id}.json"
        if os.path.exists(progress_file):
            with open(progress_file, 'r', encoding='utf-8') as f:
                return json.load(f)

        return None
    except Exception as e:
        logger.error(f"ğŸ“Š [å¼‚æ­¥è¿›åº¦] è·å–è¿›åº¦å¤±è´¥: {analysis_id}, é”™è¯¯: {e}")
        return None

def format_time(seconds: float) -> str:
    """æ ¼å¼åŒ–æ—¶é—´æ˜¾ç¤º"""
    if seconds < 60:
        return f"{seconds:.1f}ç§’"
    elif seconds < 3600:
        minutes = seconds / 60
        return f"{minutes:.1f}åˆ†é’Ÿ"
    else:
        hours = seconds / 3600
        return f"{hours:.1f}å°æ—¶"


def get_latest_analysis_id() -> Optional[str]:
    """è·å–æœ€æ–°çš„åˆ†æID"""
    try:
        # æ£€æŸ¥REDIS_ENABLEDç¯å¢ƒå˜é‡
        redis_enabled = os.getenv('REDIS_ENABLED', 'false').lower() == 'true'

        # å¦‚æœRediså¯ç”¨ï¼Œå…ˆå°è¯•ä»Redisè·å–
        if redis_enabled:
            try:
                import redis

                # ä»ç¯å¢ƒå˜é‡è·å–Redisé…ç½®
                redis_host = os.getenv('REDIS_HOST', 'localhost')
                redis_port = int(os.getenv('REDIS_PORT', 6379))
                redis_password = os.getenv('REDIS_PASSWORD', None)
                redis_db = int(os.getenv('REDIS_DB', 0))

                # åˆ›å»ºRedisè¿æ¥
                if redis_password:
                    redis_client = redis.Redis(
                        host=redis_host,
                        port=redis_port,
                        password=redis_password,
                        db=redis_db,
                        decode_responses=True
                    )
                else:
                    redis_client = redis.Redis(
                        host=redis_host,
                        port=redis_port,
                        db=redis_db,
                        decode_responses=True
                    )

                # è·å–æ‰€æœ‰progressé”®
                keys = redis_client.keys("progress:*")
                if not keys:
                    return None

                # è·å–æ¯ä¸ªé”®çš„æ•°æ®ï¼Œæ‰¾åˆ°æœ€æ–°çš„
                latest_time = 0
                latest_id = None

                for key in keys:
                    try:
                        data = redis_client.get(key)
                        if data:
                            progress_data = json.loads(data)
                            last_update = progress_data.get('last_update', 0)
                            if last_update > latest_time:
                                latest_time = last_update
                                # ä»é”®åä¸­æå–analysis_id (å»æ‰"progress:"å‰ç¼€)
                                latest_id = key.replace('progress:', '')
                    except Exception:
                        continue

                if latest_id:
                    logger.info(f"ğŸ“Š [æ¢å¤åˆ†æ] æ‰¾åˆ°æœ€æ–°åˆ†æID: {latest_id}")
                    return latest_id

            except Exception as e:
                logger.debug(f"ğŸ“Š [æ¢å¤åˆ†æ] RedisæŸ¥æ‰¾å¤±è´¥: {e}")

        # å¦‚æœRediså¤±è´¥æˆ–æœªå¯ç”¨ï¼Œå°è¯•ä»æ–‡ä»¶æŸ¥æ‰¾
        data_dir = Path("data")
        if data_dir.exists():
            progress_files = list(data_dir.glob("progress_*.json"))
            if progress_files:
                # æŒ‰ä¿®æ”¹æ—¶é—´æ’åºï¼Œè·å–æœ€æ–°çš„
                latest_file = max(progress_files, key=lambda f: f.stat().st_mtime)
                # ä»æ–‡ä»¶åæå–analysis_id
                filename = latest_file.name
                if filename.startswith("progress_") and filename.endswith(".json"):
                    analysis_id = filename[9:-5]  # å»æ‰å‰ç¼€å’Œåç¼€
                    logger.debug(f"ğŸ“Š [æ¢å¤åˆ†æ] ä»æ–‡ä»¶æ‰¾åˆ°æœ€æ–°åˆ†æID: {analysis_id}")
                    return analysis_id

        return None
    except Exception as e:
        logger.error(f"ğŸ“Š [æ¢å¤åˆ†æ] è·å–æœ€æ–°åˆ†æIDå¤±è´¥: {e}")
        return None
